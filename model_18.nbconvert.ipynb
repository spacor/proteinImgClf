{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "c21a5bb776b463e9488f1928b636be7b5a92a1c2"
   },
   "outputs": [],
   "source": [
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# base_path = r'../input'\n",
    "base_path = r'input'\n",
    "PATH_TRAIN_ANNO = os.path.join(base_path, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(base_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "583ead53ccf420ab4290230a0a17cc3b6c62c74d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    USE_TENSORBOARD = True\n",
    "    writer = SummaryWriter()\n",
    "except:\n",
    "    USE_TENSORBOARD = False\n",
    "    print('No tensorboard X')\n",
    "\n",
    "def record_tb(phase, tag, value, global_step):\n",
    "    if USE_TENSORBOARD is True:\n",
    "        writer.add_scalar('{phase}/{tag}'.format(phase=phase, tag=tag), value, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7a95c899247b666f9235e3100a569744c46bf943"
   },
   "outputs": [],
   "source": [
    "# os.listdir(PATH_TRAIN_IMG)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e85715fa2a9217474fc039c2b399c9b33490689a"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28\n",
    "MAX_TAGS = 5\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "VAL_SIZE =0.2\n",
    "THRESHOLD = 0.5\n",
    "SAMPLES = 1\n",
    "base_lr = 0.01\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7e81577b2c725960293a5cfabb29e0d46d66834c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 31072\n",
      "[('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', [16, 0]),\n",
      " ('000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', [7, 1, 2, 0]),\n",
      " ('000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', [5])]\n"
     ]
    }
   ],
   "source": [
    "def get_transform_anno(annotation_path, img_path):\n",
    "    df = pd.read_csv(annotation_path)\n",
    "    annotations = []\n",
    "    for i, row in df.iterrows():\n",
    "        rcd_id = row['Id']\n",
    "        rcd_cate =  [int(j) for j in row['Target'].split()]\n",
    "        annotations.append((rcd_id, rcd_cate))\n",
    "    return annotations\n",
    "#get annotations\n",
    "annotations = get_transform_anno(PATH_TRAIN_ANNO, PATH_TRAIN_IMG)\n",
    "sample_size = int(len(annotations) * SAMPLES)\n",
    "print('sample size: {}'.format(sample_size))\n",
    "annotations = annotations[:sample_size]\n",
    "pprint(annotations[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "878d1a4d5d29884cc313258347df1ee630abae1a"
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, img_meta, img_path, transform = None):\n",
    "        self.img_meta = img_meta\n",
    "        self.transform = transform\n",
    "        self.channels = ['red', 'blue', 'yellow', 'green']\n",
    "        self.img_path = img_path\n",
    "        self.mlb = MultiLabelBinarizer(classes=range(0,NUM_CLASSES))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id, img_tags= self.img_meta[idx]\n",
    "        ch = []\n",
    "        img_file_template = '{}_{}.png'\n",
    "        for c in self.channels:\n",
    "            ch.append(io.imread(os.path.join(self.img_path, img_file_template.format(img_id, c))))\n",
    "        img = np.stack(ch)\n",
    "\n",
    "        #augmentation\n",
    "        if bool(self.transform) is True:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        #binarize\n",
    "        img_tags = self.mlb.fit_transform([img_tags]).squeeze()\n",
    "        \n",
    "        #transform to tensor\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img_tags = torch.from_numpy(img_tags)\n",
    "        \n",
    "        output = (img, img_tags)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "af583f0882e55fd31a3df230822ac86f99e25f4c"
   },
   "outputs": [],
   "source": [
    "class ImgTfm:\n",
    "    def __init__(self, aug_pipline = None):\n",
    "        self.seq = aug_pipline\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "#         seq_det = self.seq.to_deterministic()\n",
    "        \n",
    "        #augmentation\n",
    "        aug_img=img.copy().transpose((1, 2, 0))\n",
    "        aug_img = self.seq.augment_images([aug_img])[0]\n",
    "        aug_img=aug_img.transpose((2, 1, 0))\n",
    "        \n",
    "        #normalize\n",
    "        aug_img=aug_img/255\n",
    "        \n",
    "        return aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "7c0aeb64e2a7b651582a467d82079a2fda67c71b"
   },
   "outputs": [],
   "source": [
    "def get_aug_pipline(img_size, mode = 'train'):\n",
    "    if mode == 'train':\n",
    "        seq = iaa.Sequential([\n",
    "                    iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "                    iaa.SomeOf((1,None), [\n",
    "                            iaa.Fliplr(0.5), # horizontal flips\n",
    "                            iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                            # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                            # But we only blur about 50% of all images.\n",
    "                            iaa.Sometimes(0.5,\n",
    "                                iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                            ),\n",
    "                            # Strengthen or weaken the contrast in each image.\n",
    "                            iaa.ContrastNormalization((0.75, 1.5)),\n",
    "                            # Add gaussian noise.\n",
    "                            # For 50% of all images, we sample the noise once per pixel.\n",
    "                            # For the other 50% of all images, we sample the noise per pixel AND\n",
    "                            # channel. This can change the color (not only brightness) of the\n",
    "                            # pixels.\n",
    "                            iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "                            # Make some images brighter and some darker.\n",
    "                            # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                            # which can end up changing the color of the images.\n",
    "                            iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                            # Apply affine transformations to each image.\n",
    "                            # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                            iaa.Affine(\n",
    "                                scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                                translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                                rotate=(-20, 20),\n",
    "                                shear=(-8, 8)\n",
    "                            ),\n",
    "                        iaa.PiecewiseAffine(scale=(0.01, 0.05))\n",
    "                    ], random_order=True) # apply augmenters in random order\n",
    "                ], random_order=False)\n",
    "    else: #ie.val\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "        ], random_order=False)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "4c926ebe55fb37a7bfe3ffb2d6da2b145fb5f747"
   },
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(annotations, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "composed = {}\n",
    "composed['train'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'train'))])\n",
    "composed['val'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'val'))])\n",
    "\n",
    "image_datasets = {'train': ProteinDataset(train_set, img_path = PATH_TRAIN_IMG, transform=composed['train']),\n",
    "                 'val': ProteinDataset(val_set, img_path = PATH_TRAIN_IMG, transform=composed['val'])}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "e8c442abb721b3f65c4a7b076232757725311b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 24857, 'val': 6215}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "610b2e7a2e2b430673460bfd21e2940eca4a83b1"
   },
   "outputs": [],
   "source": [
    "#test dataset\n",
    "# ix = 10\n",
    "# tmp_img, tmp_tags  = image_datasets['train'][ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "116981e26006844aba80864a76434c9b0a445188"
   },
   "outputs": [],
   "source": [
    "#test dataloader\n",
    "# tmp_img, tmp_tags = next(iter(dataloaders['train']))\n",
    "# print('tmp_img shape: {}\\ntmp_tags: shape {}'.format(tmp_img.shape, tmp_tags.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "53926b18c61ec3d5f167ee905fcde5c0dc9289f5"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class RnetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = self._prep_backbone()\n",
    "        \n",
    "    def _prep_backbone(self):     \n",
    "        base_model = models.resnet34(pretrained=True)\n",
    "        removed = list(base_model.children())[1:-2]\n",
    "        backbone = nn.Sequential(*removed)\n",
    "#         for param in backbone.parameters():\n",
    "#             param.require_grad = False\n",
    "        return backbone\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p=0.5)\n",
    "        self.fc_2 = nn.Linear(512 * 7 * 7, 256)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(256)\n",
    "        self.dropout_2 = nn.Dropout(p=0.5)\n",
    "        self.fc_3 = nn.Linear(256, self.num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc_3(x)\n",
    "        return x\n",
    "\n",
    "# class CustomEntry(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#         nn.init.kaiming_normal_(self.conv_1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv_1(x)\n",
    "#         return x\n",
    "\n",
    "class CustomEntry(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = self._prep_layers()\n",
    "        \n",
    "    def _prep_layers(self):\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        original_entry_w = torch.tensor(list(model.children())[0].weight)\n",
    "        new_entry_w = torch.cat([original_entry_w, torch.zeros(size = (64,1,7,7))], 1)\n",
    "        \n",
    "        conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        conv_1.weight=conv_1.weight = torch.nn.Parameter(new_entry_w)\n",
    "        return conv_1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        return x\n",
    "    \n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.custom_entry = CustomEntry()\n",
    "        self.backbone = RnetBackbone()\n",
    "        self.custom_head = CustomHead(num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.custom_entry(x)\n",
    "        x = self.backbone(x)\n",
    "        x = self.custom_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "4ef191d711342bf7bce65d943f8629d03bcf26c1"
   },
   "outputs": [],
   "source": [
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        #f1 loss\n",
    "#         #prep y_true\n",
    "        y_true = y_true.float()\n",
    "\n",
    "        #prep y_pred\n",
    "        y_pred = torch.tensor(data = (torch.sigmoid(y_pred).ge(THRESHOLD)), dtype=torch.float, device=DEVICE, requires_grad=True)\n",
    "\n",
    "        #calculate loss\n",
    "        tp = (y_true * y_pred).sum(0).float()\n",
    "        # tn = ((1-y_true) * (1-y_pred)).sum(0).float()\n",
    "        fp = ((1-y_true) * y_pred).sum(0).float()\n",
    "        fn = (y_true * (1-y_pred)).sum(0).float()\n",
    "\n",
    "        p = tp / (tp + fp)\n",
    "        r = tp / (tp + fn)\n",
    "\n",
    "        f1 = 2*p*r / (p+r)\n",
    "        f1[torch.isnan(f1)] = 0\n",
    "        f1_loss = 1-f1.mean()\n",
    "#         print(f1_loss)\n",
    "        return f1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "cc00e0b447f5877e1c8f2c669a0776213c480892"
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        target = target.float()\n",
    "        \n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "34c786807f448f63f4244537f13ebca2a6b44ee2"
   },
   "outputs": [],
   "source": [
    "def prep_stats(y_pred, y_true):\n",
    "    #prep y_true\n",
    "    y_true_tfm = y_true.cpu().numpy().astype('uint8')\n",
    "    \n",
    "    #prep y_pred khot\n",
    "    y_pred_tfm = (torch.sigmoid(y_pred) > THRESHOLD).cpu().numpy().astype('uint8')\n",
    "    \n",
    "    return y_pred_tfm, y_true_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "7df1b550cc9567063a38437001eff118004b0370"
   },
   "outputs": [],
   "source": [
    "def calc_stats(y_pred, y_true, stats = 'accurancy'):\n",
    "    if stats == 'accuracy':\n",
    "        stat_value = accuracy_score(y_true, y_pred)\n",
    "    elif stats == 'precision':\n",
    "        stat_value = precision_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'recall':\n",
    "        stat_value = recall_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'f1':\n",
    "        stat_value = f1_score(y_true, y_pred, average = 'macro')\n",
    "    else:\n",
    "        stat_value = 0\n",
    "    return stat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "467bc143b3e21ddb3674f77f2c78287c9bc3684c"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5, init_steps = 0):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    steps = init_steps\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_y_true = []\n",
    "            running_y_pred = []\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets= targets.to(DEVICE)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    y_pred_tfm, y_true_tfm = prep_stats(outputs, targets)\n",
    "                    running_y_pred.append(y_pred_tfm)\n",
    "                    running_y_true.append(y_true_tfm)\n",
    "                    \n",
    "                    #export step stats duing training phase\n",
    "                    if phase == 'train':\n",
    "                        record_tb(phase, 'loss', loss.cpu().data.numpy(), steps)\n",
    "                        record_tb(phase, 'accuracy', calc_stats(y_pred_tfm, y_true_tfm, stats = 'accurancy'), steps)\n",
    "                        record_tb(phase, 'precision', calc_stats(y_pred_tfm, y_true_tfm, stats = 'precision'), steps)\n",
    "                        record_tb(phase, 'recall', calc_stats(y_pred_tfm, y_true_tfm, stats = 'recall'), steps)\n",
    "                        record_tb(phase, 'f1', calc_stats(y_pred_tfm, y_true_tfm, stats = 'f1'), steps)\n",
    "                        steps += 1\n",
    "                        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            #calc epoch stats\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = accuracy_score(np.vstack(running_y_true), np.vstack(running_y_pred))\n",
    "            epoch_precision = precision_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_recall = recall_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_f1 = f1_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            \n",
    "            #export epoch stats duing training phase\n",
    "            if phase == 'val':\n",
    "                record_tb(phase, 'loss', epoch_loss, steps)\n",
    "                record_tb(phase, 'accuracy', epoch_acc, steps)\n",
    "                record_tb(phase, 'precision', epoch_precision, steps)\n",
    "                record_tb(phase, 'recall', epoch_recall, steps)\n",
    "                record_tb(phase, 'f1', epoch_f1, steps)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Percision: {:.4f} Recall {:.4f} F1 {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "2f201122c590638f86357241d2df7204e9712213"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = CustomNet(num_class=NUM_CLASSES)\n",
    "model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "criterion = FocalLoss()\n",
    "\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "57023ae1b0a357229aca85009dd7d38eb574e500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3948 Acc: 0.0429 Percision: 0.0773 Recall 0.0293 F1 0.0384\n",
      "val Loss: 1.2534 Acc: 0.0606 Percision: 0.1090 Recall 0.0306 F1 0.0364\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.2549 Acc: 0.0554 Percision: 0.1162 Recall 0.0311 F1 0.0375\n",
      "val Loss: 2.9795 Acc: 0.1045 Percision: 0.0870 Recall 0.0525 F1 0.0464\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.2392 Acc: 0.0612 Percision: 0.1765 Recall 0.0346 F1 0.0420\n",
      "val Loss: 2.1021 Acc: 0.0915 Percision: 0.0860 Recall 0.0438 F1 0.0429\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.2297 Acc: 0.0627 Percision: 0.1937 Recall 0.0359 F1 0.0437\n",
      "val Loss: 1.5234 Acc: 0.1099 Percision: 0.1046 Recall 0.0584 F1 0.0577\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.2166 Acc: 0.0701 Percision: 0.1781 Recall 0.0403 F1 0.0511\n",
      "val Loss: 1.3067 Acc: 0.1036 Percision: 0.1616 Recall 0.0496 F1 0.0553\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.1990 Acc: 0.0764 Percision: 0.1746 Recall 0.0443 F1 0.0570\n",
      "val Loss: 1.1526 Acc: 0.1099 Percision: 0.1900 Recall 0.0596 F1 0.0708\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.1945 Acc: 0.0764 Percision: 0.1885 Recall 0.0452 F1 0.0584\n",
      "val Loss: 1.1715 Acc: 0.0841 Percision: 0.2531 Recall 0.0474 F1 0.0616\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.1856 Acc: 0.0830 Percision: 0.2350 Recall 0.0487 F1 0.0638\n",
      "val Loss: 1.1381 Acc: 0.1099 Percision: 0.1608 Recall 0.0530 F1 0.0610\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.1768 Acc: 0.0821 Percision: 0.2142 Recall 0.0493 F1 0.0643\n",
      "val Loss: 1.2881 Acc: 0.1215 Percision: 0.1819 Recall 0.0708 F1 0.0775\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.1738 Acc: 0.0879 Percision: 0.2534 Recall 0.0517 F1 0.0681\n",
      "val Loss: 1.6022 Acc: 0.1007 Percision: 0.1431 Recall 0.0514 F1 0.0610\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.1454 Acc: 0.0904 Percision: 0.2981 Recall 0.0522 F1 0.0677\n",
      "val Loss: 1.4799 Acc: 0.1057 Percision: 0.1872 Recall 0.0559 F1 0.0702\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.1359 Acc: 0.0923 Percision: 0.2723 Recall 0.0542 F1 0.0710\n",
      "val Loss: 1.0921 Acc: 0.1207 Percision: 0.2145 Recall 0.0633 F1 0.0782\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.1315 Acc: 0.0933 Percision: 0.3285 Recall 0.0571 F1 0.0758\n",
      "val Loss: 1.1597 Acc: 0.1203 Percision: 0.2296 Recall 0.0645 F1 0.0786\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.1292 Acc: 0.0938 Percision: 0.3182 Recall 0.0575 F1 0.0762\n",
      "val Loss: 1.2995 Acc: 0.1221 Percision: 0.2066 Recall 0.0653 F1 0.0785\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.1247 Acc: 0.0941 Percision: 0.2725 Recall 0.0582 F1 0.0776\n",
      "val Loss: 1.2914 Acc: 0.1244 Percision: 0.2347 Recall 0.0686 F1 0.0861\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.1234 Acc: 0.0966 Percision: 0.3205 Recall 0.0594 F1 0.0789\n",
      "val Loss: 1.3580 Acc: 0.1208 Percision: 0.2273 Recall 0.0673 F1 0.0829\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.1196 Acc: 0.0980 Percision: 0.2928 Recall 0.0595 F1 0.0789\n",
      "val Loss: 1.2236 Acc: 0.1224 Percision: 0.2438 Recall 0.0704 F1 0.0881\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.1182 Acc: 0.0987 Percision: 0.2951 Recall 0.0611 F1 0.0817\n",
      "val Loss: 1.4674 Acc: 0.1305 Percision: 0.2057 Recall 0.0726 F1 0.0888\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.1160 Acc: 0.1004 Percision: 0.2945 Recall 0.0621 F1 0.0832\n",
      "val Loss: 1.1039 Acc: 0.1227 Percision: 0.2354 Recall 0.0710 F1 0.0889\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.1140 Acc: 0.1007 Percision: 0.2864 Recall 0.0626 F1 0.0843\n",
      "val Loss: 1.3692 Acc: 0.1258 Percision: 0.3034 Recall 0.0734 F1 0.0949\n",
      "\n",
      "Training complete in 102m 37s\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=base_lr)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 10 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "#Freeze backbone\n",
    "for param in model_ft.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_ft, steps = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20, init_steps=steps)\n",
    "\n",
    "#save intermediate model\n",
    "torch.save(model_ft.state_dict(), 'M17_20181106_stage_1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "da3c4971f0cfef2943b41c6db649ca4127ad1453"
   },
   "outputs": [],
   "source": [
    "#Unfreeze everything\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Different learning rate for different layers\n",
    "optimizer_ft = optim.Adam([\n",
    "    {'params': model_ft.custom_entry.parameters(), 'lr': base_lr/3},\n",
    "    {'params': model_ft.backbone.parameters(), 'lr': base_lr/10},\n",
    "    {'params': model_ft.custom_head.parameters()},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "06eda9ec601b47a0d7d32e5afc8317f16b6ddd7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3249 Acc: 0.0175 Percision: 0.0975 Recall 0.0104 F1 0.0168\n",
      "val Loss: 1.3526 Acc: 0.0614 Percision: 0.0537 Recall 0.0269 F1 0.0328\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.2609 Acc: 0.0506 Percision: 0.1003 Recall 0.0277 F1 0.0336\n",
      "val Loss: 1.2845 Acc: 0.0833 Percision: 0.0733 Recall 0.0364 F1 0.0308\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.2327 Acc: 0.0604 Percision: 0.1927 Recall 0.0345 F1 0.0410\n",
      "val Loss: 1.2034 Acc: 0.0747 Percision: 0.0887 Recall 0.0296 F1 0.0303\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.2017 Acc: 0.0733 Percision: 0.1600 Recall 0.0413 F1 0.0527\n",
      "val Loss: 1.1601 Acc: 0.0921 Percision: 0.1227 Recall 0.0454 F1 0.0492\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.1665 Acc: 0.0879 Percision: 0.1870 Recall 0.0520 F1 0.0698\n",
      "val Loss: 1.1429 Acc: 0.0991 Percision: 0.1426 Recall 0.0610 F1 0.0716\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.1339 Acc: 0.1071 Percision: 0.2987 Recall 0.0697 F1 0.0947\n",
      "val Loss: 1.1573 Acc: 0.1553 Percision: 0.2345 Recall 0.0947 F1 0.1211\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.1010 Acc: 0.1284 Percision: 0.2652 Recall 0.0866 F1 0.1152\n",
      "val Loss: 1.0467 Acc: 0.1564 Percision: 0.2990 Recall 0.1153 F1 0.1476\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.0770 Acc: 0.1452 Percision: 0.3161 Recall 0.0995 F1 0.1322\n",
      "val Loss: 1.1667 Acc: 0.1820 Percision: 0.2532 Recall 0.1268 F1 0.1589\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.0548 Acc: 0.1550 Percision: 0.3371 Recall 0.1095 F1 0.1443\n",
      "val Loss: 0.9596 Acc: 0.2107 Percision: 0.2995 Recall 0.1312 F1 0.1657\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.0333 Acc: 0.1722 Percision: 0.3484 Recall 0.1209 F1 0.1594\n",
      "val Loss: 1.0158 Acc: 0.2159 Percision: 0.3474 Recall 0.1436 F1 0.1811\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.9658 Acc: 0.2070 Percision: 0.4056 Recall 0.1473 F1 0.1914\n",
      "val Loss: 3.1295 Acc: 0.2756 Percision: 0.3391 Recall 0.1791 F1 0.2169\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.9535 Acc: 0.2159 Percision: 0.4195 Recall 0.1540 F1 0.1986\n",
      "val Loss: 0.9953 Acc: 0.2835 Percision: 0.3825 Recall 0.1799 F1 0.2191\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.9415 Acc: 0.2230 Percision: 0.4303 Recall 0.1598 F1 0.2069\n",
      "val Loss: 0.8599 Acc: 0.2874 Percision: 0.4060 Recall 0.1854 F1 0.2277\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.9328 Acc: 0.2300 Percision: 0.4286 Recall 0.1660 F1 0.2128\n",
      "val Loss: 1.5676 Acc: 0.2859 Percision: 0.4022 Recall 0.1919 F1 0.2381\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.9303 Acc: 0.2338 Percision: 0.4355 Recall 0.1677 F1 0.2169\n",
      "val Loss: 0.8603 Acc: 0.2908 Percision: 0.4741 Recall 0.1934 F1 0.2418\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.9197 Acc: 0.2420 Percision: 0.4359 Recall 0.1737 F1 0.2235\n",
      "val Loss: 0.9017 Acc: 0.2967 Percision: 0.4665 Recall 0.2021 F1 0.2520\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.9172 Acc: 0.2394 Percision: 0.4374 Recall 0.1753 F1 0.2253\n",
      "val Loss: 0.8428 Acc: 0.2938 Percision: 0.4741 Recall 0.2031 F1 0.2492\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.9115 Acc: 0.2479 Percision: 0.4804 Recall 0.1808 F1 0.2322\n",
      "val Loss: 0.8365 Acc: 0.2925 Percision: 0.4708 Recall 0.2000 F1 0.2491\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.9091 Acc: 0.2508 Percision: 0.4746 Recall 0.1846 F1 0.2375\n",
      "val Loss: 0.8496 Acc: 0.3072 Percision: 0.4291 Recall 0.2100 F1 0.2600\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.9015 Acc: 0.2537 Percision: 0.4545 Recall 0.1858 F1 0.2374\n",
      "val Loss: 0.8304 Acc: 0.3117 Percision: 0.4668 Recall 0.2147 F1 0.2638\n",
      "\n",
      "Training complete in 139m 6s\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.9931 Acc: 0.1980 Percision: 0.3930 Recall 0.1486 F1 0.1965\n",
      "val Loss: 0.9281 Acc: 0.2576 Percision: 0.4380 Recall 0.1838 F1 0.2251\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.9842 Acc: 0.2059 Percision: 0.3867 Recall 0.1557 F1 0.2036\n",
      "val Loss: 6.4736 Acc: 0.2627 Percision: 0.4075 Recall 0.1666 F1 0.1988\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.9734 Acc: 0.2121 Percision: 0.4445 Recall 0.1657 F1 0.2167\n",
      "val Loss: 1.2074 Acc: 0.2247 Percision: 0.3338 Recall 0.1656 F1 0.1777\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.9660 Acc: 0.2185 Percision: 0.4109 Recall 0.1698 F1 0.2213\n",
      "val Loss: 1.4402 Acc: 0.2394 Percision: 0.4019 Recall 0.1832 F1 0.2324\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.9574 Acc: 0.2223 Percision: 0.4067 Recall 0.1743 F1 0.2267\n",
      "val Loss: 0.9383 Acc: 0.2722 Percision: 0.3862 Recall 0.2131 F1 0.2539\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.9504 Acc: 0.2271 Percision: 0.4421 Recall 0.1794 F1 0.2337\n",
      "val Loss: 0.9261 Acc: 0.2556 Percision: 0.4385 Recall 0.1921 F1 0.2277\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.9444 Acc: 0.2312 Percision: 0.4191 Recall 0.1835 F1 0.2368\n",
      "val Loss: 0.8914 Acc: 0.2780 Percision: 0.4147 Recall 0.1948 F1 0.2352\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.9341 Acc: 0.2390 Percision: 0.4435 Recall 0.1917 F1 0.2478\n",
      "val Loss: 0.8849 Acc: 0.2954 Percision: 0.4192 Recall 0.2311 F1 0.2714\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.9322 Acc: 0.2395 Percision: 0.4315 Recall 0.1939 F1 0.2498\n",
      "val Loss: 0.9761 Acc: 0.2763 Percision: 0.4752 Recall 0.2221 F1 0.2755\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.9236 Acc: 0.2472 Percision: 0.4352 Recall 0.1987 F1 0.2550\n",
      "val Loss: 1.0224 Acc: 0.2780 Percision: 0.4708 Recall 0.2444 F1 0.2862\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.8651 Acc: 0.2785 Percision: 0.4785 Recall 0.2243 F1 0.2843\n",
      "val Loss: 0.7831 Acc: 0.3450 Percision: 0.5143 Recall 0.2478 F1 0.3005\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.8487 Acc: 0.2894 Percision: 0.4882 Recall 0.2319 F1 0.2909\n",
      "val Loss: 0.7772 Acc: 0.3457 Percision: 0.5048 Recall 0.2557 F1 0.3085\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.8436 Acc: 0.2940 Percision: 0.4970 Recall 0.2348 F1 0.2934\n",
      "val Loss: 0.9890 Acc: 0.3534 Percision: 0.4889 Recall 0.2603 F1 0.3122\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.8370 Acc: 0.2974 Percision: 0.5276 Recall 0.2396 F1 0.2999\n",
      "val Loss: 0.7699 Acc: 0.3566 Percision: 0.5149 Recall 0.2601 F1 0.3154\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.8344 Acc: 0.3022 Percision: 0.4864 Recall 0.2386 F1 0.2970\n",
      "val Loss: 0.7766 Acc: 0.3599 Percision: 0.4959 Recall 0.2630 F1 0.3150\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.8303 Acc: 0.3037 Percision: 0.5003 Recall 0.2440 F1 0.3035\n",
      "val Loss: 0.7683 Acc: 0.3552 Percision: 0.4985 Recall 0.2593 F1 0.3123\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.8273 Acc: 0.3006 Percision: 0.4830 Recall 0.2415 F1 0.3013\n",
      "val Loss: 0.7936 Acc: 0.3600 Percision: 0.5061 Recall 0.2661 F1 0.3210\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.8243 Acc: 0.3108 Percision: 0.5108 Recall 0.2452 F1 0.3052\n",
      "val Loss: 0.7641 Acc: 0.3592 Percision: 0.5450 Recall 0.2609 F1 0.3153\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.8230 Acc: 0.3073 Percision: 0.5580 Recall 0.2477 F1 0.3085\n",
      "val Loss: 0.7658 Acc: 0.3616 Percision: 0.5063 Recall 0.2653 F1 0.3179\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.8206 Acc: 0.3097 Percision: 0.5401 Recall 0.2468 F1 0.3077\n",
      "val Loss: 0.7735 Acc: 0.3584 Percision: 0.5119 Recall 0.2678 F1 0.3229\n",
      "\n",
      "Training complete in 138m 7s\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.9077 Acc: 0.2585 Percision: 0.4534 Recall 0.2113 F1 0.2700\n",
      "val Loss: 0.8681 Acc: 0.2917 Percision: 0.4462 Recall 0.2245 F1 0.2681\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.9040 Acc: 0.2573 Percision: 0.4855 Recall 0.2137 F1 0.2727\n",
      "val Loss: 0.9310 Acc: 0.2618 Percision: 0.4366 Recall 0.2108 F1 0.2367\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.8962 Acc: 0.2636 Percision: 0.5609 Recall 0.2240 F1 0.2886\n",
      "val Loss: 0.8501 Acc: 0.3201 Percision: 0.4324 Recall 0.2472 F1 0.2906\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.8964 Acc: 0.2645 Percision: 0.5651 Recall 0.2222 F1 0.2861\n",
      "val Loss: 1.2662 Acc: 0.3339 Percision: 0.4579 Recall 0.2647 F1 0.3145\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.8918 Acc: 0.2684 Percision: 0.4778 Recall 0.2200 F1 0.2794\n",
      "val Loss: 8.0654 Acc: 0.2888 Percision: 0.4840 Recall 0.2277 F1 0.2816\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.8855 Acc: 0.2726 Percision: 0.5541 Recall 0.2307 F1 0.2964\n",
      "val Loss: 0.7939 Acc: 0.3381 Percision: 0.5035 Recall 0.2659 F1 0.3201\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.8824 Acc: 0.2716 Percision: 0.5047 Recall 0.2290 F1 0.2916\n",
      "val Loss: 0.8114 Acc: 0.3313 Percision: 0.5324 Recall 0.2725 F1 0.3340\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.8775 Acc: 0.2764 Percision: 0.5496 Recall 0.2366 F1 0.3026\n",
      "val Loss: 0.8470 Acc: 0.2916 Percision: 0.4759 Recall 0.2292 F1 0.2925\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.8660 Acc: 0.2848 Percision: 0.5448 Recall 0.2419 F1 0.3073\n",
      "val Loss: 0.8176 Acc: 0.3281 Percision: 0.5449 Recall 0.2616 F1 0.3214\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.8688 Acc: 0.2790 Percision: 0.5437 Recall 0.2425 F1 0.3086\n",
      "val Loss: 0.9878 Acc: 0.3441 Percision: 0.4307 Recall 0.2783 F1 0.3168\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.8065 Acc: 0.3189 Percision: 0.6337 Recall 0.2729 F1 0.3438\n",
      "val Loss: 0.7702 Acc: 0.3837 Percision: 0.5143 Recall 0.2980 F1 0.3604\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.7875 Acc: 0.3309 Percision: 0.6403 Recall 0.2846 F1 0.3576\n",
      "val Loss: 0.7296 Acc: 0.3876 Percision: 0.5686 Recall 0.3075 F1 0.3702\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.7853 Acc: 0.3342 Percision: 0.5740 Recall 0.2803 F1 0.3471\n",
      "val Loss: 0.7285 Acc: 0.3858 Percision: 0.5235 Recall 0.3057 F1 0.3668\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.7746 Acc: 0.3392 Percision: 0.5619 Recall 0.2824 F1 0.3475\n",
      "val Loss: 0.7585 Acc: 0.3895 Percision: 0.5744 Recall 0.3197 F1 0.3864\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.7758 Acc: 0.3379 Percision: 0.6469 Recall 0.2920 F1 0.3656\n",
      "val Loss: 0.7272 Acc: 0.3884 Percision: 0.6092 Recall 0.3068 F1 0.3724\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.7704 Acc: 0.3435 Percision: 0.5795 Recall 0.2886 F1 0.3569\n",
      "val Loss: 0.7243 Acc: 0.3895 Percision: 0.5891 Recall 0.3126 F1 0.3818\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.7671 Acc: 0.3476 Percision: 0.6062 Recall 0.2966 F1 0.3675\n",
      "val Loss: 0.7247 Acc: 0.3903 Percision: 0.6043 Recall 0.3170 F1 0.3862\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.7652 Acc: 0.3476 Percision: 0.6311 Recall 0.2975 F1 0.3711\n",
      "val Loss: 0.7222 Acc: 0.3932 Percision: 0.6602 Recall 0.3182 F1 0.3880\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.7611 Acc: 0.3487 Percision: 0.6348 Recall 0.3046 F1 0.3795\n",
      "val Loss: 0.7218 Acc: 0.3990 Percision: 0.6534 Recall 0.3147 F1 0.3806\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.7618 Acc: 0.3460 Percision: 0.6135 Recall 0.2954 F1 0.3661\n",
      "val Loss: 0.7376 Acc: 0.4003 Percision: 0.6364 Recall 0.3238 F1 0.3908\n",
      "\n",
      "Training complete in 138m 6s\n"
     ]
    }
   ],
   "source": [
    "#lr clcying\n",
    "max_cycle = 3\n",
    "for cycle in range(max_cycle):\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=base_lr)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 10 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "    model_ft, steps = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                           num_epochs=20, init_steps=steps)\n",
    "\n",
    "    #save intermediate model\n",
    "    torch.save(model_ft.state_dict(), 'M17_20181106_cycle_stage_{}.model'.format(cycle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
