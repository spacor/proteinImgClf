{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "c21a5bb776b463e9488f1928b636be7b5a92a1c2"
   },
   "outputs": [],
   "source": [
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# base_path = r'../input'\n",
    "base_path = r'input'\n",
    "PATH_TRAIN_ANNO = os.path.join(base_path, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(base_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "583ead53ccf420ab4290230a0a17cc3b6c62c74d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    USE_TENSORBOARD = True\n",
    "    writer = SummaryWriter()\n",
    "except:\n",
    "    USE_TENSORBOARD = False\n",
    "    print('No tensorboard X')\n",
    "\n",
    "def record_tb(phase, tag, value, global_step):\n",
    "    if USE_TENSORBOARD is True:\n",
    "        writer.add_scalar('{phase}/{tag}'.format(phase=phase, tag=tag), value, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7a95c899247b666f9235e3100a569744c46bf943"
   },
   "outputs": [],
   "source": [
    "# os.listdir(PATH_TRAIN_IMG)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e85715fa2a9217474fc039c2b399c9b33490689a"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28\n",
    "MAX_TAGS = 5\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "VAL_SIZE =0.2\n",
    "THRESHOLD = 0.5\n",
    "SAMPLES = 1\n",
    "base_lr = 0.01\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7e81577b2c725960293a5cfabb29e0d46d66834c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 31072\n",
      "[('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', [16, 0]),\n",
      " ('000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', [7, 1, 2, 0]),\n",
      " ('000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', [5])]\n"
     ]
    }
   ],
   "source": [
    "def get_transform_anno(annotation_path, img_path):\n",
    "    df = pd.read_csv(annotation_path)\n",
    "    annotations = []\n",
    "    for i, row in df.iterrows():\n",
    "        rcd_id = row['Id']\n",
    "        rcd_cate =  [int(j) for j in row['Target'].split()]\n",
    "        annotations.append((rcd_id, rcd_cate))\n",
    "    return annotations\n",
    "#get annotations\n",
    "annotations = get_transform_anno(PATH_TRAIN_ANNO, PATH_TRAIN_IMG)\n",
    "sample_size = int(len(annotations) * SAMPLES)\n",
    "print('sample size: {}'.format(sample_size))\n",
    "annotations = annotations[:sample_size]\n",
    "pprint(annotations[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "878d1a4d5d29884cc313258347df1ee630abae1a"
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, img_meta, img_path, transform = None):\n",
    "        self.img_meta = img_meta\n",
    "        self.transform = transform\n",
    "        self.channels = ['red', 'blue', 'yellow', 'green']\n",
    "        self.img_path = img_path\n",
    "        self.mlb = MultiLabelBinarizer(classes=range(0,NUM_CLASSES))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id, img_tags= self.img_meta[idx]\n",
    "        ch = []\n",
    "        img_file_template = '{}_{}.png'\n",
    "        for c in self.channels:\n",
    "            ch.append(io.imread(os.path.join(self.img_path, img_file_template.format(img_id, c))))\n",
    "        img = np.stack(ch)\n",
    "\n",
    "        #augmentation\n",
    "        if bool(self.transform) is True:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        #binarize\n",
    "        img_tags = self.mlb.fit_transform([img_tags]).squeeze()\n",
    "        \n",
    "        #transform to tensor\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img_tags = torch.from_numpy(img_tags)\n",
    "        \n",
    "        output = (img, img_tags)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "af583f0882e55fd31a3df230822ac86f99e25f4c"
   },
   "outputs": [],
   "source": [
    "class ImgTfm:\n",
    "    def __init__(self, aug_pipline = None):\n",
    "        self.seq = aug_pipline\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "#         seq_det = self.seq.to_deterministic()\n",
    "        \n",
    "        #augmentation\n",
    "        aug_img=img.copy().transpose((1, 2, 0))\n",
    "        aug_img = self.seq.augment_images([aug_img])[0]\n",
    "        aug_img=aug_img.transpose((2, 1, 0))\n",
    "        \n",
    "        #normalize\n",
    "        aug_img=aug_img/255\n",
    "        \n",
    "        return aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "7c0aeb64e2a7b651582a467d82079a2fda67c71b"
   },
   "outputs": [],
   "source": [
    "def get_aug_pipline(img_size, mode = 'train'):\n",
    "    if mode == 'train':\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "            iaa.Sequential([\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Affine(\n",
    "                    rotate=(-20, 20),\n",
    "                )\n",
    "            ], random_order=True) # apply augmenters in random order\n",
    "        ], random_order=False)\n",
    "    else: #ie.val\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "        ], random_order=False)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "4c926ebe55fb37a7bfe3ffb2d6da2b145fb5f747"
   },
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(annotations, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "composed = {}\n",
    "composed['train'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'train'))])\n",
    "composed['val'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'val'))])\n",
    "\n",
    "image_datasets = {'train': ProteinDataset(train_set, img_path = PATH_TRAIN_IMG, transform=composed['train']),\n",
    "                 'val': ProteinDataset(val_set, img_path = PATH_TRAIN_IMG, transform=composed['val'])}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "e8c442abb721b3f65c4a7b076232757725311b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 24857, 'val': 6215}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "610b2e7a2e2b430673460bfd21e2940eca4a83b1"
   },
   "outputs": [],
   "source": [
    "#test dataset\n",
    "# ix = 10\n",
    "# tmp_img, tmp_tags  = image_datasets['train'][ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "116981e26006844aba80864a76434c9b0a445188"
   },
   "outputs": [],
   "source": [
    "#test dataloader\n",
    "# tmp_img, tmp_tags = next(iter(dataloaders['train']))\n",
    "# print('tmp_img shape: {}\\ntmp_tags: shape {}'.format(tmp_img.shape, tmp_tags.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "53926b18c61ec3d5f167ee905fcde5c0dc9289f5"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class RnetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = self._prep_backbone()\n",
    "        \n",
    "    def _prep_backbone(self):     \n",
    "        base_model = models.resnet34(pretrained=True)\n",
    "        removed = list(base_model.children())[1:-2]\n",
    "        backbone = nn.Sequential(*removed)\n",
    "#         for param in backbone.parameters():\n",
    "#             param.require_grad = False\n",
    "        return backbone\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p=0.5)\n",
    "        self.fc_2 = nn.Linear(512 * 7 * 7, 256)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(256)\n",
    "        self.dropout_2 = nn.Dropout(p=0.5)\n",
    "        self.fc_3 = nn.Linear(256, self.num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc_3(x)\n",
    "        return x\n",
    "\n",
    "# class CustomEntry(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#         nn.init.kaiming_normal_(self.conv_1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv_1(x)\n",
    "#         return x\n",
    "\n",
    "class CustomEntry(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = self._prep_layers()\n",
    "        \n",
    "    def _prep_layers(self):\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        original_entry_w = torch.tensor(list(model.children())[0].weight)\n",
    "        new_entry_w = torch.cat([original_entry_w, torch.zeros(size = (64,1,7,7))], 1)\n",
    "        \n",
    "        conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        conv_1.weight=conv_1.weight = torch.nn.Parameter(new_entry_w)\n",
    "        return conv_1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        return x\n",
    "    \n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.custom_entry = CustomEntry()\n",
    "        self.backbone = RnetBackbone()\n",
    "        self.custom_head = CustomHead(num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.custom_entry(x)\n",
    "        x = self.backbone(x)\n",
    "        x = self.custom_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "4ef191d711342bf7bce65d943f8629d03bcf26c1"
   },
   "outputs": [],
   "source": [
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        #f1 loss\n",
    "#         #prep y_true\n",
    "        y_true = y_true.float()\n",
    "\n",
    "        #prep y_pred\n",
    "        y_pred = torch.tensor(data = (torch.sigmoid(y_pred).ge(THRESHOLD)), dtype=torch.float, device=DEVICE, requires_grad=True)\n",
    "\n",
    "        #calculate loss\n",
    "        tp = (y_true * y_pred).sum(0).float()\n",
    "        # tn = ((1-y_true) * (1-y_pred)).sum(0).float()\n",
    "        fp = ((1-y_true) * y_pred).sum(0).float()\n",
    "        fn = (y_true * (1-y_pred)).sum(0).float()\n",
    "\n",
    "        p = tp / (tp + fp)\n",
    "        r = tp / (tp + fn)\n",
    "\n",
    "        f1 = 2*p*r / (p+r)\n",
    "        f1[torch.isnan(f1)] = 0\n",
    "        f1_loss = 1-f1.mean()\n",
    "#         print(f1_loss)\n",
    "        return f1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "cc00e0b447f5877e1c8f2c669a0776213c480892"
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        target = target.float()\n",
    "        \n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "34c786807f448f63f4244537f13ebca2a6b44ee2"
   },
   "outputs": [],
   "source": [
    "def prep_stats(y_pred, y_true):\n",
    "    #prep y_true\n",
    "    y_true_tfm = y_true.cpu().numpy().astype('uint8')\n",
    "    \n",
    "    #prep y_pred khot\n",
    "    y_pred_tfm = (torch.sigmoid(y_pred) > THRESHOLD).cpu().numpy().astype('uint8')\n",
    "    \n",
    "    return y_pred_tfm, y_true_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "7df1b550cc9567063a38437001eff118004b0370"
   },
   "outputs": [],
   "source": [
    "def calc_stats(y_pred, y_true, stats = 'accurancy'):\n",
    "    if stats == 'accuracy':\n",
    "        stat_value = accuracy_score(y_true, y_pred)\n",
    "    elif stats == 'precision':\n",
    "        stat_value = precision_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'recall':\n",
    "        stat_value = recall_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'f1':\n",
    "        stat_value = f1_score(y_true, y_pred, average = 'macro')\n",
    "    else:\n",
    "        stat_value = 0\n",
    "    return stat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "467bc143b3e21ddb3674f77f2c78287c9bc3684c"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5, init_steps = 0):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    steps = init_steps\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_y_true = []\n",
    "            running_y_pred = []\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets= targets.to(DEVICE)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    y_pred_tfm, y_true_tfm = prep_stats(outputs, targets)\n",
    "                    running_y_pred.append(y_pred_tfm)\n",
    "                    running_y_true.append(y_true_tfm)\n",
    "                    \n",
    "                    #export step stats duing training phase\n",
    "                    if phase == 'train':\n",
    "                        record_tb(phase, 'loss', loss.cpu().data.numpy(), steps)\n",
    "                        record_tb(phase, 'accuracy', calc_stats(y_pred_tfm, y_true_tfm, stats = 'accurancy'), steps)\n",
    "                        record_tb(phase, 'precision', calc_stats(y_pred_tfm, y_true_tfm, stats = 'precision'), steps)\n",
    "                        record_tb(phase, 'recall', calc_stats(y_pred_tfm, y_true_tfm, stats = 'recall'), steps)\n",
    "                        record_tb(phase, 'f1', calc_stats(y_pred_tfm, y_true_tfm, stats = 'f1'), steps)\n",
    "                        steps += 1\n",
    "                        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            #calc epoch stats\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = accuracy_score(np.vstack(running_y_true), np.vstack(running_y_pred))\n",
    "            epoch_precision = precision_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_recall = recall_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_f1 = f1_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            \n",
    "            #export epoch stats duing training phase\n",
    "            if phase == 'val':\n",
    "                record_tb(phase, 'loss', epoch_loss, steps)\n",
    "                record_tb(phase, 'accuracy', epoch_acc, steps)\n",
    "                record_tb(phase, 'precision', epoch_precision, steps)\n",
    "                record_tb(phase, 'recall', epoch_recall, steps)\n",
    "                record_tb(phase, 'f1', epoch_f1, steps)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Percision: {:.4f} Recall {:.4f} F1 {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "2f201122c590638f86357241d2df7204e9712213"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = CustomNet(num_class=NUM_CLASSES)\n",
    "model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "criterion = FocalLoss()\n",
    "\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "57023ae1b0a357229aca85009dd7d38eb574e500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3786 Acc: 0.0472 Percision: 0.0894 Recall 0.0370 F1 0.0467\n",
      "val Loss: 1.4226 Acc: 0.0585 Percision: 0.0956 Recall 0.0342 F1 0.0408\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.2409 Acc: 0.0611 Percision: 0.1058 Recall 0.0363 F1 0.0438\n",
      "val Loss: 1.2026 Acc: 0.0499 Percision: 0.0816 Recall 0.0254 F1 0.0313\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.2180 Acc: 0.0650 Percision: 0.1422 Recall 0.0389 F1 0.0469\n",
      "val Loss: 1.1892 Acc: 0.0488 Percision: 0.1012 Recall 0.0285 F1 0.0382\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.2002 Acc: 0.0729 Percision: 0.1925 Recall 0.0434 F1 0.0533\n",
      "val Loss: 1.5426 Acc: 0.0490 Percision: 0.1072 Recall 0.0246 F1 0.0313\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.1807 Acc: 0.0812 Percision: 0.2128 Recall 0.0489 F1 0.0616\n",
      "val Loss: 1.1358 Acc: 0.0968 Percision: 0.1778 Recall 0.0533 F1 0.0600\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.1626 Acc: 0.0871 Percision: 0.2594 Recall 0.0555 F1 0.0723\n",
      "val Loss: 1.3254 Acc: 0.1062 Percision: 0.1548 Recall 0.0557 F1 0.0664\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.1468 Acc: 0.0986 Percision: 0.2771 Recall 0.0615 F1 0.0809\n",
      "val Loss: 1.2014 Acc: 0.0660 Percision: 0.1639 Recall 0.0339 F1 0.0480\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.1346 Acc: 0.1038 Percision: 0.2732 Recall 0.0665 F1 0.0887\n",
      "val Loss: 1.7153 Acc: 0.1149 Percision: 0.2193 Recall 0.0594 F1 0.0740\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.1278 Acc: 0.1089 Percision: 0.3001 Recall 0.0687 F1 0.0919\n",
      "val Loss: 1.1064 Acc: 0.1273 Percision: 0.2858 Recall 0.0760 F1 0.1010\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.1141 Acc: 0.1090 Percision: 0.3545 Recall 0.0762 F1 0.1039\n",
      "val Loss: 1.1922 Acc: 0.1039 Percision: 0.3871 Recall 0.0581 F1 0.0804\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.0757 Acc: 0.1228 Percision: 0.3388 Recall 0.0803 F1 0.1091\n",
      "val Loss: 1.2080 Acc: 0.1337 Percision: 0.4380 Recall 0.0792 F1 0.1075\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.0634 Acc: 0.1279 Percision: 0.3392 Recall 0.0860 F1 0.1165\n",
      "val Loss: 1.1958 Acc: 0.1285 Percision: 0.3062 Recall 0.0788 F1 0.1066\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.0569 Acc: 0.1327 Percision: 0.3831 Recall 0.0886 F1 0.1204\n",
      "val Loss: 1.5570 Acc: 0.1369 Percision: 0.2944 Recall 0.0856 F1 0.1167\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.0549 Acc: 0.1340 Percision: 0.3913 Recall 0.0911 F1 0.1246\n",
      "val Loss: 1.1487 Acc: 0.1347 Percision: 0.3974 Recall 0.0836 F1 0.1161\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.0509 Acc: 0.1369 Percision: 0.3841 Recall 0.0929 F1 0.1271\n",
      "val Loss: 1.0591 Acc: 0.1392 Percision: 0.3851 Recall 0.0827 F1 0.1139\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.0441 Acc: 0.1377 Percision: 0.3794 Recall 0.0950 F1 0.1302\n",
      "val Loss: 1.1538 Acc: 0.1419 Percision: 0.3662 Recall 0.0883 F1 0.1206\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.0429 Acc: 0.1429 Percision: 0.4097 Recall 0.0972 F1 0.1332\n",
      "val Loss: 1.4180 Acc: 0.1414 Percision: 0.3577 Recall 0.0910 F1 0.1268\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.0399 Acc: 0.1403 Percision: 0.3980 Recall 0.0976 F1 0.1341\n",
      "val Loss: 1.0402 Acc: 0.1466 Percision: 0.4067 Recall 0.0906 F1 0.1248\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.0397 Acc: 0.1403 Percision: 0.4352 Recall 0.0992 F1 0.1371\n",
      "val Loss: 1.0403 Acc: 0.1482 Percision: 0.4429 Recall 0.0931 F1 0.1270\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.0358 Acc: 0.1447 Percision: 0.4010 Recall 0.1012 F1 0.1392\n",
      "val Loss: 1.0447 Acc: 0.1537 Percision: 0.4548 Recall 0.0947 F1 0.1299\n",
      "\n",
      "Training complete in 101m 54s\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=base_lr)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 10 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "#Freeze backbone\n",
    "for param in model_ft.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_ft, steps = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20, init_steps=steps)\n",
    "\n",
    "#save intermediate model\n",
    "torch.save(model_ft.state_dict(), 'M17_20181106_stage_1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "da3c4971f0cfef2943b41c6db649ca4127ad1453"
   },
   "outputs": [],
   "source": [
    "#Unfreeze everything\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Different learning rate for different layers\n",
    "optimizer_ft = optim.Adam([\n",
    "    {'params': model_ft.custom_entry.parameters(), 'lr': base_lr/3},\n",
    "    {'params': model_ft.backbone.parameters(), 'lr': base_lr/10},\n",
    "    {'params': model_ft.custom_head.parameters()},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "06eda9ec601b47a0d7d32e5afc8317f16b6ddd7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.2973 Acc: 0.0346 Percision: 0.1205 Recall 0.0176 F1 0.0255\n",
      "val Loss: 1.2386 Acc: 0.0921 Percision: 0.0599 Recall 0.0592 F1 0.0559\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.2277 Acc: 0.0675 Percision: 0.1336 Recall 0.0373 F1 0.0443\n",
      "val Loss: 1.3336 Acc: 0.0406 Percision: 0.0556 Recall 0.0307 F1 0.0275\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.1946 Acc: 0.0832 Percision: 0.1769 Recall 0.0509 F1 0.0643\n",
      "val Loss: 1.2844 Acc: 0.0957 Percision: 0.1357 Recall 0.0622 F1 0.0809\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.1443 Acc: 0.1039 Percision: 0.2030 Recall 0.0676 F1 0.0870\n",
      "val Loss: 1.1156 Acc: 0.1297 Percision: 0.2302 Recall 0.0734 F1 0.0896\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.1000 Acc: 0.1271 Percision: 0.2399 Recall 0.0827 F1 0.1070\n",
      "val Loss: 1.0792 Acc: 0.1435 Percision: 0.2085 Recall 0.0871 F1 0.1057\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.0824 Acc: 0.1388 Percision: 0.2701 Recall 0.0904 F1 0.1176\n",
      "val Loss: 1.2714 Acc: 0.1353 Percision: 0.2552 Recall 0.1141 F1 0.1386\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.0558 Acc: 0.1606 Percision: 0.2832 Recall 0.1092 F1 0.1409\n",
      "val Loss: 1.1458 Acc: 0.1620 Percision: 0.2585 Recall 0.1178 F1 0.1209\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.0259 Acc: 0.1809 Percision: 0.3413 Recall 0.1214 F1 0.1554\n",
      "val Loss: 1.0226 Acc: 0.1878 Percision: 0.2962 Recall 0.1212 F1 0.1422\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.0010 Acc: 0.1983 Percision: 0.3326 Recall 0.1339 F1 0.1692\n",
      "val Loss: 0.9785 Acc: 0.2270 Percision: 0.3240 Recall 0.1350 F1 0.1644\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.9826 Acc: 0.2045 Percision: 0.3839 Recall 0.1444 F1 0.1851\n",
      "val Loss: 0.9547 Acc: 0.2102 Percision: 0.3005 Recall 0.1306 F1 0.1631\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.9086 Acc: 0.2478 Percision: 0.4102 Recall 0.1718 F1 0.2176\n",
      "val Loss: 0.8590 Acc: 0.2769 Percision: 0.4219 Recall 0.1757 F1 0.2165\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.8838 Acc: 0.2630 Percision: 0.4327 Recall 0.1847 F1 0.2311\n",
      "val Loss: 0.8531 Acc: 0.2861 Percision: 0.3925 Recall 0.1837 F1 0.2239\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.8800 Acc: 0.2661 Percision: 0.4266 Recall 0.1885 F1 0.2355\n",
      "val Loss: 0.8444 Acc: 0.2916 Percision: 0.4397 Recall 0.1917 F1 0.2363\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.8680 Acc: 0.2713 Percision: 0.4641 Recall 0.1940 F1 0.2417\n",
      "val Loss: 0.8604 Acc: 0.2953 Percision: 0.4175 Recall 0.1931 F1 0.2360\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.8623 Acc: 0.2777 Percision: 0.4440 Recall 0.1992 F1 0.2489\n",
      "val Loss: 0.8680 Acc: 0.2887 Percision: 0.4304 Recall 0.1925 F1 0.2380\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.8581 Acc: 0.2807 Percision: 0.4527 Recall 0.2009 F1 0.2507\n",
      "val Loss: 0.8380 Acc: 0.3009 Percision: 0.3802 Recall 0.2046 F1 0.2485\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.8490 Acc: 0.2859 Percision: 0.5756 Recall 0.2097 F1 0.2617\n",
      "val Loss: 0.8235 Acc: 0.3059 Percision: 0.4296 Recall 0.2033 F1 0.2491\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.8462 Acc: 0.2874 Percision: 0.4497 Recall 0.2080 F1 0.2581\n",
      "val Loss: 0.8208 Acc: 0.3131 Percision: 0.4263 Recall 0.2104 F1 0.2545\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.8385 Acc: 0.2895 Percision: 0.5619 Recall 0.2167 F1 0.2705\n",
      "val Loss: 0.8145 Acc: 0.3180 Percision: 0.4920 Recall 0.2173 F1 0.2659\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.8346 Acc: 0.2966 Percision: 0.4689 Recall 0.2196 F1 0.2722\n",
      "val Loss: 0.8089 Acc: 0.3197 Percision: 0.4360 Recall 0.2153 F1 0.2631\n",
      "\n",
      "Training complete in 137m 53s\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.9371 Acc: 0.2370 Percision: 0.4344 Recall 0.1757 F1 0.2233\n",
      "val Loss: 0.9167 Acc: 0.2379 Percision: 0.4100 Recall 0.1510 F1 0.1939\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.9247 Acc: 0.2388 Percision: 0.4291 Recall 0.1827 F1 0.2327\n",
      "val Loss: 0.9049 Acc: 0.2632 Percision: 0.4056 Recall 0.1722 F1 0.2158\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.9115 Acc: 0.2499 Percision: 0.4584 Recall 0.1914 F1 0.2430\n",
      "val Loss: 4.5778 Acc: 0.2595 Percision: 0.4288 Recall 0.2004 F1 0.2490\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.9031 Acc: 0.2562 Percision: 0.4681 Recall 0.1999 F1 0.2544\n",
      "val Loss: 5.5182 Acc: 0.2803 Percision: 0.4383 Recall 0.1957 F1 0.2412\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.8942 Acc: 0.2650 Percision: 0.4536 Recall 0.2105 F1 0.2667\n",
      "val Loss: 4.0448 Acc: 0.2321 Percision: 0.3967 Recall 0.1893 F1 0.2412\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.8830 Acc: 0.2713 Percision: 0.4526 Recall 0.2151 F1 0.2716\n",
      "val Loss: 2.6402 Acc: 0.2750 Percision: 0.4386 Recall 0.2255 F1 0.2542\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.8749 Acc: 0.2801 Percision: 0.4969 Recall 0.2221 F1 0.2804\n",
      "val Loss: 0.8506 Acc: 0.3178 Percision: 0.4638 Recall 0.2318 F1 0.2809\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.8657 Acc: 0.2818 Percision: 0.4735 Recall 0.2297 F1 0.2891\n",
      "val Loss: 0.8700 Acc: 0.3048 Percision: 0.5170 Recall 0.2385 F1 0.2884\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.8652 Acc: 0.2841 Percision: 0.4568 Recall 0.2295 F1 0.2877\n",
      "val Loss: 0.8621 Acc: 0.3186 Percision: 0.4750 Recall 0.2275 F1 0.2677\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.8480 Acc: 0.2974 Percision: 0.4984 Recall 0.2398 F1 0.2996\n",
      "val Loss: 0.8993 Acc: 0.3264 Percision: 0.4628 Recall 0.2268 F1 0.2808\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.7767 Acc: 0.3404 Percision: 0.5682 Recall 0.2717 F1 0.3353\n",
      "val Loss: 0.7643 Acc: 0.3658 Percision: 0.5306 Recall 0.2666 F1 0.3262\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.7576 Acc: 0.3502 Percision: 0.6016 Recall 0.2848 F1 0.3510\n",
      "val Loss: 0.7557 Acc: 0.3678 Percision: 0.5515 Recall 0.2742 F1 0.3329\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.7512 Acc: 0.3586 Percision: 0.6249 Recall 0.2955 F1 0.3621\n",
      "val Loss: 0.7565 Acc: 0.3716 Percision: 0.5236 Recall 0.2769 F1 0.3374\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.7442 Acc: 0.3628 Percision: 0.5787 Recall 0.2894 F1 0.3520\n",
      "val Loss: 0.7522 Acc: 0.3756 Percision: 0.5449 Recall 0.2829 F1 0.3436\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.7389 Acc: 0.3632 Percision: 0.5537 Recall 0.2976 F1 0.3613\n",
      "val Loss: 0.7436 Acc: 0.3824 Percision: 0.5539 Recall 0.2820 F1 0.3432\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.7335 Acc: 0.3698 Percision: 0.6013 Recall 0.3048 F1 0.3727\n",
      "val Loss: 0.7469 Acc: 0.3726 Percision: 0.5394 Recall 0.2896 F1 0.3517\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.7306 Acc: 0.3704 Percision: 0.6068 Recall 0.3060 F1 0.3732\n",
      "val Loss: 0.7393 Acc: 0.3736 Percision: 0.6059 Recall 0.2934 F1 0.3584\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.7276 Acc: 0.3714 Percision: 0.6351 Recall 0.3090 F1 0.3774\n",
      "val Loss: 0.7410 Acc: 0.3777 Percision: 0.5870 Recall 0.2936 F1 0.3586\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.7232 Acc: 0.3716 Percision: 0.6295 Recall 0.3136 F1 0.3839\n",
      "val Loss: 0.7380 Acc: 0.3811 Percision: 0.6151 Recall 0.2990 F1 0.3653\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.7202 Acc: 0.3762 Percision: 0.6225 Recall 0.3117 F1 0.3784\n",
      "val Loss: 0.7356 Acc: 0.3826 Percision: 0.6250 Recall 0.2970 F1 0.3679\n",
      "\n",
      "Training complete in 136m 49s\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.8203 Acc: 0.3204 Percision: 0.5142 Recall 0.2622 F1 0.3244\n",
      "val Loss: 1.1631 Acc: 0.3294 Percision: 0.5550 Recall 0.2461 F1 0.2892\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.8119 Acc: 0.3220 Percision: 0.5133 Recall 0.2673 F1 0.3302\n",
      "val Loss: 0.8183 Acc: 0.3252 Percision: 0.5431 Recall 0.2490 F1 0.2996\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.8095 Acc: 0.3240 Percision: 0.5472 Recall 0.2724 F1 0.3382\n",
      "val Loss: 0.9816 Acc: 0.2911 Percision: 0.5045 Recall 0.2500 F1 0.2912\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.8030 Acc: 0.3266 Percision: 0.5336 Recall 0.2732 F1 0.3376\n",
      "val Loss: 0.8614 Acc: 0.3015 Percision: 0.5242 Recall 0.3223 F1 0.3686\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.7946 Acc: 0.3329 Percision: 0.5469 Recall 0.2841 F1 0.3513\n",
      "val Loss: 0.9030 Acc: 0.3088 Percision: 0.5431 Recall 0.2786 F1 0.3400\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.7874 Acc: 0.3411 Percision: 0.5385 Recall 0.2863 F1 0.3525\n",
      "val Loss: 0.8388 Acc: 0.3255 Percision: 0.6071 Recall 0.2711 F1 0.3352\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.7807 Acc: 0.3391 Percision: 0.5595 Recall 0.2974 F1 0.3687\n",
      "val Loss: 0.8148 Acc: 0.3518 Percision: 0.5133 Recall 0.2654 F1 0.3239\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.7729 Acc: 0.3476 Percision: 0.5870 Recall 0.3031 F1 0.3734\n",
      "val Loss: 0.8932 Acc: 0.3178 Percision: 0.5637 Recall 0.2970 F1 0.3328\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.7702 Acc: 0.3483 Percision: 0.5633 Recall 0.3038 F1 0.3734\n",
      "val Loss: 0.8173 Acc: 0.3620 Percision: 0.5582 Recall 0.2971 F1 0.3595\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.7659 Acc: 0.3490 Percision: 0.5696 Recall 0.3047 F1 0.3743\n",
      "val Loss: 0.8962 Acc: 0.3686 Percision: 0.5778 Recall 0.2953 F1 0.3574\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.6826 Acc: 0.3965 Percision: 0.6269 Recall 0.3481 F1 0.4218\n",
      "val Loss: 0.7240 Acc: 0.4005 Percision: 0.6157 Recall 0.3372 F1 0.4089\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.4143 Percision: 0.6561 Recall 0.3710 F1 0.4483\n",
      "val Loss: 0.7249 Acc: 0.3980 Percision: 0.5868 Recall 0.3288 F1 0.3988\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.6540 Acc: 0.4180 Percision: 0.6641 Recall 0.3804 F1 0.4592\n",
      "val Loss: 0.7173 Acc: 0.4100 Percision: 0.6285 Recall 0.3429 F1 0.4159\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.6429 Acc: 0.4245 Percision: 0.7474 Recall 0.4000 F1 0.4847\n",
      "val Loss: 0.7168 Acc: 0.4054 Percision: 0.6291 Recall 0.3397 F1 0.4125\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.6429 Acc: 0.4288 Percision: 0.6990 Recall 0.3870 F1 0.4676\n",
      "val Loss: 0.7147 Acc: 0.4032 Percision: 0.6625 Recall 0.3328 F1 0.4112\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.6337 Acc: 0.4322 Percision: 0.6731 Recall 0.3954 F1 0.4757\n",
      "val Loss: 0.7148 Acc: 0.4011 Percision: 0.6519 Recall 0.3409 F1 0.4192\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.4373 Percision: 0.7087 Recall 0.4025 F1 0.4858\n",
      "val Loss: 0.7668 Acc: 0.4082 Percision: 0.6047 Recall 0.3579 F1 0.4310\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.6288 Acc: 0.4343 Percision: 0.7092 Recall 0.4081 F1 0.4904\n",
      "val Loss: 0.7177 Acc: 0.4093 Percision: 0.5827 Recall 0.3317 F1 0.3986\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.6191 Acc: 0.4408 Percision: 0.7078 Recall 0.4099 F1 0.4918\n",
      "val Loss: 0.7265 Acc: 0.4091 Percision: 0.6032 Recall 0.3399 F1 0.4057\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.6161 Acc: 0.4429 Percision: 0.6867 Recall 0.4134 F1 0.4944\n",
      "val Loss: 0.7234 Acc: 0.4077 Percision: 0.6369 Recall 0.3440 F1 0.4139\n",
      "\n",
      "Training complete in 137m 8s\n"
     ]
    }
   ],
   "source": [
    "#lr clcying\n",
    "max_cycle = 3\n",
    "for cycle in range(max_cycle):\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=base_lr)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 10 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "    model_ft, steps = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                           num_epochs=20, init_steps=steps)\n",
    "\n",
    "    #save intermediate model\n",
    "    torch.save(model_ft.state_dict(), 'M17_20181106_cycle_stage_{}.model'.format(cycle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
