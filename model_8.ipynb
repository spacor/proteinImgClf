{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4248fd9c0afae8eaac391ab0d1895db2be249e75"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# base_path = r'../input'\n",
    "base_path = r'input'\n",
    "PATH_TRAIN_ANNO = os.path.join(base_path, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(base_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "583ead53ccf420ab4290230a0a17cc3b6c62c74d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    USE_TENSORBOARD = True\n",
    "    writer = SummaryWriter()\n",
    "except:\n",
    "    USE_TENSORBOARD = False\n",
    "    print('No tensorboard X')\n",
    "\n",
    "def record_tb(phase, tag, value, global_step):\n",
    "    if USE_TENSORBOARD is True:\n",
    "        writer.add_scalar('{phase}/{tag}'.format(phase=phase, tag=tag), value, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7a95c899247b666f9235e3100a569744c46bf943"
   },
   "outputs": [],
   "source": [
    "# os.listdir(PATH_TRAIN_IMG)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e85715fa2a9217474fc039c2b399c9b33490689a"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28\n",
    "MAX_TAGS = 5\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "VAL_SIZE =0.2\n",
    "THRESHOLD = 0.5\n",
    "SAMPLES = 1\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7e81577b2c725960293a5cfabb29e0d46d66834c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 3107\n",
      "[('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', [16, 0]),\n",
      " ('000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', [7, 1, 2, 0]),\n",
      " ('000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', [5])]\n"
     ]
    }
   ],
   "source": [
    "def get_transform_anno(annotation_path, img_path):\n",
    "    df = pd.read_csv(annotation_path)\n",
    "    annotations = []\n",
    "    for i, row in df.iterrows():\n",
    "        rcd_id = row['Id']\n",
    "        rcd_cate =  [int(j) for j in row['Target'].split()]\n",
    "        annotations.append((rcd_id, rcd_cate))\n",
    "    return annotations\n",
    "#get annotations\n",
    "annotations = get_transform_anno(PATH_TRAIN_ANNO, PATH_TRAIN_IMG)\n",
    "sample_size = int(len(annotations) * SAMPLES)\n",
    "print('sample size: {}'.format(sample_size))\n",
    "annotations = annotations[:sample_size]\n",
    "pprint(annotations[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "878d1a4d5d29884cc313258347df1ee630abae1a"
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, img_meta, img_path, transform = None):\n",
    "        self.img_meta = img_meta\n",
    "        self.transform = transform\n",
    "        self.channels = ['red', 'blue', 'yellow', 'green']\n",
    "        self.img_path = img_path\n",
    "        self.mlb = MultiLabelBinarizer(classes=range(0,NUM_CLASSES))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id, img_tags= self.img_meta[idx]\n",
    "        ch = []\n",
    "        img_file_template = '{}_{}.png'\n",
    "        for c in self.channels:\n",
    "            ch.append(io.imread(os.path.join(self.img_path, img_file_template.format(img_id, c))))\n",
    "        img = np.stack(ch)\n",
    "\n",
    "        #augmentation\n",
    "        if bool(self.transform) is True:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        #binarize\n",
    "        img_tags = self.mlb.fit_transform([img_tags]).squeeze()\n",
    "        \n",
    "        #transform to tensor\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img_tags = torch.from_numpy(img_tags)\n",
    "        \n",
    "        output = (img, img_tags)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "af583f0882e55fd31a3df230822ac86f99e25f4c"
   },
   "outputs": [],
   "source": [
    "class ImgTfm:\n",
    "    def __init__(self, aug_pipline = None):\n",
    "        self.seq = aug_pipline\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "#         seq_det = self.seq.to_deterministic()\n",
    "        \n",
    "        #augmentation\n",
    "        aug_img=img.copy().transpose((1, 2, 0))\n",
    "        aug_img = self.seq.augment_images([aug_img])[0]\n",
    "        aug_img=aug_img.transpose((2, 1, 0))\n",
    "        \n",
    "        #normalize\n",
    "        aug_img=aug_img/255\n",
    "        \n",
    "        return aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "7c0aeb64e2a7b651582a467d82079a2fda67c71b"
   },
   "outputs": [],
   "source": [
    "def get_aug_pipline(img_size, mode = 'train'):\n",
    "    if mode == 'train':\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "            iaa.SomeOf((1,None), [\n",
    "                    iaa.Fliplr(0.5), # horizontal flips\n",
    "                    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                    # But we only blur about 50% of all images.\n",
    "                    iaa.Sometimes(0.5,\n",
    "                        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                    ),\n",
    "                    # Strengthen or weaken the contrast in each image.\n",
    "                    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "                    # Add gaussian noise.\n",
    "                    # For 50% of all images, we sample the noise once per pixel.\n",
    "                    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "                    # channel. This can change the color (not only brightness) of the\n",
    "                    # pixels.\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "                    # Make some images brighter and some darker.\n",
    "                    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                    # which can end up changing the color of the images.\n",
    "                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                    # Apply affine transformations to each image.\n",
    "                    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-20, 20),\n",
    "                        shear=(-8, 8)\n",
    "                    ),\n",
    "                iaa.PiecewiseAffine(scale=(0.01, 0.05))\n",
    "            ], random_order=True) # apply augmenters in random order\n",
    "        ], random_order=False)\n",
    "    else: #ie.val\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "        ], random_order=False)\n",
    "#     seq = iaa.Sequential([\n",
    "#                 iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "#             ], random_order=False)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "4c926ebe55fb37a7bfe3ffb2d6da2b145fb5f747"
   },
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(annotations, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "composed = {}\n",
    "composed['train'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'train'))])\n",
    "composed['val'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'val'))])\n",
    "\n",
    "image_datasets = {'train': ProteinDataset(train_set, img_path = PATH_TRAIN_IMG, transform=composed['train']),\n",
    "                 'val': ProteinDataset(val_set, img_path = PATH_TRAIN_IMG, transform=composed['val'])}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "e8c442abb721b3f65c4a7b076232757725311b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 2485, 'val': 622}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "610b2e7a2e2b430673460bfd21e2940eca4a83b1"
   },
   "outputs": [],
   "source": [
    "#test dataset\n",
    "# ix = 10\n",
    "# tmp_img, tmp_tags  = image_datasets['train'][ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "116981e26006844aba80864a76434c9b0a445188"
   },
   "outputs": [],
   "source": [
    "#test dataloader\n",
    "# tmp_img, tmp_tags = next(iter(dataloaders['train']))\n",
    "# print('tmp_img shape: {}\\ntmp_tags: shape {}'.format(tmp_img.shape, tmp_tags.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "53926b18c61ec3d5f167ee905fcde5c0dc9289f5"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class RnetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = self._prep_backbone()\n",
    "        \n",
    "    def _prep_backbone(self):     \n",
    "        base_model = models.resnet34(pretrained=False)\n",
    "        removed = list(base_model.children())[1:-2]\n",
    "        backbone = nn.Sequential(*removed)\n",
    "#         for param in backbone.parameters():\n",
    "#             param.require_grad = False\n",
    "        return backbone\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p=0.5)\n",
    "        self.fc_2 = nn.Linear(512 * 7 * 7, 256)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(256)\n",
    "        self.dropout_2 = nn.Dropout(p=0.5)\n",
    "        self.fc_3 = nn.Linear(256, self.num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc_3(x)\n",
    "        return x\n",
    "\n",
    "class CustomEntry(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        return x\n",
    "    \n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.custom_entry = CustomEntry()\n",
    "        self.backbone = RnetBackbone()\n",
    "        self.custom_head = CustomHead(num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.custom_entry(x)\n",
    "        x = self.backbone(x)\n",
    "        x = self.custom_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "4ef191d711342bf7bce65d943f8629d03bcf26c1"
   },
   "outputs": [],
   "source": [
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        #f1 loss\n",
    "#         #prep y_true\n",
    "        y_true = y_true.float()\n",
    "\n",
    "        #prep y_pred\n",
    "        y_pred = torch.tensor(data = (torch.sigmoid(y_pred).ge(THRESHOLD)), dtype=torch.float, device=DEVICE, requires_grad=True)\n",
    "\n",
    "        #calculate loss\n",
    "        tp = (y_true * y_pred).sum(0).float()\n",
    "        # tn = ((1-y_true) * (1-y_pred)).sum(0).float()\n",
    "        fp = ((1-y_true) * y_pred).sum(0).float()\n",
    "        fn = (y_true * (1-y_pred)).sum(0).float()\n",
    "\n",
    "        p = tp / (tp + fp)\n",
    "        r = tp / (tp + fn)\n",
    "\n",
    "        f1 = 2*p*r / (p+r)\n",
    "        f1[torch.isnan(f1)] = 0\n",
    "        f1_loss = 1-f1.mean()\n",
    "#         print(f1_loss)\n",
    "        return f1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        target = target.float()\n",
    "        \n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "34c786807f448f63f4244537f13ebca2a6b44ee2"
   },
   "outputs": [],
   "source": [
    "def prep_stats(y_pred, y_true):\n",
    "    #prep y_true\n",
    "    y_true_tfm = y_true.cpu().numpy().astype('uint8')\n",
    "    \n",
    "    #prep y_pred khot\n",
    "    y_pred_tfm = (torch.sigmoid(y_pred) > THRESHOLD).cpu().numpy().astype('uint8')\n",
    "    \n",
    "    return y_pred_tfm, y_true_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "7df1b550cc9567063a38437001eff118004b0370"
   },
   "outputs": [],
   "source": [
    "def calc_stats(y_pred, y_true, stats = 'accurancy'):\n",
    "    if stats == 'accuracy':\n",
    "        stat_value = accuracy_score(y_true, y_pred)\n",
    "    elif stats == 'precision':\n",
    "        stat_value = precision_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'recall':\n",
    "        stat_value = recall_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'f1':\n",
    "        stat_value = f1_score(y_true, y_pred, average = 'macro')\n",
    "    else:\n",
    "        stat_value = 0\n",
    "    return stat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "467bc143b3e21ddb3674f77f2c78287c9bc3684c"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_y_true = []\n",
    "            running_y_pred = []\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets= targets.to(DEVICE)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    y_pred_tfm, y_true_tfm = prep_stats(outputs, targets)\n",
    "                    running_y_pred.append(y_pred_tfm)\n",
    "                    running_y_true.append(y_true_tfm)\n",
    "                    \n",
    "                    #export step stats duing training phase\n",
    "                    if phase == 'train':\n",
    "                        record_tb(phase, 'loss', loss.cpu().data.numpy(), steps)\n",
    "                        record_tb(phase, 'accuracy', calc_stats(y_pred_tfm, y_true_tfm, stats = 'accurancy'), steps)\n",
    "                        record_tb(phase, 'precision', calc_stats(y_pred_tfm, y_true_tfm, stats = 'precision'), steps)\n",
    "                        record_tb(phase, 'recall', calc_stats(y_pred_tfm, y_true_tfm, stats = 'recall'), steps)\n",
    "                        record_tb(phase, 'f1', calc_stats(y_pred_tfm, y_true_tfm, stats = 'f1'), steps)\n",
    "                        steps += 1\n",
    "                        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            #calc epoch stats\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = accuracy_score(np.vstack(running_y_true), np.vstack(running_y_pred))\n",
    "            epoch_precision = precision_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_recall = recall_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_f1 = f1_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            \n",
    "            #export epoch stats duing training phase\n",
    "            if phase == 'val':\n",
    "                record_tb(phase, 'loss', epoch_loss, steps)\n",
    "                record_tb(phase, 'accuracy', epoch_acc, steps)\n",
    "                record_tb(phase, 'precision', epoch_precision, steps)\n",
    "                record_tb(phase, 'recall', epoch_recall, steps)\n",
    "                record_tb(phase, 'f1', epoch_f1, steps)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Percision: {:.4f} Recall {:.4f} F1 {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "be546ee708d7ccb01c9f876bb189db4818a7d12a"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = CustomNet(num_class=NUM_CLASSES)\n",
    "model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "criterion = FocalLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "a27461b7756ca489c66881be19cb1d0d54bf5d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 3.2821 Acc: 0.0333 Percision: 0.0615 Recall 0.0530 F1 0.0563\n",
      "val Loss: 1.7752 Acc: 0.0592 Percision: 0.0291 Recall 0.0343 F1 0.0265\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 2.2125 Acc: 0.0244 Percision: 0.0607 Recall 0.0292 F1 0.0378\n",
      "val Loss: 3.0392 Acc: 0.0000 Percision: 0.0704 Recall 0.0041 F1 0.0074\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 2.8741 Acc: 0.0329 Percision: 0.0511 Recall 0.0322 F1 0.0384\n",
      "val Loss: 1.9000 Acc: 0.0855 Percision: 0.0153 Recall 0.0357 F1 0.0214\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 3.7121 Acc: 0.0175 Percision: 0.0627 Recall 0.0506 F1 0.0555\n",
      "val Loss: 11.9544 Acc: 0.0280 Percision: 0.0385 Recall 0.0336 F1 0.0055\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 4.6165 Acc: 0.0248 Percision: 0.0584 Recall 0.0547 F1 0.0563\n",
      "val Loss: 49.7492 Acc: 0.0839 Percision: 0.0868 Recall 0.0366 F1 0.0241\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 5.9634 Acc: 0.0207 Percision: 0.0560 Recall 0.0573 F1 0.0563\n",
      "val Loss: 6.9739 Acc: 0.0000 Percision: 0.0361 Recall 0.0045 F1 0.0077\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 4.6323 Acc: 0.0223 Percision: 0.0600 Recall 0.0584 F1 0.0590\n",
      "val Loss: 285.3721 Acc: 0.0658 Percision: 0.0303 Recall 0.0401 F1 0.0293\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 2.3883 Acc: 0.0195 Percision: 0.0533 Recall 0.0188 F1 0.0254\n",
      "val Loss: 1.9184 Acc: 0.0016 Percision: 0.0456 Recall 0.0053 F1 0.0092\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 1.7460 Acc: 0.0101 Percision: 0.0752 Recall 0.0099 F1 0.0155\n",
      "val Loss: 1.9949 Acc: 0.0016 Percision: 0.0601 Recall 0.0023 F1 0.0042\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 1.6213 Acc: 0.0122 Percision: 0.0631 Recall 0.0089 F1 0.0135\n",
      "val Loss: 1.7775 Acc: 0.0000 Percision: 0.0529 Recall 0.0036 F1 0.0061\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 1.5458 Acc: 0.0162 Percision: 0.0516 Recall 0.0095 F1 0.0138\n",
      "val Loss: 1.4363 Acc: 0.0033 Percision: 0.0392 Recall 0.0024 F1 0.0046\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 1.5064 Acc: 0.0089 Percision: 0.0945 Recall 0.0077 F1 0.0131\n",
      "val Loss: 1.7813 Acc: 0.0049 Percision: 0.0377 Recall 0.0037 F1 0.0067\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 1.4859 Acc: 0.0085 Percision: 0.0465 Recall 0.0063 F1 0.0103\n",
      "val Loss: 1.5116 Acc: 0.0000 Percision: 0.0246 Recall 0.0015 F1 0.0028\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 1.4802 Acc: 0.0093 Percision: 0.0405 Recall 0.0058 F1 0.0094\n",
      "val Loss: 1.4600 Acc: 0.0033 Percision: 0.0418 Recall 0.0026 F1 0.0048\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 1.4273 Acc: 0.0057 Percision: 0.0441 Recall 0.0051 F1 0.0087\n",
      "val Loss: 1.3889 Acc: 0.0016 Percision: 0.0550 Recall 0.0042 F1 0.0077\n",
      "\n",
      "Training complete in 10m 51s\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "c6216757e2fd5f18f15c28d27f29427270f3789b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]          12,544\n",
      "       CustomEntry-2         [-1, 64, 112, 112]               0\n",
      "       BatchNorm2d-3         [-1, 64, 112, 112]             128\n",
      "              ReLU-4         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      "            Conv2d-6           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-7           [-1, 64, 56, 56]             128\n",
      "              ReLU-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
      "             ReLU-11           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-12           [-1, 64, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-14           [-1, 64, 56, 56]             128\n",
      "             ReLU-15           [-1, 64, 56, 56]               0\n",
      "           Conv2d-16           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-17           [-1, 64, 56, 56]             128\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-24           [-1, 64, 56, 56]             128\n",
      "             ReLU-25           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-26           [-1, 64, 56, 56]               0\n",
      "           Conv2d-27          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-28          [-1, 128, 28, 28]             256\n",
      "             ReLU-29          [-1, 128, 28, 28]               0\n",
      "           Conv2d-30          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-31          [-1, 128, 28, 28]             256\n",
      "           Conv2d-32          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "             ReLU-34          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-35          [-1, 128, 28, 28]               0\n",
      "           Conv2d-36          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-37          [-1, 128, 28, 28]             256\n",
      "             ReLU-38          [-1, 128, 28, 28]               0\n",
      "           Conv2d-39          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-40          [-1, 128, 28, 28]             256\n",
      "             ReLU-41          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-47          [-1, 128, 28, 28]             256\n",
      "             ReLU-48          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-49          [-1, 128, 28, 28]               0\n",
      "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-51          [-1, 128, 28, 28]             256\n",
      "             ReLU-52          [-1, 128, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-56          [-1, 128, 28, 28]               0\n",
      "           Conv2d-57          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-58          [-1, 256, 14, 14]             512\n",
      "             ReLU-59          [-1, 256, 14, 14]               0\n",
      "           Conv2d-60          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-61          [-1, 256, 14, 14]             512\n",
      "           Conv2d-62          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-63          [-1, 256, 14, 14]             512\n",
      "             ReLU-64          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-65          [-1, 256, 14, 14]               0\n",
      "           Conv2d-66          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-67          [-1, 256, 14, 14]             512\n",
      "             ReLU-68          [-1, 256, 14, 14]               0\n",
      "           Conv2d-69          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-70          [-1, 256, 14, 14]             512\n",
      "             ReLU-71          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-72          [-1, 256, 14, 14]               0\n",
      "           Conv2d-73          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-74          [-1, 256, 14, 14]             512\n",
      "             ReLU-75          [-1, 256, 14, 14]               0\n",
      "           Conv2d-76          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-77          [-1, 256, 14, 14]             512\n",
      "             ReLU-78          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-79          [-1, 256, 14, 14]               0\n",
      "           Conv2d-80          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-81          [-1, 256, 14, 14]             512\n",
      "             ReLU-82          [-1, 256, 14, 14]               0\n",
      "           Conv2d-83          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-84          [-1, 256, 14, 14]             512\n",
      "             ReLU-85          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-86          [-1, 256, 14, 14]               0\n",
      "           Conv2d-87          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-88          [-1, 256, 14, 14]             512\n",
      "             ReLU-89          [-1, 256, 14, 14]               0\n",
      "           Conv2d-90          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-91          [-1, 256, 14, 14]             512\n",
      "             ReLU-92          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-98          [-1, 256, 14, 14]             512\n",
      "             ReLU-99          [-1, 256, 14, 14]               0\n",
      "      BasicBlock-100          [-1, 256, 14, 14]               0\n",
      "          Conv2d-101            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-102            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-103            [-1, 512, 7, 7]               0\n",
      "          Conv2d-104            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-105            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-106            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-107            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-108            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-109            [-1, 512, 7, 7]               0\n",
      "          Conv2d-110            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-111            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-112            [-1, 512, 7, 7]               0\n",
      "          Conv2d-113            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-114            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-115            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-116            [-1, 512, 7, 7]               0\n",
      "          Conv2d-117            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-118            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-119            [-1, 512, 7, 7]               0\n",
      "          Conv2d-120            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-121            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-122            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-123            [-1, 512, 7, 7]               0\n",
      "    RnetBackbone-124            [-1, 512, 7, 7]               0\n",
      "         Flatten-125                [-1, 25088]               0\n",
      "            ReLU-126                [-1, 25088]               0\n",
      "         Dropout-127                [-1, 25088]               0\n",
      "          Linear-128                  [-1, 256]       6,422,784\n",
      "            ReLU-129                  [-1, 256]               0\n",
      "     BatchNorm1d-130                  [-1, 256]             512\n",
      "         Dropout-131                  [-1, 256]               0\n",
      "          Linear-132                   [-1, 28]           7,196\n",
      "      CustomHead-133                   [-1, 28]               0\n",
      "================================================================\n",
      "Total params: 27,718,300\n",
      "Trainable params: 27,718,300\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.77\n",
      "Forward/backward pass size (MB): 103.18\n",
      "Params size (MB): 105.74\n",
      "Estimated Total Size (MB): 209.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# summary(model_ft, (4, IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomNet(\n",
       "  (custom_entry): CustomEntry(\n",
       "    (conv_1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  )\n",
       "  (backbone): RnetBackbone(\n",
       "    (backbone): Sequential(\n",
       "      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (custom_head): CustomHead(\n",
       "    (flatten): Flatten()\n",
       "    (relu_1): ReLU()\n",
       "    (dropout_1): Dropout(p=0.5)\n",
       "    (fc_2): Linear(in_features=25088, out_features=256, bias=True)\n",
       "    (relu_2): ReLU()\n",
       "    (batchnorm_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout_2): Dropout(p=0.5)\n",
       "    (fc_3): Linear(in_features=256, out_features=28, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
