{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4248fd9c0afae8eaac391ab0d1895db2be249e75"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# base_path = r'../input'\n",
    "base_path = r'input'\n",
    "PATH_TRAIN_ANNO = os.path.join(base_path, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(base_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "583ead53ccf420ab4290230a0a17cc3b6c62c74d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    USE_TENSORBOARD = True\n",
    "    writer = SummaryWriter()\n",
    "except:\n",
    "    USE_TENSORBOARD = False\n",
    "    print('No tensorboard X')\n",
    "\n",
    "def record_tb(phase, tag, value, global_step):\n",
    "    if USE_TENSORBOARD is True:\n",
    "        writer.add_scalar('{phase}/{tag}'.format(phase=phase, tag=tag), value, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7a95c899247b666f9235e3100a569744c46bf943"
   },
   "outputs": [],
   "source": [
    "# os.listdir(PATH_TRAIN_IMG)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e85715fa2a9217474fc039c2b399c9b33490689a"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28\n",
    "MAX_TAGS = 5\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "VAL_SIZE =0.2\n",
    "THRESHOLD = 0.5\n",
    "SAMPLES = 1\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "7e81577b2c725960293a5cfabb29e0d46d66834c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 31072\n",
      "[('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', [16, 0]),\n",
      " ('000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', [7, 1, 2, 0]),\n",
      " ('000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', [5])]\n"
     ]
    }
   ],
   "source": [
    "def get_transform_anno(annotation_path, img_path):\n",
    "    df = pd.read_csv(annotation_path)\n",
    "    annotations = []\n",
    "    for i, row in df.iterrows():\n",
    "        rcd_id = row['Id']\n",
    "        rcd_cate =  [int(j) for j in row['Target'].split()]\n",
    "        annotations.append((rcd_id, rcd_cate))\n",
    "    return annotations\n",
    "#get annotations\n",
    "annotations = get_transform_anno(PATH_TRAIN_ANNO, PATH_TRAIN_IMG)\n",
    "sample_size = int(len(annotations) * SAMPLES)\n",
    "print('sample size: {}'.format(sample_size))\n",
    "annotations = annotations[:sample_size]\n",
    "pprint(annotations[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "878d1a4d5d29884cc313258347df1ee630abae1a"
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, img_meta, img_path, transform = None):\n",
    "        self.img_meta = img_meta\n",
    "        self.transform = transform\n",
    "        self.channels = ['red', 'blue', 'yellow', 'green']\n",
    "        self.img_path = img_path\n",
    "        self.mlb = MultiLabelBinarizer(classes=range(0,NUM_CLASSES))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id, img_tags= self.img_meta[idx]\n",
    "        ch = []\n",
    "        img_file_template = '{}_{}.png'\n",
    "        for c in self.channels:\n",
    "            ch.append(io.imread(os.path.join(self.img_path, img_file_template.format(img_id, c))))\n",
    "        img = np.stack(ch)\n",
    "\n",
    "        #augmentation\n",
    "        if bool(self.transform) is True:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        #binarize\n",
    "        img_tags = self.mlb.fit_transform([img_tags]).squeeze()\n",
    "        \n",
    "        #transform to tensor\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img_tags = torch.from_numpy(img_tags)\n",
    "        \n",
    "        output = (img, img_tags)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "af583f0882e55fd31a3df230822ac86f99e25f4c"
   },
   "outputs": [],
   "source": [
    "class ImgTfm:\n",
    "    def __init__(self, aug_pipline = None):\n",
    "        self.seq = aug_pipline\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "#         seq_det = self.seq.to_deterministic()\n",
    "        \n",
    "        #augmentation\n",
    "        aug_img=img.copy().transpose((1, 2, 0))\n",
    "        aug_img = self.seq.augment_images([aug_img])[0]\n",
    "        aug_img=aug_img.transpose((2, 1, 0))\n",
    "        \n",
    "        #normalize\n",
    "        aug_img=aug_img/255\n",
    "        \n",
    "        return aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "7c0aeb64e2a7b651582a467d82079a2fda67c71b"
   },
   "outputs": [],
   "source": [
    "def get_aug_pipline(img_size, mode = 'train'):\n",
    "    if mode == 'train':\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "            iaa.SomeOf((1,None), [\n",
    "                    iaa.Fliplr(0.5), # horizontal flips\n",
    "                    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                    # But we only blur about 50% of all images.\n",
    "                    iaa.Sometimes(0.5,\n",
    "                        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                    ),\n",
    "                    # Strengthen or weaken the contrast in each image.\n",
    "                    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "                    # Add gaussian noise.\n",
    "                    # For 50% of all images, we sample the noise once per pixel.\n",
    "                    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "                    # channel. This can change the color (not only brightness) of the\n",
    "                    # pixels.\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "                    # Make some images brighter and some darker.\n",
    "                    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                    # which can end up changing the color of the images.\n",
    "                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                    # Apply affine transformations to each image.\n",
    "                    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-20, 20),\n",
    "                        shear=(-8, 8)\n",
    "                    ),\n",
    "                iaa.PiecewiseAffine(scale=(0.01, 0.05))\n",
    "            ], random_order=True) # apply augmenters in random order\n",
    "        ], random_order=False)\n",
    "    else: #ie.val\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "        ], random_order=False)\n",
    "#     seq = iaa.Sequential([\n",
    "#                 iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "#             ], random_order=False)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "4c926ebe55fb37a7bfe3ffb2d6da2b145fb5f747"
   },
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(annotations, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "composed = {}\n",
    "composed['train'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'train'))])\n",
    "composed['val'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'val'))])\n",
    "\n",
    "image_datasets = {'train': ProteinDataset(train_set, img_path = PATH_TRAIN_IMG, transform=composed['train']),\n",
    "                 'val': ProteinDataset(val_set, img_path = PATH_TRAIN_IMG, transform=composed['val'])}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "e8c442abb721b3f65c4a7b076232757725311b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 24857, 'val': 6215}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "610b2e7a2e2b430673460bfd21e2940eca4a83b1"
   },
   "outputs": [],
   "source": [
    "#test dataset\n",
    "# ix = 10\n",
    "# tmp_img, tmp_tags  = image_datasets['train'][ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "116981e26006844aba80864a76434c9b0a445188"
   },
   "outputs": [],
   "source": [
    "#test dataloader\n",
    "# tmp_img, tmp_tags = next(iter(dataloaders['train']))\n",
    "# print('tmp_img shape: {}\\ntmp_tags: shape {}'.format(tmp_img.shape, tmp_tags.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "53926b18c61ec3d5f167ee905fcde5c0dc9289f5"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class RnetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = self._prep_backbone()\n",
    "        \n",
    "    def _prep_backbone(self):     \n",
    "        base_model = models.resnet34(pretrained=False)\n",
    "        removed = list(base_model.children())[1:-2]\n",
    "        backbone = nn.Sequential(*removed)\n",
    "#         for param in backbone.parameters():\n",
    "#             param.require_grad = False\n",
    "        return backbone\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p=0.5)\n",
    "        self.fc_2 = nn.Linear(512 * 7 * 7, 256)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(256)\n",
    "        self.dropout_2 = nn.Dropout(p=0.5)\n",
    "        self.fc_3 = nn.Linear(256, self.num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc_3(x)\n",
    "        return x\n",
    "\n",
    "class CustomEntry(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        return x\n",
    "    \n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.custom_entry = CustomEntry()\n",
    "        self.backbone = RnetBackbone()\n",
    "        self.custom_head = CustomHead(num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.custom_entry(x)\n",
    "        x = self.backbone(x)\n",
    "        x = self.custom_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "4ef191d711342bf7bce65d943f8629d03bcf26c1"
   },
   "outputs": [],
   "source": [
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        #f1 loss\n",
    "#         #prep y_true\n",
    "        y_true = y_true.float()\n",
    "\n",
    "        #prep y_pred\n",
    "        y_pred = torch.tensor(data = (torch.sigmoid(y_pred).ge(THRESHOLD)), dtype=torch.float, device=DEVICE, requires_grad=True)\n",
    "\n",
    "        #calculate loss\n",
    "        tp = (y_true * y_pred).sum(0).float()\n",
    "        # tn = ((1-y_true) * (1-y_pred)).sum(0).float()\n",
    "        fp = ((1-y_true) * y_pred).sum(0).float()\n",
    "        fn = (y_true * (1-y_pred)).sum(0).float()\n",
    "\n",
    "        p = tp / (tp + fp)\n",
    "        r = tp / (tp + fn)\n",
    "\n",
    "        f1 = 2*p*r / (p+r)\n",
    "        f1[torch.isnan(f1)] = 0\n",
    "        f1_loss = 1-f1.mean()\n",
    "#         print(f1_loss)\n",
    "        return f1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        target = target.float()\n",
    "        \n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "34c786807f448f63f4244537f13ebca2a6b44ee2"
   },
   "outputs": [],
   "source": [
    "def prep_stats(y_pred, y_true):\n",
    "    #prep y_true\n",
    "    y_true_tfm = y_true.cpu().numpy().astype('uint8')\n",
    "    \n",
    "    #prep y_pred khot\n",
    "    y_pred_tfm = (torch.sigmoid(y_pred) > THRESHOLD).cpu().numpy().astype('uint8')\n",
    "    \n",
    "    return y_pred_tfm, y_true_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "7df1b550cc9567063a38437001eff118004b0370"
   },
   "outputs": [],
   "source": [
    "def calc_stats(y_pred, y_true, stats = 'accurancy'):\n",
    "    if stats == 'accuracy':\n",
    "        stat_value = accuracy_score(y_true, y_pred)\n",
    "    elif stats == 'precision':\n",
    "        stat_value = precision_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'recall':\n",
    "        stat_value = recall_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'f1':\n",
    "        stat_value = f1_score(y_true, y_pred, average = 'macro')\n",
    "    else:\n",
    "        stat_value = 0\n",
    "    return stat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "467bc143b3e21ddb3674f77f2c78287c9bc3684c"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_y_true = []\n",
    "            running_y_pred = []\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets= targets.to(DEVICE)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    y_pred_tfm, y_true_tfm = prep_stats(outputs, targets)\n",
    "                    running_y_pred.append(y_pred_tfm)\n",
    "                    running_y_true.append(y_true_tfm)\n",
    "                    \n",
    "                    #export step stats duing training phase\n",
    "                    if phase == 'train':\n",
    "                        record_tb(phase, 'loss', loss.cpu().data.numpy(), steps)\n",
    "                        record_tb(phase, 'accuracy', calc_stats(y_pred_tfm, y_true_tfm, stats = 'accurancy'), steps)\n",
    "                        record_tb(phase, 'precision', calc_stats(y_pred_tfm, y_true_tfm, stats = 'precision'), steps)\n",
    "                        record_tb(phase, 'recall', calc_stats(y_pred_tfm, y_true_tfm, stats = 'recall'), steps)\n",
    "                        record_tb(phase, 'f1', calc_stats(y_pred_tfm, y_true_tfm, stats = 'f1'), steps)\n",
    "                        steps += 1\n",
    "                        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            #calc epoch stats\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = accuracy_score(np.vstack(running_y_true), np.vstack(running_y_pred))\n",
    "            epoch_precision = precision_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_recall = recall_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_f1 = f1_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            \n",
    "            #export epoch stats duing training phase\n",
    "            if phase == 'val':\n",
    "                record_tb(phase, 'loss', epoch_loss, steps)\n",
    "                record_tb(phase, 'accuracy', epoch_acc, steps)\n",
    "                record_tb(phase, 'precision', epoch_precision, steps)\n",
    "                record_tb(phase, 'recall', epoch_recall, steps)\n",
    "                record_tb(phase, 'f1', epoch_f1, steps)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Percision: {:.4f} Recall {:.4f} F1 {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "be546ee708d7ccb01c9f876bb189db4818a7d12a"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = CustomNet(num_class=NUM_CLASSES)\n",
    "model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "criterion = FocalLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "a27461b7756ca489c66881be19cb1d0d54bf5d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.4110 Acc: 0.0155 Percision: 0.0787 Recall 0.0148 F1 0.0235\n",
      "val Loss: 1.4526 Acc: 0.0039 Percision: 0.0402 Recall 0.0214 F1 0.0256\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.3091 Acc: 0.0316 Percision: 0.1100 Recall 0.0174 F1 0.0254\n",
      "val Loss: 2.2451 Acc: 0.0627 Percision: 0.0658 Recall 0.0906 F1 0.0690\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.2761 Acc: 0.0517 Percision: 0.0754 Recall 0.0300 F1 0.0358\n",
      "val Loss: 1.2283 Acc: 0.0851 Percision: 0.0624 Recall 0.0358 F1 0.0390\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.2577 Acc: 0.0548 Percision: 0.1066 Recall 0.0321 F1 0.0377\n",
      "val Loss: 3.1239 Acc: 0.0660 Percision: 0.1027 Recall 0.0394 F1 0.0469\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.2382 Acc: 0.0628 Percision: 0.1161 Recall 0.0352 F1 0.0425\n",
      "val Loss: 3.3727 Acc: 0.0859 Percision: 0.0691 Recall 0.0430 F1 0.0496\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.2068 Acc: 0.0770 Percision: 0.1527 Recall 0.0438 F1 0.0558\n",
      "val Loss: 1.1737 Acc: 0.1455 Percision: 0.1539 Recall 0.1016 F1 0.1087\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.1755 Acc: 0.0940 Percision: 0.2068 Recall 0.0547 F1 0.0718\n",
      "val Loss: 1.1138 Acc: 0.1582 Percision: 0.1131 Recall 0.0752 F1 0.0816\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.1486 Acc: 0.1054 Percision: 0.2302 Recall 0.0638 F1 0.0852\n",
      "val Loss: 1.1221 Acc: 0.1400 Percision: 0.2257 Recall 0.0807 F1 0.0988\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.1358 Acc: 0.1119 Percision: 0.2811 Recall 0.0713 F1 0.0968\n",
      "val Loss: 1.0721 Acc: 0.1567 Percision: 0.2315 Recall 0.0912 F1 0.1073\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.1174 Acc: 0.1209 Percision: 0.2727 Recall 0.0776 F1 0.1045\n",
      "val Loss: 5.7356 Acc: 0.1508 Percision: 0.3029 Recall 0.0872 F1 0.1135\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.0493 Acc: 0.1440 Percision: 0.3363 Recall 0.0934 F1 0.1254\n",
      "val Loss: 2.1824 Acc: 0.2039 Percision: 0.3769 Recall 0.1302 F1 0.1668\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.0244 Acc: 0.1587 Percision: 0.3615 Recall 0.1056 F1 0.1414\n",
      "val Loss: 1.3789 Acc: 0.2223 Percision: 0.3664 Recall 0.1404 F1 0.1800\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.0098 Acc: 0.1688 Percision: 0.3549 Recall 0.1131 F1 0.1506\n",
      "val Loss: 1.8150 Acc: 0.2386 Percision: 0.4070 Recall 0.1551 F1 0.1963\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.9979 Acc: 0.1792 Percision: 0.4041 Recall 0.1233 F1 0.1636\n",
      "val Loss: 0.9582 Acc: 0.2474 Percision: 0.4176 Recall 0.1566 F1 0.1991\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.9856 Acc: 0.1892 Percision: 0.3997 Recall 0.1307 F1 0.1725\n",
      "val Loss: 0.9986 Acc: 0.2537 Percision: 0.4287 Recall 0.1591 F1 0.2008\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.9779 Acc: 0.1950 Percision: 0.4044 Recall 0.1366 F1 0.1798\n",
      "val Loss: 1.3224 Acc: 0.2552 Percision: 0.4370 Recall 0.1587 F1 0.2041\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.0084 Acc: 0.1783 Percision: 0.3958 Recall 0.1204 F1 0.1589\n",
      "val Loss: 1.2236 Acc: 0.2245 Percision: 0.3851 Recall 0.1414 F1 0.1777\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.9940 Acc: 0.1844 Percision: 0.4057 Recall 0.1236 F1 0.1620\n",
      "val Loss: 0.9215 Acc: 0.2461 Percision: 0.4618 Recall 0.1647 F1 0.2088\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.9740 Acc: 0.1978 Percision: 0.4116 Recall 0.1382 F1 0.1827\n",
      "val Loss: 1.1003 Acc: 0.2587 Percision: 0.4215 Recall 0.1697 F1 0.2125\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.9657 Acc: 0.2053 Percision: 0.4212 Recall 0.1454 F1 0.1909\n",
      "val Loss: 1.6394 Acc: 0.2758 Percision: 0.4491 Recall 0.1794 F1 0.2245\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.9518 Acc: 0.2168 Percision: 0.4250 Recall 0.1506 F1 0.1966\n",
      "val Loss: 1.9679 Acc: 0.2782 Percision: 0.4397 Recall 0.1825 F1 0.2245\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.9486 Acc: 0.2172 Percision: 0.4049 Recall 0.1522 F1 0.1979\n",
      "val Loss: 0.8977 Acc: 0.2748 Percision: 0.4741 Recall 0.1813 F1 0.2286\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.9457 Acc: 0.2169 Percision: 0.4337 Recall 0.1545 F1 0.2018\n",
      "val Loss: 1.1927 Acc: 0.2761 Percision: 0.4541 Recall 0.1829 F1 0.2278\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.9444 Acc: 0.2183 Percision: 0.4309 Recall 0.1543 F1 0.2009\n",
      "val Loss: 2.9626 Acc: 0.2708 Percision: 0.4549 Recall 0.1802 F1 0.2266\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.9453 Acc: 0.2204 Percision: 0.4351 Recall 0.1558 F1 0.2030\n",
      "val Loss: 1.6669 Acc: 0.2724 Percision: 0.4722 Recall 0.1826 F1 0.2285\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.9417 Acc: 0.2212 Percision: 0.4846 Recall 0.1569 F1 0.2053\n",
      "val Loss: 1.5038 Acc: 0.2775 Percision: 0.4896 Recall 0.1847 F1 0.2329\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.9392 Acc: 0.2228 Percision: 0.4612 Recall 0.1588 F1 0.2067\n",
      "val Loss: 0.9749 Acc: 0.2792 Percision: 0.4700 Recall 0.1875 F1 0.2335\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.9377 Acc: 0.2229 Percision: 0.4404 Recall 0.1574 F1 0.2052\n",
      "val Loss: 0.8815 Acc: 0.2817 Percision: 0.4911 Recall 0.1932 F1 0.2423\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.9331 Acc: 0.2274 Percision: 0.4727 Recall 0.1616 F1 0.2097\n",
      "val Loss: 1.2928 Acc: 0.2816 Percision: 0.4788 Recall 0.1909 F1 0.2396\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.9354 Acc: 0.2269 Percision: 0.4287 Recall 0.1616 F1 0.2089\n",
      "val Loss: 1.3012 Acc: 0.2793 Percision: 0.4522 Recall 0.1858 F1 0.2331\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.9280 Acc: 0.2250 Percision: 0.4395 Recall 0.1634 F1 0.2122\n",
      "val Loss: 0.8591 Acc: 0.2833 Percision: 0.4925 Recall 0.1898 F1 0.2400\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.9301 Acc: 0.2298 Percision: 0.4346 Recall 0.1622 F1 0.2108\n",
      "val Loss: 0.8587 Acc: 0.2851 Percision: 0.4856 Recall 0.1910 F1 0.2373\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.9307 Acc: 0.2274 Percision: 0.4326 Recall 0.1636 F1 0.2120\n",
      "val Loss: 0.9927 Acc: 0.2853 Percision: 0.4839 Recall 0.1914 F1 0.2404\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.9281 Acc: 0.2295 Percision: 0.4441 Recall 0.1640 F1 0.2130\n",
      "val Loss: 0.8579 Acc: 0.2811 Percision: 0.4917 Recall 0.1886 F1 0.2362\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.9302 Acc: 0.2281 Percision: 0.4433 Recall 0.1621 F1 0.2110\n",
      "val Loss: 0.9293 Acc: 0.2896 Percision: 0.4828 Recall 0.2015 F1 0.2501\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.9320 Acc: 0.2298 Percision: 0.4485 Recall 0.1650 F1 0.2139\n",
      "val Loss: 0.8555 Acc: 0.2856 Percision: 0.5023 Recall 0.1945 F1 0.2433\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.9306 Acc: 0.2270 Percision: 0.4385 Recall 0.1637 F1 0.2119\n",
      "val Loss: 1.1441 Acc: 0.2875 Percision: 0.4810 Recall 0.1903 F1 0.2366\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.9283 Acc: 0.2285 Percision: 0.4420 Recall 0.1633 F1 0.2117\n",
      "val Loss: 0.8570 Acc: 0.2854 Percision: 0.4965 Recall 0.1891 F1 0.2361\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.9297 Acc: 0.2303 Percision: 0.4522 Recall 0.1644 F1 0.2138\n",
      "val Loss: 1.4768 Acc: 0.2775 Percision: 0.4727 Recall 0.1826 F1 0.2274\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.9302 Acc: 0.2278 Percision: 0.4511 Recall 0.1632 F1 0.2116\n",
      "val Loss: 1.5864 Acc: 0.2854 Percision: 0.4880 Recall 0.1917 F1 0.2389\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.9281 Acc: 0.2326 Percision: 0.4425 Recall 0.1670 F1 0.2166\n",
      "val Loss: 0.8583 Acc: 0.2861 Percision: 0.4534 Recall 0.1916 F1 0.2382\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.9287 Acc: 0.2302 Percision: 0.4436 Recall 0.1638 F1 0.2130\n",
      "val Loss: 1.1130 Acc: 0.2838 Percision: 0.4577 Recall 0.1913 F1 0.2382\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.9330 Acc: 0.2262 Percision: 0.4276 Recall 0.1617 F1 0.2090\n",
      "val Loss: 0.8579 Acc: 0.2850 Percision: 0.4888 Recall 0.1902 F1 0.2358\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.9299 Acc: 0.2298 Percision: 0.4610 Recall 0.1634 F1 0.2118\n",
      "val Loss: 1.2275 Acc: 0.2800 Percision: 0.4790 Recall 0.1871 F1 0.2328\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.9300 Acc: 0.2289 Percision: 0.4346 Recall 0.1618 F1 0.2098\n",
      "val Loss: 0.8551 Acc: 0.2854 Percision: 0.4921 Recall 0.1929 F1 0.2425\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.9310 Acc: 0.2285 Percision: 0.4239 Recall 0.1625 F1 0.2106\n",
      "val Loss: 0.8553 Acc: 0.2872 Percision: 0.4968 Recall 0.1939 F1 0.2443\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.9280 Acc: 0.2320 Percision: 0.4289 Recall 0.1640 F1 0.2118\n",
      "val Loss: 0.8719 Acc: 0.2845 Percision: 0.4902 Recall 0.1948 F1 0.2450\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.9299 Acc: 0.2287 Percision: 0.4460 Recall 0.1645 F1 0.2128\n",
      "val Loss: 0.8574 Acc: 0.2848 Percision: 0.4955 Recall 0.1894 F1 0.2357\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.9293 Acc: 0.2244 Percision: 0.4492 Recall 0.1630 F1 0.2111\n",
      "val Loss: 1.4914 Acc: 0.2835 Percision: 0.4502 Recall 0.1894 F1 0.2355\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.9326 Acc: 0.2264 Percision: 0.4302 Recall 0.1613 F1 0.2094\n",
      "val Loss: 0.8573 Acc: 0.2833 Percision: 0.4919 Recall 0.1917 F1 0.2399\n",
      "\n",
      "Training complete in 362m 36s\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "c6216757e2fd5f18f15c28d27f29427270f3789b"
   },
   "outputs": [],
   "source": [
    "# summary(model_ft, (4, IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
