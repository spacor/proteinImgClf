{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27de3105570afc167f91c9c584f0e8b71d617ac4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "292842c5bcc867ce181a7b52b34dd7d74354ff33"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "186296f8ccdb08346ed223c43cb4e38be95947b5"
   },
   "outputs": [],
   "source": [
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bed5a271ff1afc4bff4be794be184f00c3364460"
   },
   "outputs": [],
   "source": [
    "base_path = r'../input'\n",
    "# base_path = r'input'\n",
    "PATH_TRAIN_ANNO = os.path.join(base_path, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(base_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ff7b07dabe69d88fa097cb8077669863de0935c"
   },
   "outputs": [],
   "source": [
    "os.listdir(PATH_TRAIN_IMG)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d387664cc7b19730a1710c4a80ac9a1ba3f188a1"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28\n",
    "MAX_TAGS = 5\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "VAL_SIZE =0.33\n",
    "THRESHOLD = 0.5\n",
    "SAMPLES = 1\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d3f3869cf89b2c418b6b8bcb167e496583c0202f"
   },
   "outputs": [],
   "source": [
    "def get_transform_anno(annotation_path, img_path):\n",
    "    df = pd.read_csv(annotation_path)\n",
    "    annotations = []\n",
    "    for i, row in df.iterrows():\n",
    "        rcd_id = row['Id']\n",
    "        rcd_cate =  [int(j) for j in row['Target'].split()]\n",
    "        annotations.append((rcd_id, rcd_cate))\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6bed24f78c30c8e5c761df5c46a330d28abf05d"
   },
   "outputs": [],
   "source": [
    "#get annotations\n",
    "annotations = get_transform_anno(PATH_TRAIN_ANNO, PATH_TRAIN_IMG)\n",
    "sample_size = int(len(annotations) * SAMPLES)\n",
    "print('sample size: {}'.format(sample_size))\n",
    "annotations = annotations[:sample_size]\n",
    "pprint(annotations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1ff37cfa9d5ae423677158d678107fe07bca2b6"
   },
   "outputs": [],
   "source": [
    "#find out max tags, which is 5\n",
    "# MAX_TAGS = 0\n",
    "# for i in annotations:\n",
    "#     num_tags = len(i[1])\n",
    "#     if num_tags > MAX_TAGS:\n",
    "#         MAX_TAGS = num_tags\n",
    "# print('max num of tags: {}'.format(MAX_TAGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc0cec3fc521d086c8c42c85a091700ed787c185"
   },
   "outputs": [],
   "source": [
    "#Test augmentation\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Scale({\"height\": 224, \"width\": 224}),\n",
    "    iaa.Sequential([\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Affine(\n",
    "            rotate=(-20, 20),\n",
    "        )\n",
    "    ], random_order=True) # apply augmenters in random order\n",
    "], random_order=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5877156add98adeb74271368021e02d10fad7929"
   },
   "outputs": [],
   "source": [
    "#read raw data\n",
    "ix = 26\n",
    "tmp = annotations[ix]\n",
    "tmp_id = tmp[0]\n",
    "tmp_img_tags = tmp[1]\n",
    "\n",
    "tmp_ch = []\n",
    "channels = ['red', 'blue', 'yellow', 'green']\n",
    "img_file_template = '{}_{}.png'\n",
    "for c in channels:\n",
    "    tmp_ch.append(io.imread(os.path.join(PATH_TRAIN_IMG, img_file_template.format(tmp_id, c))))\n",
    "tmp_img = np.stack(tmp_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c1223050392f1cb406238d3903881f47e3ce2991"
   },
   "outputs": [],
   "source": [
    "tmp_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0026ab1cc484cc8b70436ce388352c9e51b00c66"
   },
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    return ax\n",
    "\n",
    "def show_batch_img_per_channel(imgs):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    for ix, ax in enumerate(axes.flat):\n",
    "        tmp_img = imgs[ix]\n",
    "        ax = show_img(tmp_img, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f34e2f059fd72e218bdcd124bbabd199304b64f0"
   },
   "outputs": [],
   "source": [
    "#display each channel before aug\n",
    "show_batch_img_per_channel(tmp_img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9024be16c14e7f11851f1004a6600aae54b5efdb"
   },
   "outputs": [],
   "source": [
    "seq_det = seq.to_deterministic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "acadb8397033219f6da88ce1e15b42be54a80a33"
   },
   "outputs": [],
   "source": [
    "#augmentation\n",
    "tmp_aug_img=tmp_img.transpose((1, 2, 0))\n",
    "tmp_aug_img = seq_det.augment_images([tmp_aug_img.copy()])[0]\n",
    "tmp_aug_img=tmp_aug_img.transpose((2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "533ccf4e2bf09b3886a6caf8f3d73f37edcfb170"
   },
   "outputs": [],
   "source": [
    "#display each channel after aug\n",
    "show_batch_img_per_channel(tmp_aug_img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5096ab17f096168c30c2c4ae4739c03e65fe74b4"
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, img_meta, max_tags, img_path, transform = None):\n",
    "        self.img_meta = img_meta\n",
    "        self.transform = transform\n",
    "        self.max_tags = max_tags\n",
    "        self.channels = ['red', 'blue', 'yellow', 'green']\n",
    "        self.dummy_value = 28 #for padding\n",
    "        self.img_path = img_path\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id, img_tags= self.img_meta[idx]\n",
    "        ch = []\n",
    "        img_file_template = '{}_{}.png'\n",
    "        for c in channels:\n",
    "            ch.append(io.imread(os.path.join(self.img_path, img_file_template.format(img_id, c))))\n",
    "        img = np.stack(tmp_ch)\n",
    "\n",
    "        #augmentation\n",
    "        if bool(self.transform) is True:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        #pad\n",
    "        img_tags = np.pad(np.array(img_tags), pad_width = (0, self.max_tags), mode = 'constant', constant_values=(self.dummy_value,self.dummy_value))[:self.max_tags]\n",
    "        \n",
    "        #transform to tensor\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img_tags = torch.from_numpy(img_tags)\n",
    "        \n",
    "        output = (img, img_tags)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "993bf7bb1330ea30d8db8f26af2459bddcef77c1"
   },
   "outputs": [],
   "source": [
    "class ImgTfm:\n",
    "    def __init__(self, aug_pipline = None):\n",
    "        self.seq = aug_pipline\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "        seq_det = seq.to_deterministic()\n",
    "        \n",
    "        #augmentation\n",
    "        aug_img=img.copy().transpose((1, 2, 0))\n",
    "        aug_img = seq_det.augment_images([aug_img])[0]\n",
    "        aug_img=aug_img.transpose((2, 1, 0))\n",
    "        \n",
    "        #normalize\n",
    "        aug_img=aug_img/255\n",
    "        \n",
    "        return aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b309013cd4db65b0fd295fb4c4b3d1b5149418de"
   },
   "outputs": [],
   "source": [
    "def get_aug_pipline(img_size, mode = 'train'):\n",
    "    if mode == 'train':\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "            iaa.Sequential([\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Affine(\n",
    "                    rotate=(-20, 20),\n",
    "                )\n",
    "            ], random_order=True) # apply augmenters in random order\n",
    "        ], random_order=False)\n",
    "    else: #ie.val\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "        ], random_order=False)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9dbf0260236e9f6a2ad2e1dc732739e11476c2e"
   },
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(annotations, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "composed = {}\n",
    "composed['train'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'train'))])\n",
    "composed['val'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'val'))])\n",
    "\n",
    "image_datasets = {'train': ProteinDataset(train_set, max_tags = MAX_TAGS, img_path = PATH_TRAIN_IMG, transform=composed['train']),\n",
    "                 'val': ProteinDataset(val_set, max_tags = MAX_TAGS, img_path = PATH_TRAIN_IMG, transform=composed['val'])}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c183c83281df73b1c9cb36a33c4a48830edc339b"
   },
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca1f14d3932fd13842300094dd910f3860582ac8"
   },
   "outputs": [],
   "source": [
    "#test dataset\n",
    "ix = 10\n",
    "tmp_img, tmp_tags  = image_datasets['train'][ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e71282fede26391eea444dbc6fef1834e8d04d1"
   },
   "outputs": [],
   "source": [
    "#test dataloader\n",
    "tmp_img, tmp_tags = next(iter(dataloaders['train']))\n",
    "print('tmp_img shape: {}\\ntmp_tags: shape {}'.format(tmp_img.shape, tmp_tags.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab57284d8f683e5c7f1c2f069870305d95b67e0f"
   },
   "outputs": [],
   "source": [
    "def inverse_transform(img_torch):\n",
    "    \"\"\"denormalize and inverse transform img\"\"\"\n",
    "#     inv_normalize = transforms.Normalize(\n",
    "#         mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "#         std=[1/0.229, 1/0.224, 1/0.255]\n",
    "#     )\n",
    "    tmp = deepcopy(img_torch)\n",
    "#     inv_normalize(tmp)\n",
    "    tmp = np.clip((tmp.numpy().transpose((1,2,0)) * 255), a_min=0, a_max=255).astype(np.int)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "99d4e1e4f9de62d96baedb06439a1bcf97aa8c2a"
   },
   "outputs": [],
   "source": [
    "def show_batch_img(imgs):\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
    "    for ix, ax in enumerate(axes.flat):\n",
    "        tmp_img = imgs[ix][:3] #showing first 3 channel only\n",
    "        tmp_img = inverse_transform(tmp_img)\n",
    "        ax = show_img(tmp_img, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24464eff27339774bb747d58b0b9656dd488af4c"
   },
   "outputs": [],
   "source": [
    "show_batch_img(tmp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e522c20046d423926e09324cc72033b4c6f7194"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class RnetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = self._prep_backbone()\n",
    "        \n",
    "    def _prep_backbone(self):     \n",
    "        base_model = models.resnet34(pretrained=False)\n",
    "        removed = list(base_model.children())[1:-2]\n",
    "        backbone = nn.Sequential(*removed)\n",
    "#         for param in backbone.parameters():\n",
    "#             param.require_grad = False\n",
    "        return backbone\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p=0.5)\n",
    "        self.fc_2 = nn.Linear(512 * 7 * 7, 256)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(256)\n",
    "        self.dropout_2 = nn.Dropout(p=0.5)\n",
    "        self.fc_3 = nn.Linear(256, self.num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc_3(x)\n",
    "        return x\n",
    "\n",
    "class CustomEntry(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        return x\n",
    "    \n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.custom_entry = CustomEntry()\n",
    "        self.backbone = RnetBackbone()\n",
    "        self.custom_head = CustomHead(num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.custom_entry(x)\n",
    "        x = self.backbone(x)\n",
    "        x = self.custom_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15d0f869c2cabd57d685494df9cd9bbec54c44d0"
   },
   "outputs": [],
   "source": [
    "def k_hot_embedding(labels, num_classes):\n",
    "    khot = torch.eye(num_classes)[labels.data.cpu()]\n",
    "    khot = khot.sum(1).clamp(0,1)\n",
    "    return khot\n",
    "    \n",
    "def criterion(y_pred, y_true):\n",
    "    #prep y_true\n",
    "    y_true_khot = k_hot_embedding(y_true, num_classes = NUM_CLASSES + 1)\n",
    "    y_true_khot = y_true_khot[:, :-1] #last element is dummy\n",
    "    y_true_khot = y_true_khot.to(DEVICE)\n",
    "    \n",
    "    #calculate loss\n",
    "    \n",
    "    loss = F.binary_cross_entropy_with_logits(y_pred, y_true_khot)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "344ba573c50aaa2569581e57e1a845d3857ee252"
   },
   "outputs": [],
   "source": [
    "a = torch.from_numpy(np.random.rand(5,4)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "302659720f37d52fe1f286f6e2818c7f5bac2951"
   },
   "outputs": [],
   "source": [
    "(a > 0.5).cpu().numpy().astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb26f89e9b6335842f42555e1d6356e7e15fabb2"
   },
   "outputs": [],
   "source": [
    "def prep_stats(y_pred, y_true):\n",
    "    #prep y_true\n",
    "    y_true_khot = k_hot_embedding(y_true, num_classes = NUM_CLASSES + 1)\n",
    "    y_true_khot = y_true_khot[:, :-1].cpu().numpy().astype('uint8') #last element is dummy\n",
    "    \n",
    "    #prep y_pred khot\n",
    "    y_pred_khot = (torch.sigmoid(y_pred) > THRESHOLD).cpu().numpy().astype('uint8')\n",
    "    \n",
    "    return y_pred_khot, y_true_khot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cae1139e883e11b9acb66107d44ca438379df5ea"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_y_true = []\n",
    "            running_y_pred = []\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    y_pred_khot, y_true_khot = prep_stats(outputs, targets)\n",
    "                    running_y_pred.append(y_pred_khot)\n",
    "                    running_y_true.append(y_true_khot)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "#                 running_corrects += torch.sum(preds == categories.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "#             epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            epoch_acc = accuracy_score(np.vstack(running_y_true), np.vstack(running_y_pred))\n",
    "            epoch_precision = precision_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_recall = recall_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_f1 = f1_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Percision: {:.4f} Recall {:.4f} F1 {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3630da25b7d9bec8d1a872bddac54ddc92744119"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = CustomNet(num_class=NUM_CLASSES)\n",
    "model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12d01bd529bd2f40bb8ff6d952f35237ac4bd1f5"
   },
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15cf23cbb33e86a9218c12fccf2b617e1e3fd120"
   },
   "outputs": [],
   "source": [
    "# tmp_img, tmp_tags = next(iter(dataloaders['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0bf0eb4ebf99677af33bc06495e797b0408fc93"
   },
   "outputs": [],
   "source": [
    "# tmp_y_pred = model_ft(tmp_img)\n",
    "# tmp_y_pred.shape\n",
    "# tmp_tags.shape\n",
    "\n",
    "# y_pred_khot, y_true_khot = prep_stats(tmp_y_pred, tmp_tags)\n",
    "\n",
    "# np.vstack([y_pred_khot, y_true_khot]).shape\n",
    "\n",
    "# precision_score(y_true_khot, y_pred_khot, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f575f610066b73bdb2f2b6a79371d7d399fa97f1"
   },
   "outputs": [],
   "source": [
    "# tmp_img = tmp_img.to(DEVICE)\n",
    "# tmp_y_pred = model_ft(tmp_img)\n",
    "\n",
    "# y_pred_khot, y_true_khot = prep_stats(tmp_y_pred, tmp_tags)\n",
    "\n",
    "# precision_score(y_true_khot, y_pred_khot, average='macro')\n",
    "\n",
    "# recall_score(y_true_khot, y_pred_khot, average='macro')\n",
    "\n",
    "# f1_score(y_true_khot, y_pred_khot, average='macro')\n",
    "\n",
    "# accuracy_score(y_true_khot, y_pred_khot)\n",
    "\n",
    "# y_true_khot[1]\n",
    "\n",
    "# y_pred_khot[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "199996f76454f0395c031435f63fb34a4f09e181"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
