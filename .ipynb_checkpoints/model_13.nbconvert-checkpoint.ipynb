{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4248fd9c0afae8eaac391ab0d1895db2be249e75"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# base_path = r'../input'\n",
    "base_path = r'input'\n",
    "PATH_TRAIN_ANNO = os.path.join(base_path, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(base_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "583ead53ccf420ab4290230a0a17cc3b6c62c74d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    USE_TENSORBOARD = True\n",
    "    writer = SummaryWriter()\n",
    "except:\n",
    "    USE_TENSORBOARD = False\n",
    "    print('No tensorboard X')\n",
    "\n",
    "def record_tb(phase, tag, value, global_step):\n",
    "    if USE_TENSORBOARD is True:\n",
    "        writer.add_scalar('{phase}/{tag}'.format(phase=phase, tag=tag), value, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7a95c899247b666f9235e3100a569744c46bf943"
   },
   "outputs": [],
   "source": [
    "# os.listdir(PATH_TRAIN_IMG)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e85715fa2a9217474fc039c2b399c9b33490689a"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28\n",
    "MAX_TAGS = 5\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "VAL_SIZE =0.2\n",
    "THRESHOLD = 0.5\n",
    "SAMPLES = 1\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "7e81577b2c725960293a5cfabb29e0d46d66834c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 31072\n",
      "[('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', [16, 0]),\n",
      " ('000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', [7, 1, 2, 0]),\n",
      " ('000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', [5])]\n"
     ]
    }
   ],
   "source": [
    "def get_transform_anno(annotation_path, img_path):\n",
    "    df = pd.read_csv(annotation_path)\n",
    "    annotations = []\n",
    "    for i, row in df.iterrows():\n",
    "        rcd_id = row['Id']\n",
    "        rcd_cate =  [int(j) for j in row['Target'].split()]\n",
    "        annotations.append((rcd_id, rcd_cate))\n",
    "    return annotations\n",
    "#get annotations\n",
    "annotations = get_transform_anno(PATH_TRAIN_ANNO, PATH_TRAIN_IMG)\n",
    "sample_size = int(len(annotations) * SAMPLES)\n",
    "print('sample size: {}'.format(sample_size))\n",
    "annotations = annotations[:sample_size]\n",
    "pprint(annotations[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "878d1a4d5d29884cc313258347df1ee630abae1a"
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, img_meta, img_path, transform = None):\n",
    "        self.img_meta = img_meta\n",
    "        self.transform = transform\n",
    "        self.channels = ['red', 'blue', 'yellow', 'green']\n",
    "        self.img_path = img_path\n",
    "        self.mlb = MultiLabelBinarizer(classes=range(0,NUM_CLASSES))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id, img_tags= self.img_meta[idx]\n",
    "        ch = []\n",
    "        img_file_template = '{}_{}.png'\n",
    "        for c in self.channels:\n",
    "            ch.append(io.imread(os.path.join(self.img_path, img_file_template.format(img_id, c))))\n",
    "        img = np.stack(ch)\n",
    "\n",
    "        #augmentation\n",
    "        if bool(self.transform) is True:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        #binarize\n",
    "        img_tags = self.mlb.fit_transform([img_tags]).squeeze()\n",
    "        \n",
    "        #transform to tensor\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img_tags = torch.from_numpy(img_tags)\n",
    "        \n",
    "        output = (img, img_tags)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "af583f0882e55fd31a3df230822ac86f99e25f4c"
   },
   "outputs": [],
   "source": [
    "class ImgTfm:\n",
    "    def __init__(self, aug_pipline = None):\n",
    "        self.seq = aug_pipline\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "#         seq_det = self.seq.to_deterministic()\n",
    "        \n",
    "        #augmentation\n",
    "        aug_img=img.copy().transpose((1, 2, 0))\n",
    "        aug_img = self.seq.augment_images([aug_img])[0]\n",
    "        aug_img=aug_img.transpose((2, 1, 0))\n",
    "        \n",
    "        #normalize\n",
    "        aug_img=aug_img/255\n",
    "        \n",
    "        return aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "7c0aeb64e2a7b651582a467d82079a2fda67c71b"
   },
   "outputs": [],
   "source": [
    "def get_aug_pipline(img_size, mode = 'train'):\n",
    "    if mode == 'train':\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "            iaa.Sequential([\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Affine(\n",
    "                    rotate=(-20, 20),\n",
    "                )\n",
    "            ], random_order=True) # apply augmenters in random order\n",
    "        ], random_order=False)\n",
    "    else: #ie.val\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "        ], random_order=False)\n",
    "#     seq = iaa.Sequential([\n",
    "#                 iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "#             ], random_order=False)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "4c926ebe55fb37a7bfe3ffb2d6da2b145fb5f747"
   },
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(annotations, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "composed = {}\n",
    "composed['train'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'train'))])\n",
    "composed['val'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'val'))])\n",
    "\n",
    "image_datasets = {'train': ProteinDataset(train_set, img_path = PATH_TRAIN_IMG, transform=composed['train']),\n",
    "                 'val': ProteinDataset(val_set, img_path = PATH_TRAIN_IMG, transform=composed['val'])}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "e8c442abb721b3f65c4a7b076232757725311b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 24857, 'val': 6215}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "610b2e7a2e2b430673460bfd21e2940eca4a83b1"
   },
   "outputs": [],
   "source": [
    "#test dataset\n",
    "# ix = 10\n",
    "# tmp_img, tmp_tags  = image_datasets['train'][ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "116981e26006844aba80864a76434c9b0a445188"
   },
   "outputs": [],
   "source": [
    "#test dataloader\n",
    "# tmp_img, tmp_tags = next(iter(dataloaders['train']))\n",
    "# print('tmp_img shape: {}\\ntmp_tags: shape {}'.format(tmp_img.shape, tmp_tags.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "53926b18c61ec3d5f167ee905fcde5c0dc9289f5"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class RnetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = self._prep_backbone()\n",
    "        \n",
    "    def _prep_backbone(self):     \n",
    "        base_model = models.resnet34(pretrained=True)\n",
    "        removed = list(base_model.children())[1:-2]\n",
    "        backbone = nn.Sequential(*removed)\n",
    "#         for param in backbone.parameters():\n",
    "#             param.require_grad = False\n",
    "        return backbone\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p=0.5)\n",
    "        self.fc_2 = nn.Linear(512 * 7 * 7, 256)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(256)\n",
    "        self.dropout_2 = nn.Dropout(p=0.5)\n",
    "        self.fc_3 = nn.Linear(256, self.num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc_3(x)\n",
    "        return x\n",
    "\n",
    "# class CustomEntry(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#         nn.init.kaiming_normal_(self.conv_1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv_1(x)\n",
    "#         return x\n",
    "\n",
    "class CustomEntry(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = self._prep_layers()\n",
    "        \n",
    "    def _prep_layers(self):\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        original_entry_w = torch.tensor(list(model.children())[0].weight)\n",
    "        new_entry_w = torch.cat([original_entry_w, torch.zeros(size = (64,1,7,7))], 1)\n",
    "        \n",
    "        conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        conv_1.weight=conv_1.weight = torch.nn.Parameter(new_entry_w)\n",
    "        return conv_1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        return x\n",
    "    \n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.custom_entry = CustomEntry()\n",
    "        self.backbone = RnetBackbone()\n",
    "        self.custom_head = CustomHead(num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.custom_entry(x)\n",
    "        x = self.backbone(x)\n",
    "        x = self.custom_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "4ef191d711342bf7bce65d943f8629d03bcf26c1"
   },
   "outputs": [],
   "source": [
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        #f1 loss\n",
    "#         #prep y_true\n",
    "        y_true = y_true.float()\n",
    "\n",
    "        #prep y_pred\n",
    "        y_pred = torch.tensor(data = (torch.sigmoid(y_pred).ge(THRESHOLD)), dtype=torch.float, device=DEVICE, requires_grad=True)\n",
    "\n",
    "        #calculate loss\n",
    "        tp = (y_true * y_pred).sum(0).float()\n",
    "        # tn = ((1-y_true) * (1-y_pred)).sum(0).float()\n",
    "        fp = ((1-y_true) * y_pred).sum(0).float()\n",
    "        fn = (y_true * (1-y_pred)).sum(0).float()\n",
    "\n",
    "        p = tp / (tp + fp)\n",
    "        r = tp / (tp + fn)\n",
    "\n",
    "        f1 = 2*p*r / (p+r)\n",
    "        f1[torch.isnan(f1)] = 0\n",
    "        f1_loss = 1-f1.mean()\n",
    "#         print(f1_loss)\n",
    "        return f1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        target = target.float()\n",
    "        \n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "34c786807f448f63f4244537f13ebca2a6b44ee2"
   },
   "outputs": [],
   "source": [
    "def prep_stats(y_pred, y_true):\n",
    "    #prep y_true\n",
    "    y_true_tfm = y_true.cpu().numpy().astype('uint8')\n",
    "    \n",
    "    #prep y_pred khot\n",
    "    y_pred_tfm = (torch.sigmoid(y_pred) > THRESHOLD).cpu().numpy().astype('uint8')\n",
    "    \n",
    "    return y_pred_tfm, y_true_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "7df1b550cc9567063a38437001eff118004b0370"
   },
   "outputs": [],
   "source": [
    "def calc_stats(y_pred, y_true, stats = 'accurancy'):\n",
    "    if stats == 'accuracy':\n",
    "        stat_value = accuracy_score(y_true, y_pred)\n",
    "    elif stats == 'precision':\n",
    "        stat_value = precision_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'recall':\n",
    "        stat_value = recall_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'f1':\n",
    "        stat_value = f1_score(y_true, y_pred, average = 'macro')\n",
    "    else:\n",
    "        stat_value = 0\n",
    "    return stat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "467bc143b3e21ddb3674f77f2c78287c9bc3684c"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_y_true = []\n",
    "            running_y_pred = []\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets= targets.to(DEVICE)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    y_pred_tfm, y_true_tfm = prep_stats(outputs, targets)\n",
    "                    running_y_pred.append(y_pred_tfm)\n",
    "                    running_y_true.append(y_true_tfm)\n",
    "                    \n",
    "                    #export step stats duing training phase\n",
    "                    if phase == 'train':\n",
    "                        record_tb(phase, 'loss', loss.cpu().data.numpy(), steps)\n",
    "                        record_tb(phase, 'accuracy', calc_stats(y_pred_tfm, y_true_tfm, stats = 'accurancy'), steps)\n",
    "                        record_tb(phase, 'precision', calc_stats(y_pred_tfm, y_true_tfm, stats = 'precision'), steps)\n",
    "                        record_tb(phase, 'recall', calc_stats(y_pred_tfm, y_true_tfm, stats = 'recall'), steps)\n",
    "                        record_tb(phase, 'f1', calc_stats(y_pred_tfm, y_true_tfm, stats = 'f1'), steps)\n",
    "                        steps += 1\n",
    "                        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            #calc epoch stats\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = accuracy_score(np.vstack(running_y_true), np.vstack(running_y_pred))\n",
    "            epoch_precision = precision_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_recall = recall_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_f1 = f1_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            \n",
    "            #export epoch stats duing training phase\n",
    "            if phase == 'val':\n",
    "                record_tb(phase, 'loss', epoch_loss, steps)\n",
    "                record_tb(phase, 'accuracy', epoch_acc, steps)\n",
    "                record_tb(phase, 'precision', epoch_precision, steps)\n",
    "                record_tb(phase, 'recall', epoch_recall, steps)\n",
    "                record_tb(phase, 'f1', epoch_f1, steps)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Percision: {:.4f} Recall {:.4f} F1 {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "be546ee708d7ccb01c9f876bb189db4818a7d12a"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = CustomNet(num_class=NUM_CLASSES)\n",
    "model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "criterion = FocalLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze backbone\n",
    "for param in model_ft.backbone.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3608 Acc: 0.0507 Percision: 0.0913 Recall 0.0376 F1 0.0480\n",
      "val Loss: 2.1804 Acc: 0.0668 Percision: 0.1308 Recall 0.0325 F1 0.0333\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 1.2197 Acc: 0.0689 Percision: 0.2080 Recall 0.0399 F1 0.0504\n",
      "val Loss: 1.5314 Acc: 0.0836 Percision: 0.1304 Recall 0.0446 F1 0.0589\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 1.1837 Acc: 0.0854 Percision: 0.2367 Recall 0.0495 F1 0.0642\n",
      "val Loss: 1.1595 Acc: 0.1244 Percision: 0.2459 Recall 0.0640 F1 0.0780\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 1.1634 Acc: 0.0975 Percision: 0.2379 Recall 0.0556 F1 0.0725\n",
      "val Loss: 2.3961 Acc: 0.1195 Percision: 0.1877 Recall 0.0664 F1 0.0854\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 1.1489 Acc: 0.1008 Percision: 0.2792 Recall 0.0615 F1 0.0819\n",
      "val Loss: 1.1537 Acc: 0.1247 Percision: 0.2288 Recall 0.0659 F1 0.0766\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 1.1400 Acc: 0.1070 Percision: 0.2770 Recall 0.0649 F1 0.0866\n",
      "val Loss: 1.1775 Acc: 0.1115 Percision: 0.2879 Recall 0.0551 F1 0.0701\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 1.1193 Acc: 0.1133 Percision: 0.3118 Recall 0.0720 F1 0.0978\n",
      "val Loss: 1.0890 Acc: 0.1282 Percision: 0.3227 Recall 0.0800 F1 0.1070\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 1.1071 Acc: 0.1219 Percision: 0.2913 Recall 0.0771 F1 0.1048\n",
      "val Loss: 1.0738 Acc: 0.1263 Percision: 0.2507 Recall 0.0636 F1 0.0813\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 1.1030 Acc: 0.1236 Percision: 0.3165 Recall 0.0795 F1 0.1082\n",
      "val Loss: 2.0392 Acc: 0.1268 Percision: 0.2725 Recall 0.0721 F1 0.0983\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 1.0966 Acc: 0.1267 Percision: 0.3073 Recall 0.0847 F1 0.1164\n",
      "val Loss: 1.2049 Acc: 0.1416 Percision: 0.3129 Recall 0.0860 F1 0.1133\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 1.0582 Acc: 0.1391 Percision: 0.3460 Recall 0.0954 F1 0.1326\n",
      "val Loss: 1.8308 Acc: 0.1562 Percision: 0.3269 Recall 0.0927 F1 0.1260\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 1.0456 Acc: 0.1445 Percision: 0.3703 Recall 0.0996 F1 0.1372\n",
      "val Loss: 1.8432 Acc: 0.1543 Percision: 0.3572 Recall 0.0912 F1 0.1259\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 1.0414 Acc: 0.1469 Percision: 0.4359 Recall 0.0991 F1 0.1366\n",
      "val Loss: 1.9417 Acc: 0.1616 Percision: 0.3369 Recall 0.0951 F1 0.1301\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 1.0340 Acc: 0.1515 Percision: 0.3669 Recall 0.1062 F1 0.1465\n",
      "val Loss: 1.1143 Acc: 0.1561 Percision: 0.3140 Recall 0.0934 F1 0.1284\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 1.0349 Acc: 0.1525 Percision: 0.4118 Recall 0.1058 F1 0.1460\n",
      "val Loss: 1.3608 Acc: 0.1619 Percision: 0.3394 Recall 0.0969 F1 0.1336\n",
      "\n",
      "Training complete in 76m 13s\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_ft.backbone.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different learning rate for different layers\n",
    "optimizer_ft = optim.Adam([\n",
    "    {'params': model_ft.custom_entry.parameters()},\n",
    "    {'params': model_ft.backbone.parameters(), 'lr': 0.001},\n",
    "    {'params': model_ft.custom_head.parameters()},\n",
    "    ]\n",
    ")\n",
    "# Decay LR by a factor of 0.1 every n epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "a27461b7756ca489c66881be19cb1d0d54bf5d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/34\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0833 Acc: 0.1408 Percision: 0.3557 Recall 0.0914 F1 0.1239\n",
      "val Loss: 1.1811 Acc: 0.1358 Percision: 0.2557 Recall 0.1049 F1 0.1227\n",
      "\n",
      "Epoch 1/34\n",
      "----------\n",
      "train Loss: 0.9829 Acc: 0.2044 Percision: 0.3860 Recall 0.1429 F1 0.1857\n",
      "val Loss: 0.9536 Acc: 0.2366 Percision: 0.3171 Recall 0.1528 F1 0.1883\n",
      "\n",
      "Epoch 2/34\n",
      "----------\n",
      "train Loss: 0.9387 Acc: 0.2317 Percision: 0.4548 Recall 0.1706 F1 0.2207\n",
      "val Loss: 0.9253 Acc: 0.2558 Percision: 0.4242 Recall 0.1797 F1 0.2160\n",
      "\n",
      "Epoch 3/34\n",
      "----------\n",
      "train Loss: 0.9089 Acc: 0.2532 Percision: 0.4366 Recall 0.1889 F1 0.2423\n",
      "val Loss: 0.8654 Acc: 0.2875 Percision: 0.5189 Recall 0.1913 F1 0.2390\n",
      "\n",
      "Epoch 4/34\n",
      "----------\n",
      "train Loss: 0.8805 Acc: 0.2712 Percision: 0.5372 Recall 0.2072 F1 0.2635\n",
      "val Loss: 0.9000 Acc: 0.2743 Percision: 0.4493 Recall 0.1965 F1 0.2390\n",
      "\n",
      "Epoch 5/34\n",
      "----------\n",
      "train Loss: 0.8606 Acc: 0.2852 Percision: 0.4760 Recall 0.2222 F1 0.2811\n",
      "val Loss: 0.9570 Acc: 0.2566 Percision: 0.4884 Recall 0.1983 F1 0.2403\n",
      "\n",
      "Epoch 6/34\n",
      "----------\n",
      "train Loss: 0.8401 Acc: 0.3056 Percision: 0.5185 Recall 0.2373 F1 0.2987\n",
      "val Loss: 0.9061 Acc: 0.3035 Percision: 0.4753 Recall 0.2114 F1 0.2540\n",
      "\n",
      "Epoch 7/34\n",
      "----------\n",
      "train Loss: 0.8187 Acc: 0.3139 Percision: 0.4943 Recall 0.2515 F1 0.3146\n",
      "val Loss: 0.8111 Acc: 0.3199 Percision: 0.5535 Recall 0.2468 F1 0.3101\n",
      "\n",
      "Epoch 8/34\n",
      "----------\n",
      "train Loss: 0.8077 Acc: 0.3244 Percision: 0.5581 Recall 0.2625 F1 0.3275\n",
      "val Loss: 0.8260 Acc: 0.3172 Percision: 0.5697 Recall 0.2570 F1 0.3131\n",
      "\n",
      "Epoch 9/34\n",
      "----------\n",
      "train Loss: 0.7942 Acc: 0.3344 Percision: 0.5402 Recall 0.2753 F1 0.3442\n",
      "val Loss: 0.8553 Acc: 0.3323 Percision: 0.5107 Recall 0.2578 F1 0.3059\n",
      "\n",
      "Epoch 10/34\n",
      "----------\n",
      "train Loss: 0.7296 Acc: 0.3700 Percision: 0.6829 Recall 0.3086 F1 0.3821\n",
      "val Loss: 0.7269 Acc: 0.3826 Percision: 0.6306 Recall 0.3023 F1 0.3739\n",
      "\n",
      "Epoch 11/34\n",
      "----------\n",
      "train Loss: 0.7051 Acc: 0.3872 Percision: 0.6695 Recall 0.3411 F1 0.4216\n",
      "val Loss: 0.7219 Acc: 0.3918 Percision: 0.6487 Recall 0.3128 F1 0.3875\n",
      "\n",
      "Epoch 12/34\n",
      "----------\n",
      "train Loss: 0.6950 Acc: 0.3988 Percision: 0.6598 Recall 0.3427 F1 0.4193\n",
      "val Loss: 0.7179 Acc: 0.3966 Percision: 0.6430 Recall 0.3272 F1 0.4043\n",
      "\n",
      "Epoch 13/34\n",
      "----------\n",
      "train Loss: 0.6839 Acc: 0.4024 Percision: 0.6643 Recall 0.3576 F1 0.4362\n",
      "val Loss: 0.7137 Acc: 0.3967 Percision: 0.6322 Recall 0.3278 F1 0.4022\n",
      "\n",
      "Epoch 14/34\n",
      "----------\n",
      "train Loss: 0.6785 Acc: 0.4096 Percision: 0.6682 Recall 0.3555 F1 0.4329\n",
      "val Loss: 0.7101 Acc: 0.4032 Percision: 0.6898 Recall 0.3417 F1 0.4193\n",
      "\n",
      "Epoch 15/34\n",
      "----------\n",
      "train Loss: 0.6707 Acc: 0.4094 Percision: 0.6539 Recall 0.3648 F1 0.4430\n",
      "val Loss: 0.7171 Acc: 0.4006 Percision: 0.6781 Recall 0.3479 F1 0.4289\n",
      "\n",
      "Epoch 16/34\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.4185 Percision: 0.6864 Recall 0.3852 F1 0.4655\n",
      "val Loss: 0.7077 Acc: 0.4053 Percision: 0.6809 Recall 0.3434 F1 0.4222\n",
      "\n",
      "Epoch 17/34\n",
      "----------\n",
      "train Loss: 0.6523 Acc: 0.4217 Percision: 0.6671 Recall 0.3822 F1 0.4603\n",
      "val Loss: 0.7094 Acc: 0.4101 Percision: 0.6533 Recall 0.3551 F1 0.4302\n",
      "\n",
      "Epoch 18/34\n",
      "----------\n",
      "train Loss: 0.6446 Acc: 0.4282 Percision: 0.6656 Recall 0.3915 F1 0.4716\n",
      "val Loss: 0.7106 Acc: 0.4064 Percision: 0.6940 Recall 0.3565 F1 0.4346\n",
      "\n",
      "Epoch 19/34\n",
      "----------\n",
      "train Loss: 0.6349 Acc: 0.4308 Percision: 0.6957 Recall 0.4114 F1 0.4936\n",
      "val Loss: 0.7120 Acc: 0.4119 Percision: 0.7335 Recall 0.3551 F1 0.4357\n",
      "\n",
      "Epoch 20/34\n",
      "----------\n",
      "train Loss: 0.6186 Acc: 0.4404 Percision: 0.7016 Recall 0.3983 F1 0.4800\n",
      "val Loss: 0.7044 Acc: 0.4158 Percision: 0.7038 Recall 0.3698 F1 0.4518\n",
      "\n",
      "Epoch 21/34\n",
      "----------\n",
      "train Loss: 0.6136 Acc: 0.4428 Percision: 0.6859 Recall 0.4082 F1 0.4879\n",
      "val Loss: 0.7084 Acc: 0.4112 Percision: 0.7046 Recall 0.3651 F1 0.4494\n",
      "\n",
      "Epoch 22/34\n",
      "----------\n",
      "train Loss: 0.6163 Acc: 0.4413 Percision: 0.6972 Recall 0.4160 F1 0.4986\n",
      "val Loss: 0.7069 Acc: 0.4159 Percision: 0.6975 Recall 0.3686 F1 0.4519\n",
      "\n",
      "Epoch 23/34\n",
      "----------\n",
      "train Loss: 0.6103 Acc: 0.4505 Percision: 0.6742 Recall 0.4218 F1 0.4991\n",
      "val Loss: 0.7059 Acc: 0.4159 Percision: 0.6967 Recall 0.3705 F1 0.4526\n",
      "\n",
      "Epoch 24/34\n",
      "----------\n",
      "train Loss: 0.6095 Acc: 0.4470 Percision: 0.7004 Recall 0.4168 F1 0.4984\n",
      "val Loss: 0.7082 Acc: 0.4180 Percision: 0.6850 Recall 0.3721 F1 0.4539\n",
      "\n",
      "Epoch 25/34\n",
      "----------\n",
      "train Loss: 0.6092 Acc: 0.4479 Percision: 0.6924 Recall 0.4173 F1 0.4969\n",
      "val Loss: 0.7106 Acc: 0.4132 Percision: 0.7026 Recall 0.3685 F1 0.4509\n",
      "\n",
      "Epoch 26/34\n",
      "----------\n",
      "train Loss: 0.6042 Acc: 0.4516 Percision: 0.7335 Recall 0.4231 F1 0.5082\n",
      "val Loss: 0.7064 Acc: 0.4132 Percision: 0.6983 Recall 0.3718 F1 0.4536\n",
      "\n",
      "Epoch 27/34\n",
      "----------\n",
      "train Loss: 0.6055 Acc: 0.4508 Percision: 0.6959 Recall 0.4270 F1 0.5065\n",
      "val Loss: 0.7046 Acc: 0.4174 Percision: 0.7009 Recall 0.3736 F1 0.4564\n",
      "\n",
      "Epoch 28/34\n",
      "----------\n",
      "train Loss: 0.6045 Acc: 0.4510 Percision: 0.6962 Recall 0.4324 F1 0.5141\n",
      "val Loss: 0.7088 Acc: 0.4138 Percision: 0.6924 Recall 0.3725 F1 0.4539\n",
      "\n",
      "Epoch 29/34\n",
      "----------\n",
      "train Loss: 0.6047 Acc: 0.4487 Percision: 0.7359 Recall 0.4315 F1 0.5134\n",
      "val Loss: 0.7093 Acc: 0.4164 Percision: 0.7255 Recall 0.3702 F1 0.4541\n",
      "\n",
      "Epoch 30/34\n",
      "----------\n",
      "train Loss: 0.6016 Acc: 0.4521 Percision: 0.6827 Recall 0.4234 F1 0.5022\n",
      "val Loss: 0.7046 Acc: 0.4187 Percision: 0.6968 Recall 0.3725 F1 0.4541\n",
      "\n",
      "Epoch 31/34\n",
      "----------\n",
      "train Loss: 0.6005 Acc: 0.4543 Percision: 0.6909 Recall 0.4247 F1 0.5019\n",
      "val Loss: 0.7067 Acc: 0.4191 Percision: 0.7141 Recall 0.3731 F1 0.4575\n",
      "\n",
      "Epoch 32/34\n",
      "----------\n",
      "train Loss: 0.5988 Acc: 0.4562 Percision: 0.7443 Recall 0.4426 F1 0.5248\n",
      "val Loss: 0.7055 Acc: 0.4175 Percision: 0.6812 Recall 0.3745 F1 0.4539\n",
      "\n",
      "Epoch 33/34\n",
      "----------\n",
      "train Loss: 0.5984 Acc: 0.4558 Percision: 0.7003 Recall 0.4268 F1 0.5065\n",
      "val Loss: 0.7079 Acc: 0.4162 Percision: 0.6964 Recall 0.3706 F1 0.4536\n",
      "\n",
      "Epoch 34/34\n",
      "----------\n",
      "train Loss: 0.5978 Acc: 0.4556 Percision: 0.6897 Recall 0.4247 F1 0.5033\n",
      "val Loss: 0.7087 Acc: 0.4159 Percision: 0.6946 Recall 0.3747 F1 0.4574\n",
      "\n",
      "Training complete in 242m 19s\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
