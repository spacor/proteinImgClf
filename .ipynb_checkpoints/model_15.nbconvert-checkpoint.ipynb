{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# base_path = r'../input'\n",
    "base_path = r'input'\n",
    "PATH_TRAIN_ANNO = os.path.join(base_path, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(base_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "583ead53ccf420ab4290230a0a17cc3b6c62c74d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    USE_TENSORBOARD = True\n",
    "    writer = SummaryWriter()\n",
    "except:\n",
    "    USE_TENSORBOARD = False\n",
    "    print('No tensorboard X')\n",
    "\n",
    "def record_tb(phase, tag, value, global_step):\n",
    "    if USE_TENSORBOARD is True:\n",
    "        writer.add_scalar('{phase}/{tag}'.format(phase=phase, tag=tag), value, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7a95c899247b666f9235e3100a569744c46bf943"
   },
   "outputs": [],
   "source": [
    "# os.listdir(PATH_TRAIN_IMG)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e85715fa2a9217474fc039c2b399c9b33490689a"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28\n",
    "MAX_TAGS = 5\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "VAL_SIZE =0.2\n",
    "THRESHOLD = 0.5\n",
    "SAMPLES = 1\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7e81577b2c725960293a5cfabb29e0d46d66834c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 31072\n",
      "[('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', [16, 0]),\n",
      " ('000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', [7, 1, 2, 0]),\n",
      " ('000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', [5])]\n"
     ]
    }
   ],
   "source": [
    "def get_transform_anno(annotation_path, img_path):\n",
    "    df = pd.read_csv(annotation_path)\n",
    "    annotations = []\n",
    "    for i, row in df.iterrows():\n",
    "        rcd_id = row['Id']\n",
    "        rcd_cate =  [int(j) for j in row['Target'].split()]\n",
    "        annotations.append((rcd_id, rcd_cate))\n",
    "    return annotations\n",
    "#get annotations\n",
    "annotations = get_transform_anno(PATH_TRAIN_ANNO, PATH_TRAIN_IMG)\n",
    "sample_size = int(len(annotations) * SAMPLES)\n",
    "print('sample size: {}'.format(sample_size))\n",
    "annotations = annotations[:sample_size]\n",
    "pprint(annotations[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "878d1a4d5d29884cc313258347df1ee630abae1a"
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, img_meta, img_path, transform = None):\n",
    "        self.img_meta = img_meta\n",
    "        self.transform = transform\n",
    "        self.channels = ['red', 'blue', 'yellow', 'green']\n",
    "        self.img_path = img_path\n",
    "        self.mlb = MultiLabelBinarizer(classes=range(0,NUM_CLASSES))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id, img_tags= self.img_meta[idx]\n",
    "        ch = []\n",
    "        img_file_template = '{}_{}.png'\n",
    "        for c in self.channels:\n",
    "            ch.append(io.imread(os.path.join(self.img_path, img_file_template.format(img_id, c))))\n",
    "        img = np.stack(ch)\n",
    "\n",
    "        #augmentation\n",
    "        if bool(self.transform) is True:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        #binarize\n",
    "        img_tags = self.mlb.fit_transform([img_tags]).squeeze()\n",
    "        \n",
    "        #transform to tensor\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img_tags = torch.from_numpy(img_tags)\n",
    "        \n",
    "        output = (img, img_tags)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "af583f0882e55fd31a3df230822ac86f99e25f4c"
   },
   "outputs": [],
   "source": [
    "class ImgTfm:\n",
    "    def __init__(self, aug_pipline = None):\n",
    "        self.seq = aug_pipline\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "#         seq_det = self.seq.to_deterministic()\n",
    "        \n",
    "        #augmentation\n",
    "        aug_img=img.copy().transpose((1, 2, 0))\n",
    "        aug_img = self.seq.augment_images([aug_img])[0]\n",
    "        aug_img=aug_img.transpose((2, 1, 0))\n",
    "        \n",
    "        #normalize\n",
    "        aug_img=aug_img/255\n",
    "        \n",
    "        return aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "7c0aeb64e2a7b651582a467d82079a2fda67c71b"
   },
   "outputs": [],
   "source": [
    "def get_aug_pipline(img_size, mode = 'train'):\n",
    "    if mode == 'train':\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "            iaa.Sequential([\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Affine(\n",
    "                    rotate=(-20, 20),\n",
    "                )\n",
    "            ], random_order=True) # apply augmenters in random order\n",
    "        ], random_order=False)\n",
    "    else: #ie.val\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "        ], random_order=False)\n",
    "#     seq = iaa.Sequential([\n",
    "#                 iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "#             ], random_order=False)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "4c926ebe55fb37a7bfe3ffb2d6da2b145fb5f747"
   },
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(annotations, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "composed = {}\n",
    "composed['train'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'train'))])\n",
    "composed['val'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'val'))])\n",
    "\n",
    "image_datasets = {'train': ProteinDataset(train_set, img_path = PATH_TRAIN_IMG, transform=composed['train']),\n",
    "                 'val': ProteinDataset(val_set, img_path = PATH_TRAIN_IMG, transform=composed['val'])}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "e8c442abb721b3f65c4a7b076232757725311b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 24857, 'val': 6215}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "610b2e7a2e2b430673460bfd21e2940eca4a83b1"
   },
   "outputs": [],
   "source": [
    "#test dataset\n",
    "# ix = 10\n",
    "# tmp_img, tmp_tags  = image_datasets['train'][ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "116981e26006844aba80864a76434c9b0a445188"
   },
   "outputs": [],
   "source": [
    "#test dataloader\n",
    "# tmp_img, tmp_tags = next(iter(dataloaders['train']))\n",
    "# print('tmp_img shape: {}\\ntmp_tags: shape {}'.format(tmp_img.shape, tmp_tags.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "53926b18c61ec3d5f167ee905fcde5c0dc9289f5"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class RnetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = self._prep_backbone()\n",
    "        \n",
    "    def _prep_backbone(self):     \n",
    "        base_model = models.resnet34(pretrained=True)\n",
    "        removed = list(base_model.children())[1:-2]\n",
    "        backbone = nn.Sequential(*removed)\n",
    "#         for param in backbone.parameters():\n",
    "#             param.require_grad = False\n",
    "        return backbone\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p=0.5)\n",
    "        self.fc_2 = nn.Linear(512 * 7 * 7, 256)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(256)\n",
    "        self.dropout_2 = nn.Dropout(p=0.5)\n",
    "        self.fc_3 = nn.Linear(256, self.num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc_3(x)\n",
    "        return x\n",
    "\n",
    "# class CustomEntry(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#         nn.init.kaiming_normal_(self.conv_1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv_1(x)\n",
    "#         return x\n",
    "\n",
    "class CustomEntry(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = self._prep_layers()\n",
    "        \n",
    "    def _prep_layers(self):\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        original_entry_w = torch.tensor(list(model.children())[0].weight)\n",
    "        new_entry_w = torch.cat([original_entry_w, torch.zeros(size = (64,1,7,7))], 1)\n",
    "        \n",
    "        conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        conv_1.weight=conv_1.weight = torch.nn.Parameter(new_entry_w)\n",
    "        return conv_1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        return x\n",
    "    \n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.custom_entry = CustomEntry()\n",
    "        self.backbone = RnetBackbone()\n",
    "        self.custom_head = CustomHead(num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.custom_entry(x)\n",
    "        x = self.backbone(x)\n",
    "        x = self.custom_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "4ef191d711342bf7bce65d943f8629d03bcf26c1"
   },
   "outputs": [],
   "source": [
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        #f1 loss\n",
    "#         #prep y_true\n",
    "        y_true = y_true.float()\n",
    "\n",
    "        #prep y_pred\n",
    "        y_pred = torch.tensor(data = (torch.sigmoid(y_pred).ge(THRESHOLD)), dtype=torch.float, device=DEVICE, requires_grad=True)\n",
    "\n",
    "        #calculate loss\n",
    "        tp = (y_true * y_pred).sum(0).float()\n",
    "        # tn = ((1-y_true) * (1-y_pred)).sum(0).float()\n",
    "        fp = ((1-y_true) * y_pred).sum(0).float()\n",
    "        fn = (y_true * (1-y_pred)).sum(0).float()\n",
    "\n",
    "        p = tp / (tp + fp)\n",
    "        r = tp / (tp + fn)\n",
    "\n",
    "        f1 = 2*p*r / (p+r)\n",
    "        f1[torch.isnan(f1)] = 0\n",
    "        f1_loss = 1-f1.mean()\n",
    "#         print(f1_loss)\n",
    "        return f1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        target = target.float()\n",
    "        \n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "34c786807f448f63f4244537f13ebca2a6b44ee2"
   },
   "outputs": [],
   "source": [
    "def prep_stats(y_pred, y_true):\n",
    "    #prep y_true\n",
    "    y_true_tfm = y_true.cpu().numpy().astype('uint8')\n",
    "    \n",
    "    #prep y_pred khot\n",
    "    y_pred_tfm = (torch.sigmoid(y_pred) > THRESHOLD).cpu().numpy().astype('uint8')\n",
    "    \n",
    "    return y_pred_tfm, y_true_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "7df1b550cc9567063a38437001eff118004b0370"
   },
   "outputs": [],
   "source": [
    "def calc_stats(y_pred, y_true, stats = 'accurancy'):\n",
    "    if stats == 'accuracy':\n",
    "        stat_value = accuracy_score(y_true, y_pred)\n",
    "    elif stats == 'precision':\n",
    "        stat_value = precision_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'recall':\n",
    "        stat_value = recall_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'f1':\n",
    "        stat_value = f1_score(y_true, y_pred, average = 'macro')\n",
    "    else:\n",
    "        stat_value = 0\n",
    "    return stat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "467bc143b3e21ddb3674f77f2c78287c9bc3684c"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5, init_steps = 0):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    steps = init_steps\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_y_true = []\n",
    "            running_y_pred = []\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets= targets.to(DEVICE)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    y_pred_tfm, y_true_tfm = prep_stats(outputs, targets)\n",
    "                    running_y_pred.append(y_pred_tfm)\n",
    "                    running_y_true.append(y_true_tfm)\n",
    "                    \n",
    "                    #export step stats duing training phase\n",
    "                    if phase == 'train':\n",
    "                        record_tb(phase, 'loss', loss.cpu().data.numpy(), steps)\n",
    "                        record_tb(phase, 'accuracy', calc_stats(y_pred_tfm, y_true_tfm, stats = 'accurancy'), steps)\n",
    "                        record_tb(phase, 'precision', calc_stats(y_pred_tfm, y_true_tfm, stats = 'precision'), steps)\n",
    "                        record_tb(phase, 'recall', calc_stats(y_pred_tfm, y_true_tfm, stats = 'recall'), steps)\n",
    "                        record_tb(phase, 'f1', calc_stats(y_pred_tfm, y_true_tfm, stats = 'f1'), steps)\n",
    "                        steps += 1\n",
    "                        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            #calc epoch stats\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = accuracy_score(np.vstack(running_y_true), np.vstack(running_y_pred))\n",
    "            epoch_precision = precision_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_recall = recall_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_f1 = f1_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            \n",
    "            #export epoch stats duing training phase\n",
    "            if phase == 'val':\n",
    "                record_tb(phase, 'loss', epoch_loss, steps)\n",
    "                record_tb(phase, 'accuracy', epoch_acc, steps)\n",
    "                record_tb(phase, 'precision', epoch_precision, steps)\n",
    "                record_tb(phase, 'recall', epoch_recall, steps)\n",
    "                record_tb(phase, 'f1', epoch_f1, steps)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Percision: {:.4f} Recall {:.4f} F1 {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "be546ee708d7ccb01c9f876bb189db4818a7d12a"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = CustomNet(num_class=NUM_CLASSES)\n",
    "model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "criterion = FocalLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 10 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze backbone\n",
    "for param in model_ft.backbone.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3525 Acc: 0.0561 Percision: 0.0887 Recall 0.0380 F1 0.0473\n",
      "val Loss: 1.2339 Acc: 0.0759 Percision: 0.0896 Recall 0.0393 F1 0.0423\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.1881 Acc: 0.0795 Percision: 0.2713 Recall 0.0464 F1 0.0587\n",
      "val Loss: 1.4990 Acc: 0.0986 Percision: 0.2027 Recall 0.0509 F1 0.0647\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.1561 Acc: 0.0935 Percision: 0.2585 Recall 0.0567 F1 0.0749\n",
      "val Loss: 1.1557 Acc: 0.1211 Percision: 0.1260 Recall 0.0647 F1 0.0745\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.1334 Acc: 0.1031 Percision: 0.2777 Recall 0.0661 F1 0.0891\n",
      "val Loss: 1.0991 Acc: 0.0994 Percision: 0.3099 Recall 0.0608 F1 0.0874\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.1197 Acc: 0.1084 Percision: 0.3074 Recall 0.0727 F1 0.1003\n",
      "val Loss: 1.0956 Acc: 0.1200 Percision: 0.2855 Recall 0.0680 F1 0.0896\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.1065 Acc: 0.1186 Percision: 0.3087 Recall 0.0789 F1 0.1087\n",
      "val Loss: 1.1034 Acc: 0.1361 Percision: 0.3920 Recall 0.0805 F1 0.1122\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.1006 Acc: 0.1194 Percision: 0.3170 Recall 0.0832 F1 0.1157\n",
      "val Loss: 1.2812 Acc: 0.1451 Percision: 0.3361 Recall 0.0850 F1 0.1120\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.1057 Acc: 0.1178 Percision: 0.3395 Recall 0.0817 F1 0.1135\n",
      "val Loss: 1.0840 Acc: 0.1379 Percision: 0.2972 Recall 0.0799 F1 0.1025\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.1332 Acc: 0.1047 Percision: 0.3833 Recall 0.0739 F1 0.1044\n",
      "val Loss: 1.2673 Acc: 0.1124 Percision: 0.2344 Recall 0.0570 F1 0.0767\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.0965 Acc: 0.1219 Percision: 0.3199 Recall 0.0834 F1 0.1156\n",
      "val Loss: 1.2855 Acc: 0.1400 Percision: 0.2927 Recall 0.0789 F1 0.1025\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.0555 Acc: 0.1347 Percision: 0.3946 Recall 0.0929 F1 0.1292\n",
      "val Loss: 1.2014 Acc: 0.1458 Percision: 0.3737 Recall 0.0858 F1 0.1198\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.0466 Acc: 0.1387 Percision: 0.3493 Recall 0.0970 F1 0.1350\n",
      "val Loss: 1.0394 Acc: 0.1574 Percision: 0.3936 Recall 0.0940 F1 0.1302\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.0365 Acc: 0.1467 Percision: 0.3459 Recall 0.1001 F1 0.1380\n",
      "val Loss: 1.2273 Acc: 0.1614 Percision: 0.3616 Recall 0.0996 F1 0.1375\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.0349 Acc: 0.1474 Percision: 0.4531 Recall 0.1052 F1 0.1471\n",
      "val Loss: 1.0757 Acc: 0.1641 Percision: 0.3644 Recall 0.0945 F1 0.1275\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.0300 Acc: 0.1509 Percision: 0.4561 Recall 0.1087 F1 0.1520\n",
      "val Loss: 1.3257 Acc: 0.1687 Percision: 0.3765 Recall 0.1008 F1 0.1379\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.0292 Acc: 0.1516 Percision: 0.4201 Recall 0.1087 F1 0.1522\n",
      "val Loss: 1.0437 Acc: 0.1696 Percision: 0.4138 Recall 0.0985 F1 0.1334\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.0237 Acc: 0.1549 Percision: 0.4501 Recall 0.1118 F1 0.1558\n",
      "val Loss: 1.0555 Acc: 0.1633 Percision: 0.4344 Recall 0.0976 F1 0.1369\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.0200 Acc: 0.1569 Percision: 0.4161 Recall 0.1119 F1 0.1550\n",
      "val Loss: 1.1089 Acc: 0.1720 Percision: 0.4071 Recall 0.1066 F1 0.1475\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.0199 Acc: 0.1569 Percision: 0.4249 Recall 0.1142 F1 0.1593\n",
      "val Loss: 1.0155 Acc: 0.1754 Percision: 0.4480 Recall 0.1092 F1 0.1508\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.0157 Acc: 0.1597 Percision: 0.4623 Recall 0.1235 F1 0.1742\n",
      "val Loss: 1.0350 Acc: 0.1728 Percision: 0.4922 Recall 0.1073 F1 0.1484\n",
      "\n",
      "Training complete in 101m 44s\n"
     ]
    }
   ],
   "source": [
    "model_ft, steps = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20, init_steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save intermediate model\n",
    "torch.save(model_ft.state_dict(), 'intermediate_11042018.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze entry\n",
    "for param in model_ft.custom_entry.parameters():\n",
    "    param.requires_grad = False\n",
    "#unfreeze last covn of backbnoe\n",
    "for param in list(list(model_ft.backbone.children())[0][-1].parameters()):\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different learning rate for different layers\n",
    "# optimizer_ft = optim.Adam([\n",
    "#     {'params': model_ft.custom_entry.parameters()},\n",
    "#     {'params': model_ft.backbone.parameters(), 'lr': 0.001},\n",
    "#     {'params': model_ft.custom_head.parameters()},\n",
    "#     ]\n",
    "# )\n",
    "# # Decay LR by a factor of 0.1 every n epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "a27461b7756ca489c66881be19cb1d0d54bf5d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1198 Acc: 0.1252 Percision: 0.3084 Recall 0.0797 F1 0.1084\n",
      "val Loss: 1.0514 Acc: 0.1619 Percision: 0.3100 Recall 0.0901 F1 0.1173\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.0447 Acc: 0.1737 Percision: 0.3490 Recall 0.1186 F1 0.1588\n",
      "val Loss: 1.0830 Acc: 0.2049 Percision: 0.2898 Recall 0.1394 F1 0.1784\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.0186 Acc: 0.1860 Percision: 0.4055 Recall 0.1346 F1 0.1796\n",
      "val Loss: 1.0009 Acc: 0.2020 Percision: 0.3355 Recall 0.1333 F1 0.1718\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.0026 Acc: 0.1955 Percision: 0.3811 Recall 0.1443 F1 0.1909\n",
      "val Loss: 0.9670 Acc: 0.2287 Percision: 0.4086 Recall 0.1551 F1 0.2000\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.9870 Acc: 0.2052 Percision: 0.3937 Recall 0.1509 F1 0.1991\n",
      "val Loss: 1.0586 Acc: 0.2205 Percision: 0.3742 Recall 0.1539 F1 0.2010\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.9751 Acc: 0.2085 Percision: 0.3897 Recall 0.1566 F1 0.2055\n",
      "val Loss: 0.9586 Acc: 0.2165 Percision: 0.4044 Recall 0.1561 F1 0.2033\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.9746 Acc: 0.2093 Percision: 0.4071 Recall 0.1592 F1 0.2094\n",
      "val Loss: 0.9831 Acc: 0.2167 Percision: 0.3386 Recall 0.1384 F1 0.1796\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.9783 Acc: 0.2048 Percision: 0.4120 Recall 0.1569 F1 0.2086\n",
      "val Loss: 0.9562 Acc: 0.2257 Percision: 0.3316 Recall 0.1550 F1 0.2022\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.9520 Acc: 0.2255 Percision: 0.4434 Recall 0.1762 F1 0.2313\n",
      "val Loss: 0.9379 Acc: 0.2392 Percision: 0.4423 Recall 0.1612 F1 0.2089\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.9357 Acc: 0.2361 Percision: 0.4995 Recall 0.1892 F1 0.2484\n",
      "val Loss: 0.9354 Acc: 0.2363 Percision: 0.4327 Recall 0.1712 F1 0.2294\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.8787 Acc: 0.2640 Percision: 0.5522 Recall 0.2080 F1 0.2715\n",
      "val Loss: 0.8966 Acc: 0.2659 Percision: 0.4966 Recall 0.1911 F1 0.2501\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.8613 Acc: 0.2733 Percision: 0.5972 Recall 0.2177 F1 0.2828\n",
      "val Loss: 0.8897 Acc: 0.2682 Percision: 0.4933 Recall 0.2016 F1 0.2614\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.8529 Acc: 0.2785 Percision: 0.5179 Recall 0.2187 F1 0.2815\n",
      "val Loss: 0.9072 Acc: 0.2703 Percision: 0.5008 Recall 0.2013 F1 0.2626\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.8473 Acc: 0.2835 Percision: 0.6367 Recall 0.2255 F1 0.2917\n",
      "val Loss: 0.8861 Acc: 0.2775 Percision: 0.4899 Recall 0.2010 F1 0.2582\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.8429 Acc: 0.2848 Percision: 0.6100 Recall 0.2365 F1 0.3076\n",
      "val Loss: 0.8809 Acc: 0.2811 Percision: 0.4931 Recall 0.2016 F1 0.2621\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.8355 Acc: 0.2916 Percision: 0.5760 Recall 0.2432 F1 0.3141\n",
      "val Loss: 0.8870 Acc: 0.2767 Percision: 0.4888 Recall 0.2015 F1 0.2625\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.8292 Acc: 0.2950 Percision: 0.6220 Recall 0.2393 F1 0.3081\n",
      "val Loss: 0.8852 Acc: 0.2821 Percision: 0.4983 Recall 0.2080 F1 0.2670\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.8217 Acc: 0.2985 Percision: 0.6277 Recall 0.2501 F1 0.3227\n",
      "val Loss: 0.8828 Acc: 0.2859 Percision: 0.5104 Recall 0.2141 F1 0.2758\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.8194 Acc: 0.3024 Percision: 0.5528 Recall 0.2534 F1 0.3246\n",
      "val Loss: 0.8818 Acc: 0.2885 Percision: 0.4860 Recall 0.2214 F1 0.2818\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.8141 Acc: 0.3007 Percision: 0.6204 Recall 0.2499 F1 0.3196\n",
      "val Loss: 0.8853 Acc: 0.2851 Percision: 0.5337 Recall 0.2080 F1 0.2691\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.7997 Acc: 0.3107 Percision: 0.5981 Recall 0.2621 F1 0.3391\n",
      "val Loss: 0.8783 Acc: 0.2906 Percision: 0.5363 Recall 0.2150 F1 0.2785\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.7971 Acc: 0.3104 Percision: 0.6228 Recall 0.2655 F1 0.3424\n",
      "val Loss: 0.8839 Acc: 0.2916 Percision: 0.5041 Recall 0.2135 F1 0.2751\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.7954 Acc: 0.3116 Percision: 0.5989 Recall 0.2572 F1 0.3281\n",
      "val Loss: 0.8806 Acc: 0.2919 Percision: 0.5282 Recall 0.2192 F1 0.2823\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.7927 Acc: 0.3199 Percision: 0.6031 Recall 0.2681 F1 0.3424\n",
      "val Loss: 0.8804 Acc: 0.2903 Percision: 0.5033 Recall 0.2144 F1 0.2771\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.7944 Acc: 0.3113 Percision: 0.5906 Recall 0.2649 F1 0.3370\n",
      "val Loss: 0.8847 Acc: 0.2946 Percision: 0.5013 Recall 0.2184 F1 0.2800\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.7935 Acc: 0.3138 Percision: 0.5643 Recall 0.2671 F1 0.3396\n",
      "val Loss: 0.8836 Acc: 0.2945 Percision: 0.4982 Recall 0.2192 F1 0.2813\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.7910 Acc: 0.3204 Percision: 0.5936 Recall 0.2650 F1 0.3380\n",
      "val Loss: 0.8824 Acc: 0.2916 Percision: 0.4878 Recall 0.2179 F1 0.2790\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.7902 Acc: 0.3156 Percision: 0.5929 Recall 0.2697 F1 0.3428\n",
      "val Loss: 0.8873 Acc: 0.2953 Percision: 0.4944 Recall 0.2178 F1 0.2793\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.7876 Acc: 0.3154 Percision: 0.5607 Recall 0.2685 F1 0.3396\n",
      "val Loss: 0.8833 Acc: 0.2953 Percision: 0.5258 Recall 0.2189 F1 0.2812\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.7886 Acc: 0.3140 Percision: 0.5868 Recall 0.2633 F1 0.3334\n",
      "val Loss: 0.8821 Acc: 0.2933 Percision: 0.4934 Recall 0.2188 F1 0.2800\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.7852 Acc: 0.3193 Percision: 0.5717 Recall 0.2744 F1 0.3478\n",
      "val Loss: 0.8870 Acc: 0.2933 Percision: 0.5172 Recall 0.2264 F1 0.2881\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.7870 Acc: 0.3174 Percision: 0.6461 Recall 0.2726 F1 0.3488\n",
      "val Loss: 0.8812 Acc: 0.2961 Percision: 0.4953 Recall 0.2204 F1 0.2816\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.7848 Acc: 0.3173 Percision: 0.5606 Recall 0.2628 F1 0.3304\n",
      "val Loss: 0.8783 Acc: 0.2937 Percision: 0.4998 Recall 0.2162 F1 0.2795\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.7855 Acc: 0.3179 Percision: 0.6403 Recall 0.2717 F1 0.3474\n",
      "val Loss: 0.8851 Acc: 0.2920 Percision: 0.4932 Recall 0.2183 F1 0.2806\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.7871 Acc: 0.3173 Percision: 0.6553 Recall 0.2768 F1 0.3546\n",
      "val Loss: 0.8820 Acc: 0.2948 Percision: 0.4955 Recall 0.2218 F1 0.2839\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.7830 Acc: 0.3202 Percision: 0.6044 Recall 0.2676 F1 0.3393\n",
      "val Loss: 0.8841 Acc: 0.2977 Percision: 0.4873 Recall 0.2229 F1 0.2823\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.7883 Acc: 0.3177 Percision: 0.6352 Recall 0.2669 F1 0.3393\n",
      "val Loss: 0.8826 Acc: 0.2928 Percision: 0.4960 Recall 0.2184 F1 0.2811\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.7865 Acc: 0.3184 Percision: 0.6184 Recall 0.2667 F1 0.3384\n",
      "val Loss: 0.8823 Acc: 0.2949 Percision: 0.5032 Recall 0.2190 F1 0.2810\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.7873 Acc: 0.3174 Percision: 0.6220 Recall 0.2706 F1 0.3423\n",
      "val Loss: 0.8808 Acc: 0.2959 Percision: 0.4925 Recall 0.2220 F1 0.2839\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.7874 Acc: 0.3166 Percision: 0.6245 Recall 0.2710 F1 0.3448\n",
      "val Loss: 0.8815 Acc: 0.2937 Percision: 0.5363 Recall 0.2200 F1 0.2831\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.7861 Acc: 0.3174 Percision: 0.5867 Recall 0.2664 F1 0.3386\n",
      "val Loss: 0.8833 Acc: 0.2930 Percision: 0.5285 Recall 0.2200 F1 0.2837\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.7863 Acc: 0.3166 Percision: 0.6538 Recall 0.2771 F1 0.3553\n",
      "val Loss: 0.8821 Acc: 0.2912 Percision: 0.4919 Recall 0.2189 F1 0.2806\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.7846 Acc: 0.3212 Percision: 0.6130 Recall 0.2697 F1 0.3430\n",
      "val Loss: 0.8795 Acc: 0.2972 Percision: 0.4958 Recall 0.2214 F1 0.2822\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.7851 Acc: 0.3211 Percision: 0.6688 Recall 0.2876 F1 0.3668\n",
      "val Loss: 0.8795 Acc: 0.2922 Percision: 0.5286 Recall 0.2201 F1 0.2840\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.7858 Acc: 0.3185 Percision: 0.6707 Recall 0.2794 F1 0.3567\n",
      "val Loss: 0.8996 Acc: 0.2961 Percision: 0.4942 Recall 0.2203 F1 0.2819\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.7853 Acc: 0.3205 Percision: 0.6413 Recall 0.2809 F1 0.3588\n",
      "val Loss: 0.8854 Acc: 0.2933 Percision: 0.5224 Recall 0.2238 F1 0.2862\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.7861 Acc: 0.3169 Percision: 0.6467 Recall 0.2739 F1 0.3500\n",
      "val Loss: 0.8799 Acc: 0.2967 Percision: 0.4907 Recall 0.2187 F1 0.2795\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.7848 Acc: 0.3211 Percision: 0.6394 Recall 0.2682 F1 0.3409\n",
      "val Loss: 0.8806 Acc: 0.2975 Percision: 0.5263 Recall 0.2232 F1 0.2854\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.7867 Acc: 0.3164 Percision: 0.6194 Recall 0.2759 F1 0.3501\n",
      "val Loss: 0.8833 Acc: 0.2940 Percision: 0.4943 Recall 0.2174 F1 0.2784\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.7864 Acc: 0.3204 Percision: 0.6132 Recall 0.2697 F1 0.3440\n",
      "val Loss: 0.8823 Acc: 0.2986 Percision: 0.5346 Recall 0.2234 F1 0.2864\n",
      "\n",
      "Training complete in 154m 22s\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=50, init_steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
