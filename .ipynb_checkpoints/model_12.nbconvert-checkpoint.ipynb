{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4248fd9c0afae8eaac391ab0d1895db2be249e75"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# base_path = r'../input'\n",
    "base_path = r'input'\n",
    "PATH_TRAIN_ANNO = os.path.join(base_path, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(base_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "583ead53ccf420ab4290230a0a17cc3b6c62c74d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    USE_TENSORBOARD = True\n",
    "    writer = SummaryWriter()\n",
    "except:\n",
    "    USE_TENSORBOARD = False\n",
    "    print('No tensorboard X')\n",
    "\n",
    "def record_tb(phase, tag, value, global_step):\n",
    "    if USE_TENSORBOARD is True:\n",
    "        writer.add_scalar('{phase}/{tag}'.format(phase=phase, tag=tag), value, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7a95c899247b666f9235e3100a569744c46bf943"
   },
   "outputs": [],
   "source": [
    "# os.listdir(PATH_TRAIN_IMG)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e85715fa2a9217474fc039c2b399c9b33490689a"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28\n",
    "MAX_TAGS = 5\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "VAL_SIZE =0.2\n",
    "THRESHOLD = 0.5\n",
    "SAMPLES = 1\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "7e81577b2c725960293a5cfabb29e0d46d66834c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 31072\n",
      "[('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', [16, 0]),\n",
      " ('000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', [7, 1, 2, 0]),\n",
      " ('000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', [5])]\n"
     ]
    }
   ],
   "source": [
    "def get_transform_anno(annotation_path, img_path):\n",
    "    df = pd.read_csv(annotation_path)\n",
    "    annotations = []\n",
    "    for i, row in df.iterrows():\n",
    "        rcd_id = row['Id']\n",
    "        rcd_cate =  [int(j) for j in row['Target'].split()]\n",
    "        annotations.append((rcd_id, rcd_cate))\n",
    "    return annotations\n",
    "#get annotations\n",
    "annotations = get_transform_anno(PATH_TRAIN_ANNO, PATH_TRAIN_IMG)\n",
    "sample_size = int(len(annotations) * SAMPLES)\n",
    "print('sample size: {}'.format(sample_size))\n",
    "annotations = annotations[:sample_size]\n",
    "pprint(annotations[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "878d1a4d5d29884cc313258347df1ee630abae1a"
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, img_meta, img_path, transform = None):\n",
    "        self.img_meta = img_meta\n",
    "        self.transform = transform\n",
    "        self.channels = ['red', 'blue', 'yellow', 'green']\n",
    "        self.img_path = img_path\n",
    "        self.mlb = MultiLabelBinarizer(classes=range(0,NUM_CLASSES))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id, img_tags= self.img_meta[idx]\n",
    "        ch = []\n",
    "        img_file_template = '{}_{}.png'\n",
    "        for c in self.channels:\n",
    "            ch.append(io.imread(os.path.join(self.img_path, img_file_template.format(img_id, c))))\n",
    "        img = np.stack(ch)\n",
    "\n",
    "        #augmentation\n",
    "        if bool(self.transform) is True:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        #binarize\n",
    "        img_tags = self.mlb.fit_transform([img_tags]).squeeze()\n",
    "        \n",
    "        #transform to tensor\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img_tags = torch.from_numpy(img_tags)\n",
    "        \n",
    "        output = (img, img_tags)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "af583f0882e55fd31a3df230822ac86f99e25f4c"
   },
   "outputs": [],
   "source": [
    "class ImgTfm:\n",
    "    def __init__(self, aug_pipline = None):\n",
    "        self.seq = aug_pipline\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "#         seq_det = self.seq.to_deterministic()\n",
    "        \n",
    "        #augmentation\n",
    "        aug_img=img.copy().transpose((1, 2, 0))\n",
    "        aug_img = self.seq.augment_images([aug_img])[0]\n",
    "        aug_img=aug_img.transpose((2, 1, 0))\n",
    "        \n",
    "        #normalize\n",
    "        aug_img=aug_img/255\n",
    "        \n",
    "        return aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "7c0aeb64e2a7b651582a467d82079a2fda67c71b"
   },
   "outputs": [],
   "source": [
    "def get_aug_pipline(img_size, mode = 'train'):\n",
    "    if mode == 'train':\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "            iaa.Sequential([\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Affine(\n",
    "                    rotate=(-20, 20),\n",
    "                )\n",
    "            ], random_order=True) # apply augmenters in random order\n",
    "        ], random_order=False)\n",
    "    else: #ie.val\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "        ], random_order=False)\n",
    "#     seq = iaa.Sequential([\n",
    "#                 iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "#             ], random_order=False)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "4c926ebe55fb37a7bfe3ffb2d6da2b145fb5f747"
   },
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(annotations, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "composed = {}\n",
    "composed['train'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'train'))])\n",
    "composed['val'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'val'))])\n",
    "\n",
    "image_datasets = {'train': ProteinDataset(train_set, img_path = PATH_TRAIN_IMG, transform=composed['train']),\n",
    "                 'val': ProteinDataset(val_set, img_path = PATH_TRAIN_IMG, transform=composed['val'])}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "e8c442abb721b3f65c4a7b076232757725311b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 24857, 'val': 6215}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "610b2e7a2e2b430673460bfd21e2940eca4a83b1"
   },
   "outputs": [],
   "source": [
    "#test dataset\n",
    "# ix = 10\n",
    "# tmp_img, tmp_tags  = image_datasets['train'][ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "116981e26006844aba80864a76434c9b0a445188"
   },
   "outputs": [],
   "source": [
    "#test dataloader\n",
    "# tmp_img, tmp_tags = next(iter(dataloaders['train']))\n",
    "# print('tmp_img shape: {}\\ntmp_tags: shape {}'.format(tmp_img.shape, tmp_tags.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "53926b18c61ec3d5f167ee905fcde5c0dc9289f5"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class RnetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = self._prep_backbone()\n",
    "        \n",
    "    def _prep_backbone(self):     \n",
    "        base_model = models.resnet34(pretrained=True)\n",
    "        removed = list(base_model.children())[1:-2]\n",
    "        backbone = nn.Sequential(*removed)\n",
    "#         for param in backbone.parameters():\n",
    "#             param.require_grad = False\n",
    "        return backbone\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p=0.5)\n",
    "        self.fc_2 = nn.Linear(512 * 7 * 7, 256)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(256)\n",
    "        self.dropout_2 = nn.Dropout(p=0.5)\n",
    "        self.fc_3 = nn.Linear(256, self.num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc_3(x)\n",
    "        return x\n",
    "\n",
    "# class CustomEntry(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#         nn.init.kaiming_normal_(self.conv_1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv_1(x)\n",
    "#         return x\n",
    "\n",
    "class CustomEntry(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = self._prep_layers()\n",
    "        \n",
    "    def _prep_layers(self):\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        original_entry_w = torch.tensor(list(model.children())[0].weight)\n",
    "        new_entry_w = torch.cat([original_entry_w, torch.zeros(size = (64,1,7,7))], 1)\n",
    "        \n",
    "        conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        conv_1.weight=conv_1.weight = torch.nn.Parameter(new_entry_w)\n",
    "        return conv_1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        return x\n",
    "    \n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.custom_entry = CustomEntry()\n",
    "        self.backbone = RnetBackbone()\n",
    "        self.custom_head = CustomHead(num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.custom_entry(x)\n",
    "        x = self.backbone(x)\n",
    "        x = self.custom_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "4ef191d711342bf7bce65d943f8629d03bcf26c1"
   },
   "outputs": [],
   "source": [
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        #f1 loss\n",
    "#         #prep y_true\n",
    "        y_true = y_true.float()\n",
    "\n",
    "        #prep y_pred\n",
    "        y_pred = torch.tensor(data = (torch.sigmoid(y_pred).ge(THRESHOLD)), dtype=torch.float, device=DEVICE, requires_grad=True)\n",
    "\n",
    "        #calculate loss\n",
    "        tp = (y_true * y_pred).sum(0).float()\n",
    "        # tn = ((1-y_true) * (1-y_pred)).sum(0).float()\n",
    "        fp = ((1-y_true) * y_pred).sum(0).float()\n",
    "        fn = (y_true * (1-y_pred)).sum(0).float()\n",
    "\n",
    "        p = tp / (tp + fp)\n",
    "        r = tp / (tp + fn)\n",
    "\n",
    "        f1 = 2*p*r / (p+r)\n",
    "        f1[torch.isnan(f1)] = 0\n",
    "        f1_loss = 1-f1.mean()\n",
    "#         print(f1_loss)\n",
    "        return f1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        target = target.float()\n",
    "        \n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "34c786807f448f63f4244537f13ebca2a6b44ee2"
   },
   "outputs": [],
   "source": [
    "def prep_stats(y_pred, y_true):\n",
    "    #prep y_true\n",
    "    y_true_tfm = y_true.cpu().numpy().astype('uint8')\n",
    "    \n",
    "    #prep y_pred khot\n",
    "    y_pred_tfm = (torch.sigmoid(y_pred) > THRESHOLD).cpu().numpy().astype('uint8')\n",
    "    \n",
    "    return y_pred_tfm, y_true_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "7df1b550cc9567063a38437001eff118004b0370"
   },
   "outputs": [],
   "source": [
    "def calc_stats(y_pred, y_true, stats = 'accurancy'):\n",
    "    if stats == 'accuracy':\n",
    "        stat_value = accuracy_score(y_true, y_pred)\n",
    "    elif stats == 'precision':\n",
    "        stat_value = precision_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'recall':\n",
    "        stat_value = recall_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'f1':\n",
    "        stat_value = f1_score(y_true, y_pred, average = 'macro')\n",
    "    else:\n",
    "        stat_value = 0\n",
    "    return stat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "467bc143b3e21ddb3674f77f2c78287c9bc3684c"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_y_true = []\n",
    "            running_y_pred = []\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets= targets.to(DEVICE)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    y_pred_tfm, y_true_tfm = prep_stats(outputs, targets)\n",
    "                    running_y_pred.append(y_pred_tfm)\n",
    "                    running_y_true.append(y_true_tfm)\n",
    "                    \n",
    "                    #export step stats duing training phase\n",
    "                    if phase == 'train':\n",
    "                        record_tb(phase, 'loss', loss.cpu().data.numpy(), steps)\n",
    "                        record_tb(phase, 'accuracy', calc_stats(y_pred_tfm, y_true_tfm, stats = 'accurancy'), steps)\n",
    "                        record_tb(phase, 'precision', calc_stats(y_pred_tfm, y_true_tfm, stats = 'precision'), steps)\n",
    "                        record_tb(phase, 'recall', calc_stats(y_pred_tfm, y_true_tfm, stats = 'recall'), steps)\n",
    "                        record_tb(phase, 'f1', calc_stats(y_pred_tfm, y_true_tfm, stats = 'f1'), steps)\n",
    "                        steps += 1\n",
    "                        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            #calc epoch stats\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = accuracy_score(np.vstack(running_y_true), np.vstack(running_y_pred))\n",
    "            epoch_precision = precision_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_recall = recall_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_f1 = f1_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            \n",
    "            #export epoch stats duing training phase\n",
    "            if phase == 'val':\n",
    "                record_tb(phase, 'loss', epoch_loss, steps)\n",
    "                record_tb(phase, 'accuracy', epoch_acc, steps)\n",
    "                record_tb(phase, 'precision', epoch_precision, steps)\n",
    "                record_tb(phase, 'recall', epoch_recall, steps)\n",
    "                record_tb(phase, 'f1', epoch_f1, steps)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Percision: {:.4f} Recall {:.4f} F1 {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "be546ee708d7ccb01c9f876bb189db4818a7d12a"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = CustomNet(num_class=NUM_CLASSES)\n",
    "model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "criterion = FocalLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze backbone\n",
    "# for param  in model_ft.backbone.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "a27461b7756ca489c66881be19cb1d0d54bf5d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.4435 Acc: 0.0139 Percision: 0.0726 Recall 0.0162 F1 0.0253\n",
      "val Loss: 1.3599 Acc: 0.0000 Percision: 0.0000 Recall 0.0000 F1 0.0000\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.2934 Acc: 0.0346 Percision: 0.0969 Recall 0.0207 F1 0.0280\n",
      "val Loss: 1.2100 Acc: 0.0854 Percision: 0.0600 Recall 0.0397 F1 0.0408\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.2472 Acc: 0.0563 Percision: 0.0986 Recall 0.0330 F1 0.0385\n",
      "val Loss: 1.2251 Acc: 0.0909 Percision: 0.0645 Recall 0.0389 F1 0.0396\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.2231 Acc: 0.0654 Percision: 0.1246 Recall 0.0368 F1 0.0426\n",
      "val Loss: 1.2120 Acc: 0.0793 Percision: 0.0466 Recall 0.0293 F1 0.0299\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.2028 Acc: 0.0747 Percision: 0.1505 Recall 0.0418 F1 0.0498\n",
      "val Loss: 1.1840 Acc: 0.0805 Percision: 0.0663 Recall 0.0416 F1 0.0464\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.1738 Acc: 0.0881 Percision: 0.1841 Recall 0.0506 F1 0.0626\n",
      "val Loss: 1.1566 Acc: 0.1163 Percision: 0.1664 Recall 0.0793 F1 0.0948\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.1385 Acc: 0.1109 Percision: 0.2166 Recall 0.0639 F1 0.0822\n",
      "val Loss: 1.1604 Acc: 0.1063 Percision: 0.1982 Recall 0.0741 F1 0.0954\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.1057 Acc: 0.1278 Percision: 0.2464 Recall 0.0755 F1 0.0986\n",
      "val Loss: 1.0943 Acc: 0.1548 Percision: 0.1994 Recall 0.0822 F1 0.0935\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.0819 Acc: 0.1461 Percision: 0.2664 Recall 0.0865 F1 0.1126\n",
      "val Loss: 1.0905 Acc: 0.1252 Percision: 0.2353 Recall 0.0934 F1 0.1194\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.0607 Acc: 0.1551 Percision: 0.3151 Recall 0.0982 F1 0.1280\n",
      "val Loss: 1.0319 Acc: 0.1583 Percision: 0.2602 Recall 0.0982 F1 0.1247\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.9887 Acc: 0.1906 Percision: 0.3472 Recall 0.1238 F1 0.1581\n",
      "val Loss: 0.9415 Acc: 0.2233 Percision: 0.3338 Recall 0.1268 F1 0.1583\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.0261 Acc: 0.1716 Percision: 0.3641 Recall 0.1071 F1 0.1397\n",
      "val Loss: 1.0009 Acc: 0.1796 Percision: 0.2893 Recall 0.1017 F1 0.1336\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.0012 Acc: 0.1815 Percision: 0.4177 Recall 0.1191 F1 0.1553\n",
      "val Loss: 1.0341 Acc: 0.2179 Percision: 0.3749 Recall 0.1293 F1 0.1636\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.9723 Acc: 0.2010 Percision: 0.3982 Recall 0.1309 F1 0.1675\n",
      "val Loss: 0.9366 Acc: 0.2361 Percision: 0.4033 Recall 0.1457 F1 0.1822\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.9589 Acc: 0.2146 Percision: 0.4176 Recall 0.1393 F1 0.1776\n",
      "val Loss: 0.9361 Acc: 0.2379 Percision: 0.3768 Recall 0.1405 F1 0.1776\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.9531 Acc: 0.2171 Percision: 0.4041 Recall 0.1405 F1 0.1780\n",
      "val Loss: 0.9254 Acc: 0.2402 Percision: 0.4155 Recall 0.1465 F1 0.1819\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.9454 Acc: 0.2270 Percision: 0.4033 Recall 0.1474 F1 0.1864\n",
      "val Loss: 0.9809 Acc: 0.2524 Percision: 0.3937 Recall 0.1551 F1 0.1915\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.9380 Acc: 0.2319 Percision: 0.4050 Recall 0.1521 F1 0.1918\n",
      "val Loss: 0.9166 Acc: 0.2523 Percision: 0.4564 Recall 0.1483 F1 0.1854\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.9350 Acc: 0.2307 Percision: 0.4088 Recall 0.1522 F1 0.1929\n",
      "val Loss: 0.9981 Acc: 0.2436 Percision: 0.4565 Recall 0.1435 F1 0.1813\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.9288 Acc: 0.2367 Percision: 0.4145 Recall 0.1572 F1 0.1990\n",
      "val Loss: 0.9417 Acc: 0.2664 Percision: 0.3824 Recall 0.1619 F1 0.1992\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.9145 Acc: 0.2422 Percision: 0.4323 Recall 0.1600 F1 0.2024\n",
      "val Loss: 0.8968 Acc: 0.2603 Percision: 0.4881 Recall 0.1593 F1 0.1991\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.9175 Acc: 0.2435 Percision: 0.4315 Recall 0.1614 F1 0.2047\n",
      "val Loss: 0.9244 Acc: 0.2611 Percision: 0.4703 Recall 0.1606 F1 0.2007\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.9148 Acc: 0.2442 Percision: 0.4484 Recall 0.1627 F1 0.2060\n",
      "val Loss: 0.8955 Acc: 0.2629 Percision: 0.4371 Recall 0.1649 F1 0.2048\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.9108 Acc: 0.2467 Percision: 0.4254 Recall 0.1637 F1 0.2070\n",
      "val Loss: 0.9196 Acc: 0.2659 Percision: 0.4440 Recall 0.1621 F1 0.2011\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.9085 Acc: 0.2481 Percision: 0.4396 Recall 0.1660 F1 0.2098\n",
      "val Loss: 0.9483 Acc: 0.2656 Percision: 0.4942 Recall 0.1640 F1 0.2042\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.9072 Acc: 0.2498 Percision: 0.4394 Recall 0.1675 F1 0.2120\n",
      "val Loss: 0.9052 Acc: 0.2688 Percision: 0.4580 Recall 0.1668 F1 0.2067\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.9065 Acc: 0.2519 Percision: 0.4458 Recall 0.1675 F1 0.2118\n",
      "val Loss: 0.8962 Acc: 0.2651 Percision: 0.4794 Recall 0.1657 F1 0.2084\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.9064 Acc: 0.2479 Percision: 0.4388 Recall 0.1686 F1 0.2134\n",
      "val Loss: 0.8909 Acc: 0.2703 Percision: 0.4490 Recall 0.1671 F1 0.2055\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.9042 Acc: 0.2516 Percision: 0.4834 Recall 0.1694 F1 0.2157\n",
      "val Loss: 0.9102 Acc: 0.2677 Percision: 0.4588 Recall 0.1678 F1 0.2075\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.9025 Acc: 0.2539 Percision: 0.4563 Recall 0.1702 F1 0.2160\n",
      "val Loss: 0.8842 Acc: 0.2693 Percision: 0.5210 Recall 0.1655 F1 0.2065\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.9004 Acc: 0.2556 Percision: 0.4841 Recall 0.1736 F1 0.2206\n",
      "val Loss: 0.8957 Acc: 0.2729 Percision: 0.4803 Recall 0.1697 F1 0.2105\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.8988 Acc: 0.2535 Percision: 0.4373 Recall 0.1720 F1 0.2179\n",
      "val Loss: 0.8881 Acc: 0.2671 Percision: 0.4740 Recall 0.1678 F1 0.2092\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.9000 Acc: 0.2519 Percision: 0.4378 Recall 0.1705 F1 0.2161\n",
      "val Loss: 0.8860 Acc: 0.2692 Percision: 0.5010 Recall 0.1668 F1 0.2072\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.8994 Acc: 0.2531 Percision: 0.4440 Recall 0.1699 F1 0.2147\n",
      "val Loss: 0.8869 Acc: 0.2669 Percision: 0.4586 Recall 0.1657 F1 0.2066\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.9008 Acc: 0.2537 Percision: 0.4375 Recall 0.1718 F1 0.2173\n",
      "val Loss: 0.8942 Acc: 0.2708 Percision: 0.4967 Recall 0.1667 F1 0.2059\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.8988 Acc: 0.2540 Percision: 0.4506 Recall 0.1719 F1 0.2179\n",
      "val Loss: 0.8865 Acc: 0.2685 Percision: 0.5111 Recall 0.1666 F1 0.2079\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.8974 Acc: 0.2549 Percision: 0.4704 Recall 0.1714 F1 0.2164\n",
      "val Loss: 0.8824 Acc: 0.2745 Percision: 0.4993 Recall 0.1725 F1 0.2125\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.8989 Acc: 0.2546 Percision: 0.4428 Recall 0.1721 F1 0.2181\n",
      "val Loss: 0.8828 Acc: 0.2717 Percision: 0.4813 Recall 0.1706 F1 0.2125\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.8979 Acc: 0.2566 Percision: 0.4544 Recall 0.1752 F1 0.2229\n",
      "val Loss: 0.8824 Acc: 0.2724 Percision: 0.5055 Recall 0.1686 F1 0.2087\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.8975 Acc: 0.2566 Percision: 0.4920 Recall 0.1734 F1 0.2199\n",
      "val Loss: 0.8827 Acc: 0.2717 Percision: 0.4760 Recall 0.1712 F1 0.2144\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.8982 Acc: 0.2564 Percision: 0.4371 Recall 0.1723 F1 0.2176\n",
      "val Loss: 0.8855 Acc: 0.2701 Percision: 0.5037 Recall 0.1694 F1 0.2112\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.8965 Acc: 0.2528 Percision: 0.5082 Recall 0.1747 F1 0.2231\n",
      "val Loss: 0.8865 Acc: 0.2766 Percision: 0.4881 Recall 0.1729 F1 0.2130\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.8987 Acc: 0.2540 Percision: 0.4828 Recall 0.1722 F1 0.2188\n",
      "val Loss: 0.8929 Acc: 0.2735 Percision: 0.4796 Recall 0.1695 F1 0.2095\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.8984 Acc: 0.2540 Percision: 0.4749 Recall 0.1728 F1 0.2192\n",
      "val Loss: 0.8886 Acc: 0.2705 Percision: 0.4547 Recall 0.1676 F1 0.2078\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.8985 Acc: 0.2525 Percision: 0.4391 Recall 0.1711 F1 0.2167\n",
      "val Loss: 0.8926 Acc: 0.2713 Percision: 0.4912 Recall 0.1685 F1 0.2092\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.8965 Acc: 0.2519 Percision: 0.4358 Recall 0.1703 F1 0.2149\n",
      "val Loss: 0.8875 Acc: 0.2742 Percision: 0.4899 Recall 0.1720 F1 0.2126\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.8970 Acc: 0.2537 Percision: 0.4505 Recall 0.1720 F1 0.2181\n",
      "val Loss: 0.8822 Acc: 0.2687 Percision: 0.4944 Recall 0.1687 F1 0.2109\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.8976 Acc: 0.2539 Percision: 0.4518 Recall 0.1722 F1 0.2186\n",
      "val Loss: 0.8829 Acc: 0.2706 Percision: 0.4490 Recall 0.1667 F1 0.2064\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.8982 Acc: 0.2557 Percision: 0.4492 Recall 0.1717 F1 0.2175\n",
      "val Loss: 0.8901 Acc: 0.2750 Percision: 0.4750 Recall 0.1754 F1 0.2172\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.8961 Acc: 0.2593 Percision: 0.4465 Recall 0.1741 F1 0.2201\n",
      "val Loss: 0.8849 Acc: 0.2727 Percision: 0.4886 Recall 0.1699 F1 0.2111\n",
      "\n",
      "Training complete in 344m 49s\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
