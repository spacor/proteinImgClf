{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4248fd9c0afae8eaac391ab0d1895db2be249e75"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# base_path = r'../input'\n",
    "base_path = r'input'\n",
    "PATH_TRAIN_ANNO = os.path.join(base_path, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(base_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "583ead53ccf420ab4290230a0a17cc3b6c62c74d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    USE_TENSORBOARD = True\n",
    "    writer = SummaryWriter()\n",
    "except:\n",
    "    USE_TENSORBOARD = False\n",
    "    print('No tensorboard X')\n",
    "\n",
    "def record_tb(phase, tag, value, global_step):\n",
    "    if USE_TENSORBOARD is True:\n",
    "        writer.add_scalar('{phase}/{tag}'.format(phase=phase, tag=tag), value, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7a95c899247b666f9235e3100a569744c46bf943"
   },
   "outputs": [],
   "source": [
    "# os.listdir(PATH_TRAIN_IMG)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e85715fa2a9217474fc039c2b399c9b33490689a"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28\n",
    "MAX_TAGS = 5\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "VAL_SIZE =0.2\n",
    "THRESHOLD = 0.5\n",
    "SAMPLES = 1\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "7e81577b2c725960293a5cfabb29e0d46d66834c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 31072\n",
      "[('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0', [16, 0]),\n",
      " ('000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0', [7, 1, 2, 0]),\n",
      " ('000a9596-bbc4-11e8-b2bc-ac1f6b6435d0', [5])]\n"
     ]
    }
   ],
   "source": [
    "def get_transform_anno(annotation_path, img_path):\n",
    "    df = pd.read_csv(annotation_path)\n",
    "    annotations = []\n",
    "    for i, row in df.iterrows():\n",
    "        rcd_id = row['Id']\n",
    "        rcd_cate =  [int(j) for j in row['Target'].split()]\n",
    "        annotations.append((rcd_id, rcd_cate))\n",
    "    return annotations\n",
    "#get annotations\n",
    "annotations = get_transform_anno(PATH_TRAIN_ANNO, PATH_TRAIN_IMG)\n",
    "sample_size = int(len(annotations) * SAMPLES)\n",
    "print('sample size: {}'.format(sample_size))\n",
    "annotations = annotations[:sample_size]\n",
    "pprint(annotations[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "878d1a4d5d29884cc313258347df1ee630abae1a"
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, img_meta, img_path, transform = None):\n",
    "        self.img_meta = img_meta\n",
    "        self.transform = transform\n",
    "        self.channels = ['red', 'blue', 'yellow', 'green']\n",
    "        self.img_path = img_path\n",
    "        self.mlb = MultiLabelBinarizer(classes=range(0,NUM_CLASSES))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id, img_tags= self.img_meta[idx]\n",
    "        ch = []\n",
    "        img_file_template = '{}_{}.png'\n",
    "        for c in self.channels:\n",
    "            ch.append(io.imread(os.path.join(self.img_path, img_file_template.format(img_id, c))))\n",
    "        img = np.stack(ch)\n",
    "\n",
    "        #augmentation\n",
    "        if bool(self.transform) is True:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        #binarize\n",
    "        img_tags = self.mlb.fit_transform([img_tags]).squeeze()\n",
    "        \n",
    "        #transform to tensor\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img_tags = torch.from_numpy(img_tags)\n",
    "        \n",
    "        output = (img, img_tags)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "af583f0882e55fd31a3df230822ac86f99e25f4c"
   },
   "outputs": [],
   "source": [
    "class ImgTfm:\n",
    "    def __init__(self, aug_pipline = None):\n",
    "        self.seq = aug_pipline\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "#         seq_det = self.seq.to_deterministic()\n",
    "        \n",
    "        #augmentation\n",
    "        aug_img=img.copy().transpose((1, 2, 0))\n",
    "        aug_img = self.seq.augment_images([aug_img])[0]\n",
    "        aug_img=aug_img.transpose((2, 1, 0))\n",
    "        \n",
    "        #normalize\n",
    "        aug_img=aug_img/255\n",
    "        \n",
    "        return aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "7c0aeb64e2a7b651582a467d82079a2fda67c71b"
   },
   "outputs": [],
   "source": [
    "def get_aug_pipline(img_size, mode = 'train'):\n",
    "    if mode == 'train':\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "            iaa.Sequential([\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Affine(\n",
    "                    rotate=(-20, 20),\n",
    "                )\n",
    "            ], random_order=True) # apply augmenters in random order\n",
    "        ], random_order=False)\n",
    "    else: #ie.val\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "        ], random_order=False)\n",
    "#     seq = iaa.Sequential([\n",
    "#                 iaa.Scale({\"height\": IMG_SIZE, \"width\": IMG_SIZE}),\n",
    "#             ], random_order=False)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "4c926ebe55fb37a7bfe3ffb2d6da2b145fb5f747"
   },
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(annotations, test_size=VAL_SIZE, random_state=42)\n",
    "\n",
    "composed = {}\n",
    "composed['train'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'train'))])\n",
    "composed['val'] = transforms.Compose([ImgTfm(aug_pipline=get_aug_pipline(img_size=IMG_SIZE, mode = 'val'))])\n",
    "\n",
    "image_datasets = {'train': ProteinDataset(train_set, img_path = PATH_TRAIN_IMG, transform=composed['train']),\n",
    "                 'val': ProteinDataset(val_set, img_path = PATH_TRAIN_IMG, transform=composed['val'])}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "e8c442abb721b3f65c4a7b076232757725311b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 24857, 'val': 6215}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "610b2e7a2e2b430673460bfd21e2940eca4a83b1"
   },
   "outputs": [],
   "source": [
    "#test dataset\n",
    "# ix = 10\n",
    "# tmp_img, tmp_tags  = image_datasets['train'][ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "116981e26006844aba80864a76434c9b0a445188"
   },
   "outputs": [],
   "source": [
    "#test dataloader\n",
    "# tmp_img, tmp_tags = next(iter(dataloaders['train']))\n",
    "# print('tmp_img shape: {}\\ntmp_tags: shape {}'.format(tmp_img.shape, tmp_tags.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "53926b18c61ec3d5f167ee905fcde5c0dc9289f5"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class RnetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = self._prep_backbone()\n",
    "        \n",
    "    def _prep_backbone(self):     \n",
    "        base_model = models.resnet34(pretrained=True)\n",
    "        removed = list(base_model.children())[1:-2]\n",
    "        backbone = nn.Sequential(*removed)\n",
    "#         for param in backbone.parameters():\n",
    "#             param.require_grad = False\n",
    "        return backbone\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p=0.5)\n",
    "        self.fc_2 = nn.Linear(512 * 7 * 7, 256)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(256)\n",
    "        self.dropout_2 = nn.Dropout(p=0.5)\n",
    "        self.fc_3 = nn.Linear(256, self.num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc_3(x)\n",
    "        return x\n",
    "\n",
    "# class CustomEntry(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#         nn.init.kaiming_normal_(self.conv_1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv_1(x)\n",
    "#         return x\n",
    "\n",
    "class CustomEntry(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = self._prep_layers()\n",
    "        \n",
    "    def _prep_layers(self):\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        original_entry_w = torch.tensor(list(model.children())[0].weight)\n",
    "        new_entry_w = torch.cat([original_entry_w, torch.zeros(size = (64,1,7,7))], 1)\n",
    "        \n",
    "        conv_1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        conv_1.weight=conv_1.weight = torch.nn.Parameter(new_entry_w)\n",
    "        return conv_1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        return x\n",
    "    \n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.custom_entry = CustomEntry()\n",
    "        self.backbone = RnetBackbone()\n",
    "        self.custom_head = CustomHead(num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.custom_entry(x)\n",
    "        x = self.backbone(x)\n",
    "        x = self.custom_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "4ef191d711342bf7bce65d943f8629d03bcf26c1"
   },
   "outputs": [],
   "source": [
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        #f1 loss\n",
    "#         #prep y_true\n",
    "        y_true = y_true.float()\n",
    "\n",
    "        #prep y_pred\n",
    "        y_pred = torch.tensor(data = (torch.sigmoid(y_pred).ge(THRESHOLD)), dtype=torch.float, device=DEVICE, requires_grad=True)\n",
    "\n",
    "        #calculate loss\n",
    "        tp = (y_true * y_pred).sum(0).float()\n",
    "        # tn = ((1-y_true) * (1-y_pred)).sum(0).float()\n",
    "        fp = ((1-y_true) * y_pred).sum(0).float()\n",
    "        fn = (y_true * (1-y_pred)).sum(0).float()\n",
    "\n",
    "        p = tp / (tp + fp)\n",
    "        r = tp / (tp + fn)\n",
    "\n",
    "        f1 = 2*p*r / (p+r)\n",
    "        f1[torch.isnan(f1)] = 0\n",
    "        f1_loss = 1-f1.mean()\n",
    "#         print(f1_loss)\n",
    "        return f1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        target = target.float()\n",
    "        \n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "34c786807f448f63f4244537f13ebca2a6b44ee2"
   },
   "outputs": [],
   "source": [
    "def prep_stats(y_pred, y_true):\n",
    "    #prep y_true\n",
    "    y_true_tfm = y_true.cpu().numpy().astype('uint8')\n",
    "    \n",
    "    #prep y_pred khot\n",
    "    y_pred_tfm = (torch.sigmoid(y_pred) > THRESHOLD).cpu().numpy().astype('uint8')\n",
    "    \n",
    "    return y_pred_tfm, y_true_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "7df1b550cc9567063a38437001eff118004b0370"
   },
   "outputs": [],
   "source": [
    "def calc_stats(y_pred, y_true, stats = 'accurancy'):\n",
    "    if stats == 'accuracy':\n",
    "        stat_value = accuracy_score(y_true, y_pred)\n",
    "    elif stats == 'precision':\n",
    "        stat_value = precision_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'recall':\n",
    "        stat_value = recall_score(y_true, y_pred, average = 'macro')\n",
    "    elif stats == 'f1':\n",
    "        stat_value = f1_score(y_true, y_pred, average = 'macro')\n",
    "    else:\n",
    "        stat_value = 0\n",
    "    return stat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "467bc143b3e21ddb3674f77f2c78287c9bc3684c"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_y_true = []\n",
    "            running_y_pred = []\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets= targets.to(DEVICE)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    y_pred_tfm, y_true_tfm = prep_stats(outputs, targets)\n",
    "                    running_y_pred.append(y_pred_tfm)\n",
    "                    running_y_true.append(y_true_tfm)\n",
    "                    \n",
    "                    #export step stats duing training phase\n",
    "                    if phase == 'train':\n",
    "                        record_tb(phase, 'loss', loss.cpu().data.numpy(), steps)\n",
    "                        record_tb(phase, 'accuracy', calc_stats(y_pred_tfm, y_true_tfm, stats = 'accurancy'), steps)\n",
    "                        record_tb(phase, 'precision', calc_stats(y_pred_tfm, y_true_tfm, stats = 'precision'), steps)\n",
    "                        record_tb(phase, 'recall', calc_stats(y_pred_tfm, y_true_tfm, stats = 'recall'), steps)\n",
    "                        record_tb(phase, 'f1', calc_stats(y_pred_tfm, y_true_tfm, stats = 'f1'), steps)\n",
    "                        steps += 1\n",
    "                        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            #calc epoch stats\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = accuracy_score(np.vstack(running_y_true), np.vstack(running_y_pred))\n",
    "            epoch_precision = precision_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_recall = recall_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            epoch_f1 = f1_score(np.vstack(running_y_true), np.vstack(running_y_pred), average = 'macro')\n",
    "            \n",
    "            #export epoch stats duing training phase\n",
    "            if phase == 'val':\n",
    "                record_tb(phase, 'loss', epoch_loss, steps)\n",
    "                record_tb(phase, 'accuracy', epoch_acc, steps)\n",
    "                record_tb(phase, 'precision', epoch_precision, steps)\n",
    "                record_tb(phase, 'recall', epoch_recall, steps)\n",
    "                record_tb(phase, 'f1', epoch_f1, steps)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Percision: {:.4f} Recall {:.4f} F1 {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "be546ee708d7ccb01c9f876bb189db4818a7d12a"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = CustomNet(num_class=NUM_CLASSES)\n",
    "model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "criterion = FocalLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze backbone\n",
    "for param in model_ft.backbone.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/spacor/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3479 Acc: 0.0575 Percision: 0.0944 Recall 0.0418 F1 0.0499\n",
      "val Loss: 2.5592 Acc: 0.0926 Percision: 0.0943 Recall 0.0432 F1 0.0461\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.1877 Acc: 0.0865 Percision: 0.2139 Recall 0.0497 F1 0.0634\n",
      "val Loss: 1.2789 Acc: 0.1153 Percision: 0.1902 Recall 0.0577 F1 0.0667\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.1540 Acc: 0.0952 Percision: 0.2500 Recall 0.0584 F1 0.0763\n",
      "val Loss: 1.6397 Acc: 0.1227 Percision: 0.1569 Recall 0.0645 F1 0.0777\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.1477 Acc: 0.0993 Percision: 0.2999 Recall 0.0620 F1 0.0832\n",
      "val Loss: 1.7138 Acc: 0.1187 Percision: 0.2534 Recall 0.0639 F1 0.0857\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.1273 Acc: 0.1086 Percision: 0.2845 Recall 0.0682 F1 0.0921\n",
      "val Loss: 2.0058 Acc: 0.1308 Percision: 0.2362 Recall 0.0690 F1 0.0874\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.1190 Acc: 0.1143 Percision: 0.3028 Recall 0.0728 F1 0.0986\n",
      "val Loss: 1.1656 Acc: 0.1305 Percision: 0.2577 Recall 0.0718 F1 0.0901\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.1027 Acc: 0.1227 Percision: 0.3240 Recall 0.0799 F1 0.1093\n",
      "val Loss: 1.1322 Acc: 0.1374 Percision: 0.2945 Recall 0.0725 F1 0.0952\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.0956 Acc: 0.1238 Percision: 0.3813 Recall 0.0850 F1 0.1178\n",
      "val Loss: 1.1707 Acc: 0.1500 Percision: 0.3212 Recall 0.0790 F1 0.1003\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.0898 Acc: 0.1289 Percision: 0.3796 Recall 0.0882 F1 0.1214\n",
      "val Loss: 1.1610 Acc: 0.1527 Percision: 0.3432 Recall 0.0992 F1 0.1374\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.0854 Acc: 0.1300 Percision: 0.3361 Recall 0.0889 F1 0.1229\n",
      "val Loss: 1.0684 Acc: 0.1596 Percision: 0.3888 Recall 0.0938 F1 0.1183\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.0453 Acc: 0.1405 Percision: 0.3611 Recall 0.0965 F1 0.1331\n",
      "val Loss: 1.0294 Acc: 0.1619 Percision: 0.3991 Recall 0.0990 F1 0.1367\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.0323 Acc: 0.1458 Percision: 0.3585 Recall 0.0986 F1 0.1362\n",
      "val Loss: 1.0888 Acc: 0.1706 Percision: 0.3463 Recall 0.1033 F1 0.1384\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.0280 Acc: 0.1529 Percision: 0.3694 Recall 0.1039 F1 0.1437\n",
      "val Loss: 1.2265 Acc: 0.1590 Percision: 0.3496 Recall 0.0933 F1 0.1253\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.0246 Acc: 0.1514 Percision: 0.4228 Recall 0.1043 F1 0.1435\n",
      "val Loss: 1.0231 Acc: 0.1658 Percision: 0.4102 Recall 0.1013 F1 0.1380\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.0211 Acc: 0.1560 Percision: 0.4120 Recall 0.1082 F1 0.1498\n",
      "val Loss: 1.0729 Acc: 0.1669 Percision: 0.3687 Recall 0.0988 F1 0.1352\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.0181 Acc: 0.1574 Percision: 0.3954 Recall 0.1096 F1 0.1508\n",
      "val Loss: 1.1307 Acc: 0.1669 Percision: 0.3714 Recall 0.1055 F1 0.1444\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.0149 Acc: 0.1618 Percision: 0.4160 Recall 0.1119 F1 0.1544\n",
      "val Loss: 1.1302 Acc: 0.1646 Percision: 0.3861 Recall 0.1051 F1 0.1460\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 1.0141 Acc: 0.1596 Percision: 0.4517 Recall 0.1118 F1 0.1542\n",
      "val Loss: 1.0347 Acc: 0.1664 Percision: 0.4411 Recall 0.1040 F1 0.1448\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 1.0106 Acc: 0.1630 Percision: 0.4667 Recall 0.1147 F1 0.1593\n",
      "val Loss: 1.1103 Acc: 0.1714 Percision: 0.4488 Recall 0.1116 F1 0.1535\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 1.0078 Acc: 0.1623 Percision: 0.4823 Recall 0.1179 F1 0.1644\n",
      "val Loss: 1.4034 Acc: 0.1772 Percision: 0.3395 Recall 0.1125 F1 0.1510\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 1.0030 Acc: 0.1665 Percision: 0.4032 Recall 0.1156 F1 0.1592\n",
      "val Loss: 1.1109 Acc: 0.1759 Percision: 0.4358 Recall 0.1115 F1 0.1517\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 1.0024 Acc: 0.1667 Percision: 0.4151 Recall 0.1145 F1 0.1577\n",
      "val Loss: 1.0743 Acc: 0.1765 Percision: 0.3911 Recall 0.1096 F1 0.1499\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 1.0008 Acc: 0.1654 Percision: 0.4326 Recall 0.1154 F1 0.1589\n",
      "val Loss: 1.1226 Acc: 0.1746 Percision: 0.4139 Recall 0.1105 F1 0.1512\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 1.0013 Acc: 0.1667 Percision: 0.4211 Recall 0.1170 F1 0.1616\n",
      "val Loss: 0.9999 Acc: 0.1732 Percision: 0.4454 Recall 0.1097 F1 0.1509\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 1.0006 Acc: 0.1659 Percision: 0.4829 Recall 0.1180 F1 0.1638\n",
      "val Loss: 1.0680 Acc: 0.1738 Percision: 0.4044 Recall 0.1095 F1 0.1519\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.9982 Acc: 0.1670 Percision: 0.4506 Recall 0.1184 F1 0.1633\n",
      "val Loss: 1.0388 Acc: 0.1777 Percision: 0.4369 Recall 0.1142 F1 0.1563\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.9988 Acc: 0.1680 Percision: 0.4617 Recall 0.1195 F1 0.1652\n",
      "val Loss: 1.0797 Acc: 0.1751 Percision: 0.4067 Recall 0.1128 F1 0.1547\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 1.0002 Acc: 0.1703 Percision: 0.4897 Recall 0.1204 F1 0.1675\n",
      "val Loss: 1.0351 Acc: 0.1786 Percision: 0.4660 Recall 0.1135 F1 0.1547\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.9992 Acc: 0.1680 Percision: 0.5414 Recall 0.1222 F1 0.1704\n",
      "val Loss: 1.0746 Acc: 0.1769 Percision: 0.4440 Recall 0.1124 F1 0.1545\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.9963 Acc: 0.1715 Percision: 0.5186 Recall 0.1231 F1 0.1707\n",
      "val Loss: 1.0126 Acc: 0.1799 Percision: 0.4597 Recall 0.1134 F1 0.1552\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.9976 Acc: 0.1661 Percision: 0.4387 Recall 0.1183 F1 0.1627\n",
      "val Loss: 1.0320 Acc: 0.1774 Percision: 0.4645 Recall 0.1129 F1 0.1553\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.9965 Acc: 0.1701 Percision: 0.5037 Recall 0.1292 F1 0.1808\n",
      "val Loss: 1.0007 Acc: 0.1790 Percision: 0.4165 Recall 0.1127 F1 0.1538\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.9988 Acc: 0.1683 Percision: 0.4509 Recall 0.1190 F1 0.1640\n",
      "val Loss: 1.0170 Acc: 0.1770 Percision: 0.4442 Recall 0.1139 F1 0.1568\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.9986 Acc: 0.1713 Percision: 0.4534 Recall 0.1182 F1 0.1627\n",
      "val Loss: 1.0394 Acc: 0.1801 Percision: 0.4021 Recall 0.1136 F1 0.1547\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.9989 Acc: 0.1685 Percision: 0.4522 Recall 0.1182 F1 0.1628\n",
      "val Loss: 1.0917 Acc: 0.1740 Percision: 0.4295 Recall 0.1102 F1 0.1520\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.9966 Acc: 0.1690 Percision: 0.4163 Recall 0.1248 F1 0.1731\n",
      "val Loss: 1.0417 Acc: 0.1759 Percision: 0.4468 Recall 0.1124 F1 0.1555\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.9966 Acc: 0.1684 Percision: 0.4728 Recall 0.1189 F1 0.1642\n",
      "val Loss: 1.0363 Acc: 0.1759 Percision: 0.4093 Recall 0.1128 F1 0.1553\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.9979 Acc: 0.1670 Percision: 0.4935 Recall 0.1200 F1 0.1664\n",
      "val Loss: 1.0746 Acc: 0.1783 Percision: 0.4199 Recall 0.1130 F1 0.1545\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.9971 Acc: 0.1720 Percision: 0.4841 Recall 0.1232 F1 0.1716\n",
      "val Loss: 1.0358 Acc: 0.1757 Percision: 0.4470 Recall 0.1135 F1 0.1565\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.9957 Acc: 0.1674 Percision: 0.5046 Recall 0.1213 F1 0.1684\n",
      "val Loss: 1.0730 Acc: 0.1754 Percision: 0.4212 Recall 0.1141 F1 0.1573\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.9966 Acc: 0.1693 Percision: 0.4684 Recall 0.1208 F1 0.1671\n",
      "val Loss: 1.0107 Acc: 0.1762 Percision: 0.4072 Recall 0.1108 F1 0.1523\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.9974 Acc: 0.1682 Percision: 0.4330 Recall 0.1202 F1 0.1656\n",
      "val Loss: 0.9968 Acc: 0.1770 Percision: 0.4457 Recall 0.1118 F1 0.1543\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.9960 Acc: 0.1691 Percision: 0.4695 Recall 0.1183 F1 0.1632\n",
      "val Loss: 1.0396 Acc: 0.1764 Percision: 0.4176 Recall 0.1126 F1 0.1548\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.9985 Acc: 0.1675 Percision: 0.4328 Recall 0.1204 F1 0.1667\n",
      "val Loss: 1.0184 Acc: 0.1780 Percision: 0.4383 Recall 0.1140 F1 0.1557\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.9968 Acc: 0.1683 Percision: 0.5512 Recall 0.1225 F1 0.1706\n",
      "val Loss: 1.0443 Acc: 0.1761 Percision: 0.4204 Recall 0.1109 F1 0.1521\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.9953 Acc: 0.1691 Percision: 0.4813 Recall 0.1194 F1 0.1646\n",
      "val Loss: 1.0304 Acc: 0.1786 Percision: 0.4372 Recall 0.1135 F1 0.1558\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.9961 Acc: 0.1740 Percision: 0.4948 Recall 0.1255 F1 0.1743\n",
      "val Loss: 1.0845 Acc: 0.1767 Percision: 0.4087 Recall 0.1127 F1 0.1552\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.9976 Acc: 0.1749 Percision: 0.4460 Recall 0.1204 F1 0.1656\n",
      "val Loss: 1.0762 Acc: 0.1780 Percision: 0.4241 Recall 0.1133 F1 0.1554\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.9966 Acc: 0.1709 Percision: 0.5103 Recall 0.1235 F1 0.1720\n",
      "val Loss: 1.0318 Acc: 0.1756 Percision: 0.4451 Recall 0.1136 F1 0.1565\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.9961 Acc: 0.1693 Percision: 0.4839 Recall 0.1245 F1 0.1735\n",
      "val Loss: 1.0105 Acc: 0.1790 Percision: 0.4361 Recall 0.1122 F1 0.1534\n",
      "\n",
      "Training complete in 254m 52s\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model_ft.backbone.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different learning rate for different layers\n",
    "# optimizer_ft = optim.Adam([\n",
    "#     {'params': model_ft.custom_entry.parameters()},\n",
    "#     {'params': model_ft.backbone.parameters(), 'lr': 0.001},\n",
    "#     {'params': model_ft.custom_head.parameters()},\n",
    "#     ]\n",
    "# )\n",
    "# # Decay LR by a factor of 0.1 every n epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "a27461b7756ca489c66881be19cb1d0d54bf5d47"
   },
   "outputs": [],
   "source": [
    "# model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "#                        num_epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
